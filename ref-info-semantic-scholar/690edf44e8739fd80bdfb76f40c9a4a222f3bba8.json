{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741053"
                        ],
                        "name": "Wang-Cheng Kang",
                        "slug": "Wang-Cheng-Kang",
                        "structuredName": {
                            "firstName": "Wang-Cheng",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang-Cheng Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35660011"
                        ],
                        "name": "Julian McAuley",
                        "slug": "Julian-McAuley",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "McAuley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian McAuley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "For sequential recommendation, Kang and McAuley [22] introduce a two-layer Transformer decoder (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "To model such sequential dynamics in user behaviors, various methods have been proposed to make sequential recommendations based on users\u2019 historical interactions [15, 22, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "Other than recurrent neural networks, various deep learning models are also introduced for sequential recommendation [3, 22, 33, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": ", next item recommendation) task, which has been widely used in [12, 22, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "To ensure the quality of the dataset, following the common practice [12, 22, 40, 49], we keep users with at least five feedbacks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 31
                            }
                        ],
                        "text": "For sequential recommendation, Kang and McAuley [22] introduce a two-layer Transformer decoder (i.e., Transformer language model) called SASRec to capture user\u2019s sequential behaviors and achieve state-of-the-art results on several public datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "\u2022 Steam4: This is a dataset collected from Steam, a large online video game distribution platform, by Kang andMcAuley [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "\u2022 SASRec [22]: It uses a left-to-right Transformer language model to capture users\u2019 sequential behaviors, and achieves state-of-the-art performance on sequential recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "2Here, following [22, 40], we use the relative time index instead of absolute time index for numbering interaction records."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 60
                            }
                        ],
                        "text": "For dataset preprocessing, we follow the common practice in [22, 40, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 63
                            }
                        ],
                        "text": "For easy and fair evaluation, we follow the common strategy in [12, 22, 49], pairing each ground truth item in the test set with 100 randomly sampled negative items that the user has not interacted with."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "\u2022 Amazon Beauty3: This is a series of product review datasets crawled from Amazon.com by McAuley et al. [34]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 52127932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97faeefa771e8cc8e55159e2bd03e6f5eef249a8",
            "isKey": true,
            "numCitedBy": 723,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential dynamics are a key feature of many modern recommender systems, which seek to capture the 'context' of users' activities on the basis of actions they have performed recently. To capture such patterns, two approaches have proliferated: Markov Chains (MCs) and Recurrent Neural Networks (RNNs). Markov Chains assume that a user's next action can be predicted on the basis of just their last (or last few) actions, while RNNs in principle allow for longer-term semantics to be uncovered. Generally speaking, MC-based methods perform best in extremely sparse datasets, where model parsimony is critical, while RNNs perform better in denser datasets where higher model complexity is affordable. The goal of our work is to balance these two goals, by proposing a self-attention based sequential model (SASRec) that allows us to capture long-term semantics (like an RNN), but, using an attention mechanism, makes its predictions based on relatively few actions (like an MC). At each time step, SASRec seeks to identify which items are 'relevant' from a user's action history, and use them to predict the next item. Extensive empirical studies show that our method outperforms various state-of-the-art sequential models (including MC/CNN/RNN-based approaches) on both sparse and dense datasets. Moreover, the model is an order of magnitude more efficient than comparable CNN/RNN-based models. Visualizations on attention weights also show how our model adaptively handles datasets with various density, and uncovers meaningful patterns in activity sequences."
            },
            "slug": "Self-Attentive-Sequential-Recommendation-Kang-McAuley",
            "title": {
                "fragments": [],
                "text": "Self-Attentive Sequential Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Extensive empirical studies show that the proposed self-attention based sequential model (SASRec) outperforms various state-of-the-art sequential models (including MC/CNN/RNN-based approaches) on both sparse and dense datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE International Conference on Data Mining (ICDM)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143649323"
                        ],
                        "name": "Jin Huang",
                        "slug": "Jin-Huang",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542603"
                        ],
                        "name": "Wayne Xin Zhao",
                        "slug": "Wayne-Xin-Zhao",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Zhao",
                            "middleNames": [
                                "Xin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wayne Xin Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20768777"
                        ],
                        "name": "Hong-Jian Dou",
                        "slug": "Hong-Jian-Dou",
                        "structuredName": {
                            "firstName": "Hong-Jian",
                            "lastName": "Dou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong-Jian Dou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153693432"
                        ],
                        "name": "Ji-rong Wen",
                        "slug": "Ji-rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152536227"
                        ],
                        "name": "Edward Y. Chang",
                        "slug": "Edward-Y.-Chang",
                        "structuredName": {
                            "firstName": "Edward Y.",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Y. Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] employ Memory Network to improve sequential recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "To make the sampling reliable and representative [19], these 100 negative items are sampled according to their popularity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49644765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4e5af510c63ecb84c4619b9fc12a2d26a3c8d40",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "With the revival of neural networks, many studies try to adapt powerful sequential neural models, \u0131e Recurrent Neural Networks (RNN), to sequential recommendation. RNN-based networks encode historical interaction records into a hidden state vector. Although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. It is difficult to capture fine-grained user preference from the interaction sequence. Furthermore, the latent vector representation is usually hard to understand and explain. To address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. Our model integrates the RNN-based networks with Key-Value Memory Network (KV-MN). We further incorporate knowledge base (KB) information to enhance the semantic representation of KV-MN. RNN-based models are good at capturing sequential user preference, while knowledge-enhanced KV-MNs are good at capturing attribute-level user preference. By using a hybrid of RNNs and KV-MNs, it is expected to be endowed with both benefits from these two components. The sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. With the incorporation of KB information, our model is also highly interpretable. To our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale KB information."
            },
            "slug": "Improving-Sequential-Recommendation-with-Memory-Huang-Zhao",
            "title": {
                "fragments": [],
                "text": "Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a novel knowledge enhanced sequential recommender that integrates the RNN-based networks with Key-Value Memory Network (KV-MN) and incorporates knowledge base information to enhance the semantic representation of KV- MN."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2933399"
                        ],
                        "name": "Ruining He",
                        "slug": "Ruining-He",
                        "structuredName": {
                            "firstName": "Ruining",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruining He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35660011"
                        ],
                        "name": "Julian McAuley",
                        "slug": "Julian-McAuley",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "McAuley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian McAuley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Besides the first-order MCs, high-order MCs are also adopted to consider more previous items [10, 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9124261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fea7e2bcbe852bcb33ce70a4d57664e954f0e82a",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting personalized sequential behavior is a key task for recommender systems. In order to predict user actions such as the next product to purchase, movie to watch, or place to visit, it is essential to take into account both long-term user preferences and sequential patterns (i.e., short-term dynamics). Matrix Factorization and Markov Chain methods have emerged as two separate but powerful paradigms for modeling the two respectively. Combining these ideas has led to unified methods that accommodate long-and short-term dynamics simultaneously by modeling pairwise user-item and item-item interactions. In spite of the success of such methods for tackling dense data, they are challenged by sparsity issues, which are prevalent in real-world datasets. In recent years, similarity-based methods have been proposed for (sequentially-unaware) item recommendation with promising results on sparse datasets. In this paper, we propose to fuse such methods with Markov Chains to make personalized sequential recommendations. We evaluate our method, Fossil, on a variety of large, real-world datasets. We show quantitatively that Fossil outperforms alternative algorithms, especially on sparse datasets, and qualitatively that it captures personalized dynamics and is able to make meaningful recommendations."
            },
            "slug": "Fusing-Similarity-Models-with-Markov-Chains-for-He-McAuley",
            "title": {
                "fragments": [],
                "text": "Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Fossil is proposed, a similarity-based method that outperforms alternative algorithms, especially on sparse datasets, and qualitatively that it captures personalized dynamics and is able to make meaningful recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE 16th International Conference on Data Mining (ICDM)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3431394"
                        ],
                        "name": "Jiaxi Tang",
                        "slug": "Jiaxi-Tang",
                        "structuredName": {
                            "firstName": "Jiaxi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaxi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133843000"
                        ],
                        "name": "Ke Wang",
                        "slug": "Ke-Wang",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "Other than recurrent neural networks, various deep learning models are also introduced for sequential recommendation [3, 22, 33, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "\u2022 Caser [49]: It employs CNN in both horizontal and vertical way to model high-order MCs for sequential recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": ", next item recommendation) task, which has been widely used in [12, 22, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "To ensure the quality of the dataset, following the common practice [12, 22, 40, 49], we keep users with at least five feedbacks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "For example, Tang and Wang [49] propose a Convolutional Sequence Model (Caser) to learn sequential patterns using both horizontal and vertical convolutional filters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 60
                            }
                        ],
                        "text": "For dataset preprocessing, we follow the common practice in [22, 40, 49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 63
                            }
                        ],
                        "text": "For easy and fair evaluation, we follow the common strategy in [12, 22, 49], pairing each ground truth item in the test set with 100 randomly sampled negative items that the user has not interacted with."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39847715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75a927501749c2cbc0e19a58f798f04de59df64a",
            "isKey": true,
            "numCitedBy": 710,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Top-N sequential recommendation models each user as a sequence of items interacted in the past and aims to predict top-N ranked items that a user will likely interact in a \u00bbnear future\u00bb. The order of interaction implies that sequential patterns play an important role where more recent items in a sequence have a larger impact on the next item. In this paper, we propose a Convolutional Sequence Embedding Recommendation Model \u00bbCaser\u00bb as a solution to address this requirement. The idea is to embed a sequence of recent items into an \u00bbimage\u00bb in the time and latent spaces and learn sequential patterns as local features of the image using convolutional filters. This approach provides a unified and flexible network structure for capturing both general preferences and sequential patterns. The experiments on public data sets demonstrated that Caser consistently outperforms state-of-the-art sequential recommendation methods on a variety of common evaluation metrics."
            },
            "slug": "Personalized-Top-N-Sequential-Recommendation-via-Tang-Wang",
            "title": {
                "fragments": [],
                "text": "Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A Convolutional Sequence Embedding Recommendation Model \u00bbCaser\u00bb is proposed, which is to embed a sequence of recent items into an image in the time and latent spaces and learn sequential patterns as local features of the image using convolutional filters."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152907678"
                        ],
                        "name": "Jing Li",
                        "slug": "Jing-Li",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749477"
                        ],
                        "name": "Pengjie Ren",
                        "slug": "Pengjie-Ren",
                        "structuredName": {
                            "firstName": "Pengjie",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pengjie Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721165"
                        ],
                        "name": "Zhumin Chen",
                        "slug": "Zhumin-Chen",
                        "structuredName": {
                            "firstName": "Zhumin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhumin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780667"
                        ],
                        "name": "Z. Ren",
                        "slug": "Z.-Ren",
                        "structuredName": {
                            "firstName": "Zhaochun",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889776"
                        ],
                        "name": "Tao Lian",
                        "slug": "Tao-Lian",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Lian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Lian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729719"
                        ],
                        "name": "Jun Ma",
                        "slug": "Jun-Ma",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 368,
                                "start": 364
                            }
                        ],
                        "text": "The basic idea of these methods is to encode user\u2019s previous records into a vector (i.e., representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i.e., BPR-max and TOP1-max) and an improved sampling strategy [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 119
                            }
                        ],
                        "text": "Recently, some works try to employ the attention mechanism to improve recommendation performances and interpretability [28, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 284
                            }
                        ],
                        "text": ", representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[28] incorporate an attention mechanism into GRU to capture both the user\u2019s sequential behavior and main purpose in session-based recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21066930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97de32d8ca162944e5f7e83071c596d13d168109",
            "isKey": true,
            "numCitedBy": 670,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Given e-commerce scenarios that user profiles are invisible, session-based recommendation is proposed to generate recommendation results from short sessions. Previous work only considers the user's sequential behavior in the current session, whereas the user's main purpose in the current session is not emphasized. In this paper, we propose a novel neural networks framework, i.e., Neural Attentive Recommendation Machine (NARM), to tackle this problem. Specifically, we explore a hybrid encoder with an attention mechanism to model the user's sequential behavior and capture the user's main purpose in the current session, which are combined as a unified session representation later. We then compute the recommendation scores for each candidate item with a bi-linear matching scheme based on this unified session representation. We train NARM by jointly learning the item and session representations as well as their matchings. We carried out extensive experiments on two benchmark datasets. Our experimental results show that NARM outperforms state-of-the-art baselines on both datasets. Furthermore, we also find that NARM achieves a significant improvement on long sessions, which demonstrates its advantages in modeling the user's sequential behavior and main purpose simultaneously."
            },
            "slug": "Neural-Attentive-Session-based-Recommendation-Li-Ren",
            "title": {
                "fragments": [],
                "text": "Neural Attentive Session-based Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A novel neural networks framework, i.e., Neural Attentive Recommendation Machine (NARM), is proposed to tackle session-based recommendation, which outperforms state-of-the-art baselines on both datasets and achieves a significant improvement on long sessions."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "In this work, following OpenAI GPT [37] and BERT [6], we use a smoother GELU [13] activation rather than the standard ReLu activation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 213
                            }
                        ],
                        "text": "For representation power, the superior results for deep bidirectional models on text sequence modeling tasks show that it is beneficial to incorporate context from both sides for sequence representations learning [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Specifically, inspired by the success of BERT [6] in text understanding, we propose to apply the deep bidirectional self-attention model to sequential recommendation, as illustrated in Figure 1b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "To tackle this problem, we introduce the Cloze task [6, 50] to take the place of the objective in unidirectional models (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Previous work has shown that it is beneficial to jointly attend to information from different representation subspaces at different positions [6, 29, 52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "In contrast, Transformer [52] and BERT [6] are built solely on multi-head self-attention and achieve state-of-the-art results on text sequence modeling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "In order to efficiently train our proposed model, we apply a new objective: Cloze task [50] (also known as \u201cMasked Language Model\u201d in [6]) to sequential recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": true,
            "numCitedBy": 38956,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155385667"
                        ],
                        "name": "Feng Yu",
                        "slug": "Feng-Yu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48873756"
                        ],
                        "name": "Q. Liu",
                        "slug": "Q.-Liu",
                        "structuredName": {
                            "firstName": "Q.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50425438"
                        ],
                        "name": "Shu Wu",
                        "slug": "Shu-Wu",
                        "structuredName": {
                            "firstName": "Shu",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shu Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123865558"
                        ],
                        "name": "Liang Wang",
                        "slug": "Liang-Wang",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143874948"
                        ],
                        "name": "T. Tan",
                        "slug": "T.-Tan",
                        "structuredName": {
                            "firstName": "Tieniu",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 231
                            }
                        ],
                        "text": ", representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7, 14, 15, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 315,
                                "start": 310
                            }
                        ],
                        "text": "The basic idea of these methods is to encode user\u2019s previous records into a vector (i.e., representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i.e., BPR-max and TOP1-max) and an improved sampling strategy [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2023817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d87ab4e11143a02afaf28222c4cacb7248a3ad0",
            "isKey": true,
            "numCitedBy": 339,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Next basket recommendation becomes an increasing concern. Most conventional models explore either sequential transaction features or general interests of users. Further, some works treat users' general interests and sequential behaviors as two totally divided matters, and then combine them in some way for next basket recommendation. Moreover, the state-of-the-art models are based on the assumption of Markov Chains (MC), which only capture local sequential features between two adjacent baskets. In this work, we propose a novel model, Dynamic REcurrent bAsket Model (DREAM), based on Recurrent Neural Network (RNN). DREAM not only learns a dynamic representation of a user but also captures global sequential features among baskets. The dynamic representation of a specific user can reveal user's dynamic interests at different time, and the global sequential features reflect interactions of all baskets of the user over time. Experiment results on two public datasets indicate that DREAM is more effective than the state-of-the-art models for next basket recommendation."
            },
            "slug": "A-Dynamic-Recurrent-Model-for-Next-Basket-Yu-Liu",
            "title": {
                "fragments": [],
                "text": "A Dynamic Recurrent Model for Next Basket Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a novel model, Dynamic REcurrent bAsket Model (DREAM), based on Recurrent Neural Network (RNN), which not only learns a dynamic representation of a user but also captures global sequential features among baskets."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2933399"
                        ],
                        "name": "Ruining He",
                        "slug": "Ruining-He",
                        "structuredName": {
                            "firstName": "Ruining",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruining He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741053"
                        ],
                        "name": "Wang-Cheng Kang",
                        "slug": "Wang-Cheng-Kang",
                        "structuredName": {
                            "firstName": "Wang-Cheng",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang-Cheng Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35660011"
                        ],
                        "name": "Julian McAuley",
                        "slug": "Julian-McAuley",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "McAuley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian McAuley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Besides the first-order MCs, high-order MCs are also adopted to consider more previous items [10, 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10246046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5a823053663a77869d4b38a8026c51ebc2e975e",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling the complex interactions between users and items as well as amongst items themselves is at the core of designing successful recommender systems. One classical setting is predicting users' personalized sequential behavior (or 'next-item' recommendation), where the challenges mainly lie in modeling 'third-order' interactions between a user, her previously visited item(s), and the next item to consume. Existing methods typically decompose these higher-order interactions into a combination of pairwise relationships, by way of which user preferences (user-item interactions) and sequential patterns (item-item interactions) are captured by separate components. In this paper, we propose a unified method, TransRec, to model such third-order relationships for large-scale sequential prediction. Methodologically, we embed items into a 'transition space' where users are modeled as translation vectors operating on item sequences. Empirically, this approach outperforms the state-of-the-art on a wide spectrum of real-world datasets. Data and code are available at https://sites.google.com/a/eng.ucsd.edu/ruining-he/."
            },
            "slug": "Translation-based-Recommendation-He-Kang",
            "title": {
                "fragments": [],
                "text": "Translation-based Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a unified method, TransRec, to model such third-order relationships for large-scale sequential prediction, and embeds items into a 'transition space' where users are modeled as translation vectors operating on item sequences."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507883"
                        ],
                        "name": "Bal\u00e1zs Hidasi",
                        "slug": "Bal\u00e1zs-Hidasi",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Hidasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Hidasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713164"
                        ],
                        "name": "Alexandros Karatzoglou",
                        "slug": "Alexandros-Karatzoglou",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Karatzoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandros Karatzoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2666397"
                        ],
                        "name": "L. Baltrunas",
                        "slug": "L.-Baltrunas",
                        "structuredName": {
                            "firstName": "Linas",
                            "lastName": "Baltrunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baltrunas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754164"
                        ],
                        "name": "D. Tikk",
                        "slug": "D.-Tikk",
                        "structuredName": {
                            "firstName": "Domonkos",
                            "lastName": "Tikk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tikk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "To model such sequential dynamics in user behaviors, various methods have been proposed to make sequential recommendations based on users\u2019 historical interactions [15, 22, 40]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "\u2022 GRU4Rec [15]: It uses GRU with ranking based loss to model user sequences for session based recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7, 14, 15, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": ", representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11810482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfb1e7d1559fbc2eb63761bc170061d256496bdf",
            "isKey": true,
            "numCitedBy": 1369,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches."
            },
            "slug": "Session-based-Recommendations-with-Recurrent-Neural-Hidasi-Karatzoglou",
            "title": {
                "fragments": [],
                "text": "Session-based Recommendations with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that by modeling the whole session, more accurate recommendations can be provided by an RNN-based approach for session-based recommendations, and introduced several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422336"
                        ],
                        "name": "A\u00e4ron van den Oord",
                        "slug": "A\u00e4ron-van-den-Oord",
                        "structuredName": {
                            "firstName": "A\u00e4ron",
                            "lastName": "Oord",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A\u00e4ron van den Oord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48373216"
                        ],
                        "name": "S. Dieleman",
                        "slug": "S.-Dieleman",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Dieleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dieleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621946"
                        ],
                        "name": "B. Schrauwen",
                        "slug": "B.-Schrauwen",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Schrauwen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schrauwen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": ", text [23, 53], images [21, 55], and acoustic features [51] into CF models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7118498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eeff60867041d2ea92d1b38a20c2031d240d8872",
            "isKey": false,
            "numCitedBy": 995,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic music recommendation has become an increasingly relevant problem in recent years, since a lot of music is now sold and consumed digitally. Most recommender systems rely on collaborative filtering. However, this approach suffers from the cold start problem: it fails when no usage data is available, so it is not effective for recommending new and unpopular songs. In this paper, we propose to use a latent factor model for recommendation, and predict the latent factors from music audio when they cannot be obtained from usage data. We compare a traditional approach using a bag-of-words representation of the audio signals with deep convolutional neural networks, and evaluate the predictions quantitatively and qualitatively on the Million Song Dataset. We show that using predicted latent factors produces sensible recommendations, despite the fact that there is a large semantic gap between the characteristics of a song that affect user preference and the corresponding audio signal. We also show that recent advances in deep learning translate very well to the music recommendation setting, with deep convolutional neural networks significantly outperforming the traditional approach."
            },
            "slug": "Deep-content-based-music-recommendation-Oord-Dieleman",
            "title": {
                "fragments": [],
                "text": "Deep content-based music recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes to use a latent factor model for recommendation, and predict the latent factors from music audio when they cannot be obtained from usage data, and shows that recent advances in deep learning translate very well to the music recommendation setting, with deep convolutional neural networks significantly outperforming the traditional approach."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145484826"
                        ],
                        "name": "Qiao Liu",
                        "slug": "Qiao-Liu",
                        "structuredName": {
                            "firstName": "Qiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111107493"
                        ],
                        "name": "Yifu Zeng",
                        "slug": "Yifu-Zeng",
                        "structuredName": {
                            "firstName": "Yifu",
                            "lastName": "Zeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yifu Zeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1396564485"
                        ],
                        "name": "Refuoe Mokhosi",
                        "slug": "Refuoe-Mokhosi",
                        "structuredName": {
                            "firstName": "Refuoe",
                            "lastName": "Mokhosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refuoe Mokhosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111127164"
                        ],
                        "name": "Haibin Zhang",
                        "slug": "Haibin-Zhang",
                        "structuredName": {
                            "firstName": "Haibin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibin Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 119
                            }
                        ],
                        "text": "Recently, some works try to employ the attention mechanism to improve recommendation performances and interpretability [28, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "Other than recurrent neural networks, various deep learning models are also introduced for sequential recommendation [3, 22, 33, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "STAMP captures both users\u2019 general interests and current interests using an MLP network with attention [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 50775765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd3f489fc0438e500c0473af40dfebe4705df6d2",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting users' actions based on anonymous sessions is a challenging problem in web-based behavioral modeling research, mainly due to the uncertainty of user behavior and the limited information. Recent advances in recurrent neural networks have led to promising approaches to solving this problem, with long short-term memory model proving effective in capturing users' general interests from previous clicks. However, none of the existing approaches explicitly take the effects of users' current actions on their next moves into account. In this study, we argue that a long-term memory model may be insufficient for modeling long sessions that usually contain user interests drift caused by unintended clicks. A novel short-term attention/memory priority model is proposed as a remedy, which is capable of capturing users' general interests from the long-term memory of a session context, whilst taking into account users' current interests from the short-term memory of the last-clicks. The validity and efficacy of the proposed attention mechanism is extensively evaluated on three benchmark data sets from the RecSys Challenge 2015 and CIKM Cup 2016. The numerical results show that our model achieves state-of-the-art performance in all the tests."
            },
            "slug": "STAMP:-Short-Term-Attention/Memory-Priority-Model-Liu-Zeng",
            "title": {
                "fragments": [],
                "text": "STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is argued that a long-term memory model may be insufficient for modeling long sessions that usually contain user interests drift caused by unintended clicks, and a novel short-term attention/memory priority model is proposed as a remedy, which is capable of capturing users' general interests from the long- Term memory of a session context, whilst taking into account users' current interest from the short- term memory of the last-clicks."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32781973"
                        ],
                        "name": "Lizi Liao",
                        "slug": "Lizi-Liao",
                        "structuredName": {
                            "firstName": "Lizi",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lizi Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143982887"
                        ],
                        "name": "Liqiang Nie",
                        "slug": "Liqiang-Nie",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48539382"
                        ],
                        "name": "Xia Hu",
                        "slug": "Xia-Hu",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": ", next item recommendation) task, which has been widely used in [12, 22, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "To ensure the quality of the dataset, following the common practice [12, 22, 40, 49], we keep users with at least five feedbacks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "For NCF7, GRU4Rec8, GRU4Rec+8, Caser9, and SASRec10, we use code provided by the corresponding authors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "For example, Neural Collaborative Filtering (NCF) [12] estimates user preferences via Multi-Layer Perceptions (MLP) instead of inner product, while AutoRec [44] and CDAE [57] predict users\u2019 ratings using Auto-encoder framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 63
                            }
                        ],
                        "text": "For easy and fair evaluation, we follow the common strategy in [12, 22, 49], pairing each ground truth item in the test set with 100 randomly sampled negative items that the user has not interacted with."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "Among all the baseline methods, sequential methods (e.g., FPMC and GRU4Rec+) outperforms non-sequential methods (e.g., BPR-MF and NCF) on all datasets consistently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "\u2022 NCF [12]: It models user\u2013item interactions with a MLP instead of the inner product in matrix factorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13907106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad42c33c299ef1c53dfd4697e3f7f98ed0ca31dd",
            "isKey": true,
            "numCitedBy": 3248,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance."
            },
            "slug": "Neural-Collaborative-Filtering-He-Liao",
            "title": {
                "fragments": [],
                "text": "Neural Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work strives to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback, and presents a general framework named NCF, short for Neural network-based Collaborative Filtering."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 118
                            }
                        ],
                        "text": "The temperature \u221a d/h is introduced to produce a softer attention distribution for avoiding extremely small gradients [16, 52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 150
                            }
                        ],
                        "text": "In order to make use of the sequential information of the input, we inject Positional Embeddings into the input item embeddings at the bottoms of the Transformer layer stacks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 27
                            }
                        ],
                        "text": "As shown in Figure 1a, the Transformer layer Trm contains two sub-layers, a Multi-Head Self-Attention sub-layer and a Position-wise Feed-Forward Network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 75
                            }
                        ],
                        "text": "For sequential recommendation, Kang and McAuley [22] introduce a two-layer Transformer decoder (i.e., Transformer language model) called SASRec to capture user\u2019s sequential behaviors and achieve state-of-the-art results on several public datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Previous work has shown that it is beneficial to jointly attend to information from different representation subspaces at different positions [6, 29, 52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 68
                            }
                        ],
                        "text": "As illustrated in Figure 1b, BERT4Rec is stacked by L bidirectional Transformer layers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "In this work, we use the learnable positional embeddings instead of the fixed sinusoid embeddings in [52] for better performances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": ", machine translation [2, 52] and text classification [58]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 9
                            }
                        ],
                        "text": "Stacking Transformer Layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 38
                            }
                        ],
                        "text": "\u2022 SASRec [22]: It uses a left-to-right Transformer language model to capture users\u2019 sequential behaviors, and achieves state-of-the-art performance on sequential recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 184
                            }
                        ],
                        "text": "As illustrated in Figure 1b, given an input sequence of length t , we iteratively compute hidden representations hli at each layer l for each position i simultaneously by applying the Transformer layer from [52]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 51
                            }
                        ],
                        "text": "It is built upon the popular self-attention layer, \u201cTransformer layer\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 289
                            }
                        ],
                        "text": "At each layer, it iteratively revises the\n2Here, following [22, 40], we use the relative time index instead of absolute time index for numbering interaction records.\nrepresentation of every position by exchanging information across all positions at the previous layer in parallel with the Transformer layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "In contrast, Transformer [52] and BERT [6] are built solely on multi-head self-attention and achieve state-of-the-art results on text sequence modeling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 71
                            }
                        ],
                        "text": "As elaborated above, without any recurrence or convolution module, the Transformer layer Trm is not aware of the order of the input sequence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "Here, we introduce a new sequential recommendation model called BERT4Rec, which adopts Bidirectional Encoder Representations from Transformers to a new task, sequential Recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 84
                            }
                        ],
                        "text": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": true,
            "numCitedBy": 41249,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2907656"
                        ],
                        "name": "Tim Donkers",
                        "slug": "Tim-Donkers",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Donkers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Donkers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264774"
                        ],
                        "name": "Benedikt Loepp",
                        "slug": "Benedikt-Loepp",
                        "structuredName": {
                            "firstName": "Benedikt",
                            "lastName": "Loepp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benedikt Loepp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145758499"
                        ],
                        "name": "J. Ziegler",
                        "slug": "J.-Ziegler",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Ziegler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ziegler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "7https://github.com/hexiangnan/neural_collaborative_filtering 8https://github.com/hidasib/GRU4Rec 9https://github.com/graytowne/caser_pytorch 10https://github.com/kang205/SASRec\nWe implement BERT4Rec11 with TensorFlow."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "For example, Li et al. [28] incorporate an attention mechanism into GRU to capture both the user\u2019s sequential behavior and main purpose in session-based recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 240
                            }
                        ],
                        "text": "The basic idea of these methods is to encode user\u2019s previous records into a vector (i.e., representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i.e., BPR-max and TOP1-max) and an improved sampling strategy [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "For NCF7, GRU4Rec8, GRU4Rec+8, Caser9, and SASRec10, we use code provided by the corresponding authors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Furthermore, SASRec performs distinctly better than GRU4Rec and GRU4Rec+, suggesting that self-attention mechanism is a more powerful tool for sequential recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7, 14, 15, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "\u2022 GRU4Rec+ [14]: It is an improved version of GRU4Rec with a new class of loss functions and sampling strategy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Among all the baseline methods, sequential methods (e.g., FPMC and GRU4Rec+) outperforms non-sequential methods (e.g., BPR-MF and NCF) on all datasets consistently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 252
                            }
                        ],
                        "text": ", representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "This causes Caser to perform worse than GRU4Rec+ and SASRec, especially on sparse datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "\u2022 FPMC [40]: It captures users\u2019 general taste as well as their sequential behaviors by combing MF with first-order MCs. \u2022 GRU4Rec [15]: It uses GRU with ranking based loss to model user sequences for session based recommendation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 38116062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "665a99a77b3d07859d56dd78ceda17c2ce226195",
            "isKey": true,
            "numCitedBy": 209,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks are powerful tools for modeling sequences. They are flexibly extensible and can incorporate various kinds of information including temporal order. These properties make them well suited for generating sequential recommendations. In this paper, we extend Recurrent Neural Networks by considering unique characteristics of the Recommender Systems domain. One of these characteristics is the explicit notion of the user recommendations are specifically generated for. We show how individual users can be represented in addition to sequences of consumed items in a new type of Gated Recurrent Unit to effectively produce personalized next item recommendations. Offline experiments on two real-world datasets indicate that our extensions clearly improve objective performance when compared to state-of-the-art recommender algorithms and to a conventional Recurrent Neural Network."
            },
            "slug": "Sequential-User-based-Recurrent-Neural-Network-Donkers-Loepp",
            "title": {
                "fragments": [],
                "text": "Sequential User-based Recurrent Neural Network Recommendations"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper extends Recurrent Neural Networks by considering unique characteristics of the Recommender Systems domain and shows how individual users can be represented in addition to sequences of consumed items in a new type of Gated Recurrent Unit to effectively produce personalized next item recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145183039"
                        ],
                        "name": "Donghyun Kim",
                        "slug": "Donghyun-Kim",
                        "structuredName": {
                            "firstName": "Donghyun",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghyun Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109120259"
                        ],
                        "name": "Chanyoung Park",
                        "slug": "Chanyoung-Park",
                        "structuredName": {
                            "firstName": "Chanyoung",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chanyoung Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031932"
                        ],
                        "name": "Jinoh Oh",
                        "slug": "Jinoh-Oh",
                        "structuredName": {
                            "firstName": "Jinoh",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinoh Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31273100"
                        ],
                        "name": "Sungyoung Lee",
                        "slug": "Sungyoung-Lee",
                        "structuredName": {
                            "firstName": "Sungyoung",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungyoung Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723357"
                        ],
                        "name": "Hwanjo Yu",
                        "slug": "Hwanjo-Yu",
                        "structuredName": {
                            "firstName": "Hwanjo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hwanjo Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": ", text [23, 53], images [21, 55], and acoustic features [51] into CF models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207239982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af9c4dda90e807246a2f6fa0a922bbf8029767cf",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem, several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular, when rating data is sparse, document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews, abstracts, or synopses. However, due to the inherent limitation of the bag-of-words model, they have difficulties in effectively utilizing contextual information of the documents, which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model, convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently, ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF."
            },
            "slug": "Convolutional-Matrix-Factorization-for-Document-Kim-Park",
            "title": {
                "fragments": [],
                "text": "Convolutional Matrix Factorization for Document Context-Aware Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel context-aware recommendation model that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF) that captures contextual information of documents and further enhances the rating prediction accuracy is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49528584"
                        ],
                        "name": "Hao Wang",
                        "slug": "Hao-Wang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48246959"
                        ],
                        "name": "Naiyan Wang",
                        "slug": "Naiyan-Wang",
                        "structuredName": {
                            "firstName": "Naiyan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naiyan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": ", text [23, 53], images [21, 55], and acoustic features [51] into CF models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4833213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3eaf79589dbb9bce5a502e867a8f03917e52de26",
            "isKey": false,
            "numCitedBy": 1341,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering (CF) is a successful approach commonly used by many recommender systems. Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance. To address this sparsity problem, auxiliary information such as item content information may be utilized. Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information. Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse. To address this problem, we generalize recently advances in deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix. Extensive experiments on three real-world datasets from different domains show that CDL can significantly advance the state of the art."
            },
            "slug": "Collaborative-Deep-Learning-for-Recommender-Systems-Wang-Wang",
            "title": {
                "fragments": [],
                "text": "Collaborative Deep Learning for Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix is proposed, which can significantly advance the state of the art."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032788"
                        ],
                        "name": "Massimo Quadrana",
                        "slug": "Massimo-Quadrana",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Quadrana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Massimo Quadrana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713164"
                        ],
                        "name": "Alexandros Karatzoglou",
                        "slug": "Alexandros-Karatzoglou",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Karatzoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandros Karatzoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507883"
                        ],
                        "name": "Bal\u00e1zs Hidasi",
                        "slug": "Bal\u00e1zs-Hidasi",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Hidasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Hidasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709519"
                        ],
                        "name": "P. Cremonesi",
                        "slug": "P.-Cremonesi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Cremonesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cremonesi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10174110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb57001315188582bbb79e548dfdb354592fa80e",
            "isKey": false,
            "numCitedBy": 404,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Session-based recommendations are highly relevant in many modern on-line services (e.g. e-commerce, video streaming) and recommendation settings. Recently, Recurrent Neural Networks have been shown to perform very well in session-based settings. While in many session-based recommendation domains user identifiers are hard to come by, there are also domains in which user profiles are readily available. We propose a seamless way to personalize RNN models with cross-session information transfer and devise a Hierarchical RNN model that relays end evolves latent hidden states of the RNNs across user sessions. Results on two industry datasets show large improvements over the session-only RNNs."
            },
            "slug": "Personalizing-Session-based-Recommendations-with-Quadrana-Karatzoglou",
            "title": {
                "fragments": [],
                "text": "Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A seamless way to personalize RNN models with cross-session information transfer is proposed and a Hierarchical RNN model that relays end evolves latent hidden states of the RNNs across user sessions is devised."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38759328"
                        ],
                        "name": "Peter Shaw",
                        "slug": "Peter-Shaw",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Shaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Shaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 155
                            }
                        ],
                        "text": "Recently, there is a rising enthusiasm for applying purely attention-based neural networks to model sequential data for their effectiveness and efficiency [30, 32, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3725815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8efcc854d97dfc2a42b83316a2109f9d166e43f",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the WMT 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs."
            },
            "slug": "Self-Attention-with-Relative-Position-Shaw-Uszkoreit",
            "title": {
                "fragments": [],
                "text": "Self-Attention with Relative Position Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements, on the WMT 2014 English-to-German and English- to-French translation tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9194382"
                        ],
                        "name": "Chaoxia Wu",
                        "slug": "Chaoxia-Wu",
                        "structuredName": {
                            "firstName": "Chaoxia",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaoxia Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638246"
                        ],
                        "name": "Alex Beutel",
                        "slug": "Alex-Beutel",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Beutel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Beutel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3004697"
                        ],
                        "name": "How Jing",
                        "slug": "How-Jing",
                        "structuredName": {
                            "firstName": "How",
                            "lastName": "Jing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "How Jing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7, 14, 15, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5362246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "119868d3a5862c514e64d7855b41ff9927c311d4",
            "isKey": false,
            "numCitedBy": 520,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive, that is, they are inferred after they are observed, e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics, in addition to a more traditional low-rank factorization. On multiple real-world datasets, our model offers excellent prediction accuracy and it is very compact, since we need not learn latent state but rather just the state transition function."
            },
            "slug": "Recurrent-Recommender-Networks-Wu-Ahmed",
            "title": {
                "fragments": [],
                "text": "Recurrent Recommender Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Recurrent Recommender Networks (RRN) are proposed that are able to predict future behavioral trajectories by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics, in addition to a more traditional low-rank factorization."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741053"
                        ],
                        "name": "Wang-Cheng Kang",
                        "slug": "Wang-Cheng-Kang",
                        "structuredName": {
                            "firstName": "Wang-Cheng",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang-Cheng Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144823841"
                        ],
                        "name": "Chen Fang",
                        "slug": "Chen-Fang",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8056043"
                        ],
                        "name": "Zhaowen Wang",
                        "slug": "Zhaowen-Wang",
                        "structuredName": {
                            "firstName": "Zhaowen",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaowen Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35660011"
                        ],
                        "name": "Julian McAuley",
                        "slug": "Julian-McAuley",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "McAuley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian McAuley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": ", text [23, 53], images [21, 55], and acoustic features [51] into CF models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23787675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d8ccc5a35affb08271fee720a24418c8943b44",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Building effective recommender systems for domains like fashion is challenging due to the high level of subjectivity and the semantic complexity of the features involved (i.e., fashion styles). Recent work has shown that approaches to 'visual' recommendation (e.g. clothing, art, etc.) can be made more accurate by incorporating visual signals directly into the recommendation objective, using 'off-the-shelf' feature representations derived from deep networks. Here, we seek to extend this contribution by showing that recommendation performance can be significantly improved by learning 'fashion aware' image representations directly, i.e., by training the image representation (from the pixel level) and the recommender system jointly; this contribution is related to recent work using Siamese CNNs, though we are able to show improvements over state-of-the-art recommendation techniques such as BPR and variants that make use of pretrained visual features. Furthermore, we show that our model can be used generatively, i.e., given a user and a product category, we can generate new images (i.e., clothing items) that are most consistent with their personal taste. This represents a first step towards building systems that go beyond recommending existing items from a product corpus, but which can be used to suggest styles and aid the design of new products."
            },
            "slug": "Visually-Aware-Fashion-Recommendation-and-Design-Kang-Fang",
            "title": {
                "fragments": [],
                "text": "Visually-Aware Fashion Recommendation and Design with Generative Image Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The model is able to show improvements over state-of-the-art recommendation techniques such as BPR and variants that make use of pretrained visual features, and can be used generatively, i.e., used to suggest styles and aid the design of new products."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Data Mining (ICDM)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108052451"
                        ],
                        "name": "Yao Wu",
                        "slug": "Yao-Wu",
                        "structuredName": {
                            "firstName": "Yao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46435365"
                        ],
                        "name": "Christopher DuBois",
                        "slug": "Christopher-DuBois",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "DuBois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher DuBois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3001424"
                        ],
                        "name": "A. Zheng",
                        "slug": "A.-Zheng",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Zheng",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766588"
                        ],
                        "name": "M. Ester",
                        "slug": "M.-Ester",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Ester",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "For example, Neural Collaborative Filtering (NCF) [12] estimates user preferences via Multi-Layer Perceptions (MLP) instead of inner product, while AutoRec [44] and CDAE [57] predict users\u2019 ratings using Auto-encoder framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6392154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7656cddac460af91919558175063938acfdd813b",
            "isKey": false,
            "numCitedBy": 744,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Most real-world recommender services measure their performance based on the top-N results shown to the end users. Thus, advances in top-N recommendation have far-ranging consequences in practical applications. In this paper, we present a novel method, called Collaborative Denoising Auto-Encoder (CDAE), for top-N recommendation that utilizes the idea of Denoising Auto-Encoders. We demonstrate that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components. Thorough experiments are conducted to understand the performance of CDAE under various component settings. Furthermore, experimental results on several public datasets demonstrate that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics."
            },
            "slug": "Collaborative-Denoising-Auto-Encoders-for-Top-N-Wu-DuBois",
            "title": {
                "fragments": [],
                "text": "Collaborative Denoising Auto-Encoders for Top-N Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that the proposed model is a generalization of several well-known collaborative filtering models but with more flexible components, and that CDAE consistently outperforms state-of-the-art top-N recommendation methods on a variety of common evaluation metrics."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207178809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50d85cb114f7c5e779a6772f2931e77dddd54a5e",
            "isKey": false,
            "numCitedBy": 1340,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization."
            },
            "slug": "Factorizing-personalized-Markov-chains-for-Rendle-Freudenthaler",
            "title": {
                "fragments": [],
                "text": "Factorizing personalized Markov chains for next-basket recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data and shows that the FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382247"
                        ],
                        "name": "Zeno Gantner",
                        "slug": "Zeno-Gantner",
                        "structuredName": {
                            "firstName": "Zeno",
                            "lastName": "Gantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeno Gantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 119
                            }
                        ],
                        "text": "Among all the baseline methods, sequential methods (e.g., FPMC and GRU4Rec+) outperforms non-sequential methods (e.g., BPR-MF and NCF) on all datasets consistently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 14
                            }
                        ],
                        "text": "Compared with BPR-MF, the main improvement of FPMC is that it models users\u2019 historical records in a sequential way."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "\u2022 BPR-MF [39]: It optimizes the matrix factorization with implicit feedback using a pairwise ranking loss."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "For BPR-MF and FPMC, we implement them using TensorFlow."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10795036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db16e908246f32b60a6e0a8e27093aa145fbb1ed",
            "isKey": true,
            "numCitedBy": 3865,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion."
            },
            "slug": "BPR:-Bayesian-Personalized-Ranking-from-Implicit-Rendle-Freudenthaler",
            "title": {
                "fragments": [],
                "text": "BPR: Bayesian Personalized Ranking from Implicit Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem and provides a generic learning algorithm for optimizing models with respect to B PR-Opt."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507883"
                        ],
                        "name": "Bal\u00e1zs Hidasi",
                        "slug": "Bal\u00e1zs-Hidasi",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Hidasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Hidasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713164"
                        ],
                        "name": "Alexandros Karatzoglou",
                        "slug": "Alexandros-Karatzoglou",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Karatzoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandros Karatzoglou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7, 14, 15, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 175
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": ", BPR-max and TOP1-max) and an improved sampling strategy [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "\u2022 GRU4Rec+ [14]: It is an improved version of GRU4Rec with a new class of loss functions and sampling strategy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1159769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dd7038128e3a1ba49f0224ac711166c8dc36d3d",
            "isKey": true,
            "numCitedBy": 440,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "RNNs have been shown to be excellent models for sequential data and in particular for data that is generated by users in an session-based manner. The use of RNNs provides impressive performance benefits over classical methods in session-based recommendations. In this work we introduce novel ranking loss functions tailored to RNNs in the recommendation setting. The improved performance of these losses over alternatives, along with further tricks and refinements described in this work, allow for an overall improvement of up to 35% in terms of MRR and Recall@20 over previous session-based RNN solutions and up to 53% over classical collaborative filtering approaches. Unlike data augmentation-based improvements, our method does not increase training times significantly. We further demonstrate the performance gain of the RNN over baselines in an online A/B test."
            },
            "slug": "Recurrent-Neural-Networks-with-Top-k-Gains-for-Hidasi-Karatzoglou",
            "title": {
                "fragments": [],
                "text": "Recurrent Neural Networks with Top-k Gains for Session-based Recommendations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces novel ranking loss functions tailored to RNNs in the recommendation setting that allow for an overall improvement of up to 35% in terms of MRR and Recall@20 over previous session-based RNN solutions and up to 53% over classical collaborative filtering approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 56
                            }
                        ],
                        "text": "Another line of work is item-based neighborhood methods [20, 25, 31, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207168823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf6f83fcce274606bf0264c59d1c78a30c9c9d18",
            "isKey": false,
            "numCitedBy": 3612,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task."
            },
            "slug": "Factorization-meets-the-neighborhood:-a-filtering-Koren",
            "title": {
                "fragments": [],
                "text": "Factorization meets the neighborhood: a multifaceted collaborative filtering model"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model and a new evaluation metric is suggested, which highlights the differences among methods, based on their performance at a top-K recommendation task."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652248"
                        ],
                        "name": "J. Lember",
                        "slug": "J.-Lember",
                        "structuredName": {
                            "firstName": "J\u00fcri",
                            "lastName": "Lember",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lember"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2005362"
                        ],
                        "name": "A. Koloydenko",
                        "slug": "A.-Koloydenko",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Koloydenko",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Koloydenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7188139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "773386a738c976a444b365b2d6837312b20724a3",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated by the unceasing interest in hidden Markov models (HMMs), this paper reexamines hidden path inference in these models, using primarily a risk-based framework. While the most common maximum a posteriori (MAP), or Viterbi, path estimator and the minimum error, or Posterior Decoder (PD) have long been around, other path estimators, or decoders, have been either only hinted at or applied more recently and in dedicated applications generally unfamiliar to the statistical learning community. Over a decade ago, however, a family of algorithmically defined decoders aiming to hybridize the two standard ones was proposed elsewhere. The present paper gives a careful analysis of this hybridization approach, identifies several problems and issues with it and other previously proposed approaches, and proposes practical resolutions of those. Furthermore, simple modifications of the classical criteria for hidden path recognition are shown to lead to a new class of decoders. Dynamic programming algorithms to compute these decoders in the usual forward-backward manner are presented. A particularly interesting subclass of such estimators can be also viewed as hybrids of the MAP and PD estimators. Similar to previously proposed MAP-PD hybrids, the new class is parameterized by a small number of tunable parameters. Unlike their algorithmic predecessors, the new risk-based decoders are more clearly interpretable, and, most importantly, work \"out-of-the box\" in practice, which is demonstrated on some real bioinformatics tasks and data. Some further generalizations and applications are discussed in the conclusion."
            },
            "slug": "Bridging-Viterbi-and-posterior-decoding:-a-risk-to-Lember-Koloydenko",
            "title": {
                "fragments": [],
                "text": "Bridging Viterbi and posterior decoding: a generalized risk approach to hidden path inference based on hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A careful analysis of a family of algorithmically defined decoders aiming to hybridize the two standard ones was proposed elsewhere, and several problems and issues with it and other previously proposed approaches are identified, and practical resolutions of those are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 222
                            }
                        ],
                        "text": "Among various CF methods, Matrix Factorization (MF) is the most popular one, which projects users and items into a shared vector space and estimate a user\u2019s preference on an item by the inner product between their vectors [26, 27, 41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 467086,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e19971e7d100386b9b4cf4ea1a0782b62fe036e5",
            "isKey": false,
            "numCitedBy": 3875,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many existing approaches to collaborative filtering can neither handle very large datasets nor easily deal with users who have very few ratings. In this paper we present the Probabilistic Matrix Factorization (PMF) model which scales linearly with the number of observations and, more importantly, performs well on the large, sparse, and very imbalanced Netflix dataset. We further extend the PMF model to include an adaptive prior on the model parameters and show how the model capacity can be controlled automatically. Finally, we introduce a constrained version of the PMF model that is based on the assumption that users who have rated similar sets of movies are likely to have similar preferences. The resulting model is able to generalize considerably better for users with very few ratings. When the predictions of multiple PMF models are linearly combined with the predictions of Restricted Boltzmann Machines models, we achieve an error rate of 0.8861, that is nearly 7% better than the score of Netflix's own system."
            },
            "slug": "Probabilistic-Matrix-Factorization-Salakhutdinov-Mnih",
            "title": {
                "fragments": [],
                "text": "Probabilistic Matrix Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Probabilistic Matrix Factorization (PMF) model is presented, which scales linearly with the number of observations and performs well on the large, sparse, and very imbalanced Netflix dataset and is extended to include an adaptive prior on the model parameters."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116951322"
                        ],
                        "name": "Shoujin Wang",
                        "slug": "Shoujin-Wang",
                        "structuredName": {
                            "firstName": "Shoujin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shoujin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159009"
                        ],
                        "name": "Liang Hu",
                        "slug": "Liang-Hu",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148761004"
                        ],
                        "name": "Longbing Cao",
                        "slug": "Longbing-Cao",
                        "structuredName": {
                            "firstName": "Longbing",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longbing Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809350"
                        ],
                        "name": "Xiaoshui Huang",
                        "slug": "Xiaoshui-Huang",
                        "structuredName": {
                            "firstName": "Xiaoshui",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoshui Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1862782"
                        ],
                        "name": "Defu Lian",
                        "slug": "Defu-Lian",
                        "structuredName": {
                            "firstName": "Defu",
                            "lastName": "Lian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Defu Lian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 106
                            }
                        ],
                        "text": "In fact, the choices of items in a user\u2019s historical interactions may not follow a rigid order assumption [18, 54] due to various unobservable external factors [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19100030,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bc23b04c7681cb2a10f94b383accaf93d9fda51",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n To recommend the next item to a user in a transactional context is practical yet challenging in applications such as marketing campaigns. Transactional context refers to the items that are observable in a transaction. Most existing transaction based recommender systems (TBRSs) make recommendations by mainly considering recently occurring items instead of all the ones observed in the current context. Moreover, they often assume a rigid order between items within a transaction, which is not always practical. More importantly, a long transaction often contains many items irreverent to the next choice, which tends to overwhelm the influence of a few truly relevant ones. Therefore, we posit that a good TBRS should not only consider all the observed items in the current transaction but also weight them with different relevance to build an attentive context that outputs the proper next item with a high probability. To this end, we design an effective attention based transaction embedding model (ATEM) for context embedding to weight each observed item in a transaction without assuming order. The empirical study on real-world transaction datasets proves that ATEM significantly outperforms the state-of-the-art methods in terms of both accuracy and novelty.\n \n"
            },
            "slug": "Attention-Based-Transactional-Context-Embedding-for-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "Attention-Based Transactional Context Embedding for Next-Item Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An effective attention based transaction embedding model (ATEM) for context embedding to weight each observed item in a transaction without assuming order is designed."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s been revolutionizing the recommendation systems dramatically. The early pioneer work is a two-layer Restricted Boltzmann Machines (RBM) for collaborative filtering, proposed by Salakhutdinov et al. [42] in Netflix Prize2. One line of deep learning based recommendation algorithms seeks to use neural networks to learn distributed item representations from auxiliary information, e.g., text [23, 53], im"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7285098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1626c940a64ad96a7ed53d7d6c0df63c6696956b",
            "isKey": false,
            "numCitedBy": 1880,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system."
            },
            "slug": "Restricted-Boltzmann-machines-for-collaborative-Salakhutdinov-Mnih",
            "title": {
                "fragments": [],
                "text": "Restricted Boltzmann machines for collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper shows how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies, and demonstrates that RBM's can be successfully applied to the Netflix data set."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072136504"
                        ],
                        "name": "Paul Covington",
                        "slug": "Paul-Covington",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Covington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Covington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150138001"
                        ],
                        "name": "Jay K. Adams",
                        "slug": "Jay-K.-Adams",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Adams",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay K. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3138425"
                        ],
                        "name": "Emre Sargin",
                        "slug": "Emre-Sargin",
                        "structuredName": {
                            "firstName": "Emre",
                            "lastName": "Sargin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emre Sargin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "In fact, the choices of items in a user\u2019s historical interactions may not follow a rigid order assumption [18, 54] due to various unobservable external factors [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207240067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e383584ccbc8b920eaf3cfce3869da646ff5550",
            "isKey": false,
            "numCitedBy": 1877,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact."
            },
            "slug": "Deep-Neural-Networks-for-YouTube-Recommendations-Covington-Adams",
            "title": {
                "fragments": [],
                "text": "Deep Neural Networks for YouTube Recommendations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper details a deep candidate generation model and then describes a separate deep ranking model and provides practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144958935"
                        ],
                        "name": "Karthik Narasimhan",
                        "slug": "Karthik-Narasimhan",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Narasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Narasimhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "In this work, following OpenAI GPT [37] and BERT [6], we use a smoother GELU [13] activation rather than the standard ReLu activation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49313245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "isKey": false,
            "numCitedBy": 3958,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI)."
            },
            "slug": "Improving-Language-Understanding-by-Generative-Radford-Narasimhan",
            "title": {
                "fragments": [],
                "text": "Improving Language Understanding by Generative Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2893721"
                        ],
                        "name": "Suhang Wang",
                        "slug": "Suhang-Wang",
                        "structuredName": {
                            "firstName": "Suhang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suhang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143444619"
                        ],
                        "name": "Yilin Wang",
                        "slug": "Yilin-Wang",
                        "structuredName": {
                            "firstName": "Yilin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yilin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736632"
                        ],
                        "name": "Jiliang Tang",
                        "slug": "Jiliang-Tang",
                        "structuredName": {
                            "firstName": "Jiliang",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiliang Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800151"
                        ],
                        "name": "Kai Shu",
                        "slug": "Kai-Shu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Shu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Shu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601380"
                        ],
                        "name": "Suhas Ranganath",
                        "slug": "Suhas-Ranganath",
                        "structuredName": {
                            "firstName": "Suhas",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suhas Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38746648"
                        ],
                        "name": "Huan Liu",
                        "slug": "Huan-Liu",
                        "structuredName": {
                            "firstName": "Huan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": ", text [23, 53], images [21, 55], and acoustic features [51] into CF models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14152303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10e1fb949e10d5fe99d5f1b32bb48d625149bce8",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid growth of Location-based Social Networks (LBSNs) provides a vast amount of check-in data, which facilitates the study of point-of-interest (POI) recommendation. The majority of the existing POI recommendation methods focus on four aspects, i.e., temporal patterns, geographical influence, social correlations and textual content indications. For example, user's visits to locations have temporal patterns and users are likely to visit POIs near them. In real-world LBSNs such as Instagram, users can upload photos associating with locations. Photos not only reflect users' interests but also provide informative descriptions about locations. For example, a user who posts many architecture photos is more likely to visit famous landmarks; while a user posts lots of images about food has more incentive to visit restaurants. Thus, images have potentials to improve the performance of POI recommendation. However, little work exists for POI recommendation by exploiting images. In this paper, we study the problem of enhancing POI recommendation with visual contents. In particular, we propose a new framework Visual Content Enhanced POI recommendation (VPOI), which incorporates visual contents for POI recommendations. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework."
            },
            "slug": "What-Your-Images-Reveal:-Exploiting-Visual-Contents-Wang-Wang",
            "title": {
                "fragments": [],
                "text": "What Your Images Reveal: Exploiting Visual Contents for Point-of-Interest Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new framework Visual Content Enhanced POI recommendation (VPOI), which incorporates visual contents for POI recommendations, is proposed, which demonstrates the effectiveness of the proposed framework on real-world datasets."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35660011"
                        ],
                        "name": "Julian McAuley",
                        "slug": "Julian-McAuley",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "McAuley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian McAuley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47611785"
                        ],
                        "name": "C. Targett",
                        "slug": "C.-Targett",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Targett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Targett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177281"
                        ],
                        "name": "Qinfeng Shi",
                        "slug": "Qinfeng-Shi",
                        "structuredName": {
                            "firstName": "Qinfeng",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qinfeng Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5546141"
                        ],
                        "name": "A. V. Hengel",
                        "slug": "A.-V.-Hengel",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Hengel",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. V. Hengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "del on four real-world representative datasets which vary significantly in domains and sparsity. \u2022Amazon Beauty4: This is a series of product review datasets crawled from Amazon.com by McAuley et al. [34]. They split the data into separate datasets according to the toplevel product categories on Amazon. In this work, we adopt the \u201cBeauty\u201d category. \u2022Steam5: This is a dataset collected from Steam, a la"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1012652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fab4d19ed77dad7c437d885eceb8aa65fae5a783",
            "isKey": false,
            "numCitedBy": 1476,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans inevitably develop a sense of the relationships between objects, some of which are based on their appearance. Some pairs of objects might be seen as being alternatives to each other (such as two pairs of jeans), while others may be seen as being complementary (such as a pair of jeans and a matching shirt). This information guides many of the choices that people make, from buying clothes to their interactions with each other. We seek here to model this human sense of the relationships between objects based on their appearance. Our approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within. We cast this as a network inference problem defined on graphs of related images, and provide a large-scale dataset for the training and evaluation of the same. The system we develop is capable of recommending which clothes and accessories will go well together (and which will not), amongst a host of other applications."
            },
            "slug": "Image-Based-Recommendations-on-Styles-and-McAuley-Targett",
            "title": {
                "fragments": [],
                "text": "Image-Based Recommendations on Styles and Substitutes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach is not based on fine-grained modeling of user annotations but rather on capturing the largest dataset possible and developing a scalable method for uncovering human notions of the visual relationships within."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093760224"
                        ],
                        "name": "Santosh Kabbur",
                        "slug": "Santosh-Kabbur",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Kabbur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santosh Kabbur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150344490"
                        ],
                        "name": "Xia Ning",
                        "slug": "Xia-Ning",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Ning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Ning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50877490"
                        ],
                        "name": "G. Karypis",
                        "slug": "G.-Karypis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Karypis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Karypis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 56
                            }
                        ],
                        "text": "Another line of work is item-based neighborhood methods [20, 25, 31, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207204749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c0ff60e9d39c203929457d1ac3f840f8c8e9619",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The effectiveness of existing top-N recommendation methods decreases as the sparsity of the datasets increases. To alleviate this problem, we present an item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices. These matrices are learned using a structural equation modeling approach, wherein the value being estimated is not used for its own estimation. A comprehensive set of experiments on multiple datasets at three different sparsity levels indicate that the proposed methods can handle sparse datasets effectively and outperforms other state-of-the-art top-N recommendation methods. The experimental results also show that the relative performance gains compared to competing methods increase as the data gets sparser."
            },
            "slug": "FISM:-factored-item-similarity-models-for-top-N-Kabbur-Ning",
            "title": {
                "fragments": [],
                "text": "FISM: factored item similarity models for top-N recommender systems"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An item-based method for generating top-N recommendations that learns the item-item similarity matrix as the product of two low dimensional latent factor matrices using a structural equation modeling approach."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "We train the model using Adam [24] with learning rate of 1e-4, \u03b21 = 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "We train the model using Adam [24] with learning rate of 1e-4, \u03b21 = 0.9, \u03b22 = 0.999, \u21132 weight decay of 0.01, and linear decay of the learning rate."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 98441,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2786820"
                        ],
                        "name": "Gongbo Tang",
                        "slug": "Gongbo-Tang",
                        "structuredName": {
                            "firstName": "Gongbo",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gongbo Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144529826"
                        ],
                        "name": "Mathias M\u00fcller",
                        "slug": "Mathias-M\u00fcller",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40659617"
                        ],
                        "name": "Annette Rios Gonzales",
                        "slug": "Annette-Rios-Gonzales",
                        "structuredName": {
                            "firstName": "Annette",
                            "lastName": "Rios Gonzales",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Annette Rios Gonzales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082372"
                        ],
                        "name": "Rico Sennrich",
                        "slug": "Rico-Sennrich",
                        "structuredName": {
                            "firstName": "Rico",
                            "lastName": "Sennrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rico Sennrich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "This phenomenon is consistent with the empirical result in [48] that large h is essential for capturing long distance dependencies with multi-head self-attention."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 52100282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in neural machine translation. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks: subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2) self-attentional networks perform distinctly better than RNNs and CNNs on word sense disambiguation."
            },
            "slug": "Why-Self-Attention-A-Targeted-Evaluation-of-Neural-Tang-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2)Self-att attentional networks perform distinctly better than RNN's and CNN's on word sense disambiguation."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 55668,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "m the same matrix Hl with different learned projection matrices as in Equation 1. The temperature p d/h is introduced to produce a softer attention distribution for avoiding extremely small gradients [16, 52]. Position-wise Feed-Forward Network. As described above, the self-attention sub-layer is mainly based on linear projections. To endow the model with nonlinearity and interactions between different di"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7200347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "isKey": false,
            "numCitedBy": 9675,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."
            },
            "slug": "Distilling-the-Knowledge-in-a-Neural-Network-Hinton-Vinyals",
            "title": {
                "fragments": [],
                "text": "Distilling the Knowledge in a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows that it can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model and introduces a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719532"
                        ],
                        "name": "Guy Shani",
                        "slug": "Guy-Shani",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Shani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guy Shani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680506"
                        ],
                        "name": "R. Brafman",
                        "slug": "R.-Brafman",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Brafman",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brafman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[45] formalized recommendation generation as a sequential optimization problem and employ Markov Decision Processes (MDPs) to address it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 875571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b739b106b585c963cca70a10f38e564cc9d98cc",
            "isKey": false,
            "numCitedBy": 748,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Typical Recommender systems adopt a static view of the recommendation process and treat it as a prediction problem. We argue that it is more appropriate to view the problem of generating recommendations as a sequential decision problem and, consequently, that Markov decision processes (MDP) provide a more appropriate model for Recommender systems. MDPs introduce two benefits: they take into account the long-term effects of each recommendation, and they take into account the expected value of each recommendation. To succeed in practice, an MDP-based Recommender system must employ a strong initial model; and the bulk of this paper is concerned with the generation of such a model. In particular, we suggest the use of an n-gram predictive model for generating the initial MDP. Our n-gram model induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models. We describe our predictive model in detail and evaluate its performance on real data. In addition, we show how the model can be used in an MDP-based Recommender system."
            },
            "slug": "An-MDP-Based-Recommender-System-Shani-Heckerman",
            "title": {
                "fragments": [],
                "text": "An MDP-Based Recommender System"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The use of an n-gram predictive model is suggested for generating the initial MDP, which induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095747"
                        ],
                        "name": "S. Sedhain",
                        "slug": "S.-Sedhain",
                        "structuredName": {
                            "firstName": "Suvash",
                            "lastName": "Sedhain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sedhain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2844480"
                        ],
                        "name": "A. Menon",
                        "slug": "A.-Menon",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Menon",
                            "middleNames": [
                                "Krishna"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Menon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732536"
                        ],
                        "name": "S. Sanner",
                        "slug": "S.-Sanner",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Sanner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sanner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33650938"
                        ],
                        "name": "Lexing Xie",
                        "slug": "Lexing-Xie",
                        "structuredName": {
                            "firstName": "Lexing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lexing Xie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "For example, Neural Collaborative Filtering (NCF) [12] estimates user preferences via Multi-Layer Perceptions (MLP) instead of inner product, while AutoRec [44] and CDAE [57] predict users\u2019 ratings using Auto-encoder framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16274986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f0e32170ebd1c338442049c0ef8606ab482af5e",
            "isKey": false,
            "numCitedBy": 799,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes AutoRec, a novel autoencoder framework for collaborative filtering (CF). Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets."
            },
            "slug": "AutoRec:-Autoencoders-Meet-Collaborative-Filtering-Sedhain-Menon",
            "title": {
                "fragments": [],
                "text": "AutoRec: Autoencoders Meet Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Empirically, AutoRec's compact and efficiently trainable model outperforms state-of-the-art CF techniques (biased matrix factorization, RBM-CF and LLORMA) on the Movielens and Netflix datasets."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076086"
                        ],
                        "name": "Fethi Bougares",
                        "slug": "Fethi-Bougares",
                        "structuredName": {
                            "firstName": "Fethi",
                            "lastName": "Bougares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fethi Bougares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "7https://github.com/hexiangnan/neural_collaborative_filtering 8https://github.com/hidasib/GRU4Rec 9https://github.com/graytowne/caser_pytorch 10https://github.com/kang205/SASRec\nWe implement BERT4Rec11 with TensorFlow."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "For example, Li et al. [28] incorporate an attention mechanism into GRU to capture both the user\u2019s sequential behavior and main purpose in session-based recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 240
                            }
                        ],
                        "text": "The basic idea of these methods is to encode user\u2019s previous records into a vector (i.e., representation of user\u2019s preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [59], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i.e., BPR-max and TOP1-max) and an improved sampling strategy [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "For NCF7, GRU4Rec8, GRU4Rec+8, Caser9, and SASRec10, we use code provided by the corresponding authors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Furthermore, SASRec performs distinctly better than GRU4Rec and GRU4Rec+, suggesting that self-attention mechanism is a more powerful tool for sequential recommendation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "\u2022 GRU4Rec+ [14]: It is an improved version of GRU4Rec with a new class of loss functions and sampling strategy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Among all the baseline methods, sequential methods (e.g., FPMC and GRU4Rec+) outperforms non-sequential methods (e.g., BPR-MF and NCF) on all datasets consistently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Recently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7, 14, 15, 28, 36, 56, 59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "This causes Caser to perform worse than GRU4Rec+ and SASRec, especially on sparse datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "\u2022 FPMC [40]: It captures users\u2019 general taste as well as their sequential behaviors by combing MF with first-order MCs. \u2022 GRU4Rec [15]: It uses GRU with ranking based loss to model user sequences for session based recommendation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5590763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "isKey": true,
            "numCitedBy": 16170,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "slug": "Learning-Phrase-Representations-using-RNN-for-Cho-Merrienboer",
            "title": {
                "fragments": [],
                "text": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Qualitatively, the proposed RNN Encoder\u2010Decoder model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Moreover, we also apply dropout [47] to the output of each sub-layer, before it is normalized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 29832,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "Therefore, we employ a residual connection [9] around each of the two sublayers as in Figure 1a, followed by layer normalization [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 106571,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113591957"
                        ],
                        "name": "Robert M. Bell",
                        "slug": "Robert-M.-Bell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Bell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 146
                            }
                        ],
                        "text": "Early works on recommendation systems typically use Collaborative Filtering (CF) to model users\u2019 preferences based on their interaction histories [26, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 222
                            }
                        ],
                        "text": "Among various CF methods, Matrix Factorization (MF) is the most popular one, which projects users and items into a shared vector space and estimate a user\u2019s preference on an item by the inner product between their vectors [26, 27, 41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14698210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "703784803713e5716b0ec57c5262974adc30e275",
            "isKey": false,
            "numCitedBy": 1092,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The collaborative filtering (CF) approach to recommenders has recently enjoyed much interest and progress. The fact that it played a central role within the recently completed Netflix competition has contributed to its popularity. This chapter surveys the recent progress in the field. Matrix factorization techniques, which became a first choice for implementing CF, are described together with recent innovations. We also describe several extensions that bring competitive accuracy into neighborhood methods, which used to dominate the field. The chapter demonstrates how to utilize temporal models and implicit feedback to extend models accuracy. In passing, we include detailed descriptions of some the central methods developed for tackling the challenge of the Netflix Prize competition."
            },
            "slug": "Advances-in-Collaborative-Filtering-Koren-Bell",
            "title": {
                "fragments": [],
                "text": "Advances in Collaborative Filtering"
            },
            "venue": {
                "fragments": [],
                "text": "Recommender Systems Handbook"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Similar to CBOW, Skip-Gram (SG) [36] can also be seen as a simplified case of BERT4Rec following the similar reduction operations."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 27216,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": ", machine translation [2, 52] and text classification [58]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 20525,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146592"
                        ],
                        "name": "Zhouhan Lin",
                        "slug": "Zhouhan-Lin",
                        "structuredName": {
                            "firstName": "Zhouhan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhouhan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2521552"
                        ],
                        "name": "Minwei Feng",
                        "slug": "Minwei-Feng",
                        "structuredName": {
                            "firstName": "Minwei",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minwei Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790831"
                        ],
                        "name": "C. D. Santos",
                        "slug": "C.-D.-Santos",
                        "structuredName": {
                            "firstName": "C\u00edcero",
                            "lastName": "Santos",
                            "middleNames": [
                                "Nogueira",
                                "dos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Santos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482533"
                        ],
                        "name": "Mo Yu",
                        "slug": "Mo-Yu",
                        "structuredName": {
                            "firstName": "Mo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144028698"
                        ],
                        "name": "Bing Xiang",
                        "slug": "Bing-Xiang",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Xiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Xiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145218984"
                        ],
                        "name": "Bowen Zhou",
                        "slug": "Bowen-Zhou",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 155
                            }
                        ],
                        "text": "Recently, there is a rising enthusiasm for applying purely attention-based neural networks to model sequential data for their effectiveness and efficiency [30, 32, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15280949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204a4a70428f3938d2c538a4d74c7ae0416306d8",
            "isKey": false,
            "numCitedBy": 1604,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks."
            },
            "slug": "A-Structured-Self-attentive-Sentence-Embedding-Lin-Feng",
            "title": {
                "fragments": [],
                "text": "A Structured Self-attentive Sentence Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new model for extracting an interpretable sentence embedding by introducing self-attention is proposed, which uses a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30182834"
                        ],
                        "name": "G. Linden",
                        "slug": "G.-Linden",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Linden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Linden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157122032"
                        ],
                        "name": "Brent Smith",
                        "slug": "Brent-Smith",
                        "structuredName": {
                            "firstName": "Brent",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brent Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073999382"
                        ],
                        "name": "J. York",
                        "slug": "J.-York",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "York",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. York"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 56
                            }
                        ],
                        "text": "Another line of work is item-based neighborhood methods [20, 25, 31, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14604122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da8b0378174bc25ed174be36a1c725787b81854d",
            "isKey": false,
            "numCitedBy": 5536,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommendation algorithms are best known for their use on e-commerce Web sites, where they use input about a customer's interests to generate a list of recommended items. Many applications use only the items that customers purchase and explicitly rate to represent their interests, but they can also use other attributes, including items viewed, demographic data, subject interests, and favorite artists. At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. There are three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods. Here, we compare these methods with our algorithm, which we call item-to-item collaborative filtering. Unlike traditional collaborative filtering, our algorithm's online computation scales independently of the number of customers and number of items in the product catalog. Our algorithm produces recommendations in real-time, scales to massive data sets, and generates high quality recommendations."
            },
            "slug": "Amazon.com-Recommendations:-Item-to-Item-Filtering-Linden-Smith",
            "title": {
                "fragments": [],
                "text": "Amazon.com Recommendations: Item-to-Item Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work compares three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods, and their algorithm, which is called item-to-item collaborative filtering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Internet Comput."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8387085"
                        ],
                        "name": "Zichao Yang",
                        "slug": "Zichao-Yang",
                        "structuredName": {
                            "firstName": "Zichao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zichao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022168"
                        ],
                        "name": "Diyi Yang",
                        "slug": "Diyi-Yang",
                        "structuredName": {
                            "firstName": "Diyi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diyi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": ", machine translation [2, 52] and text classification [58]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6857205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "455afd748e8834ef521e4b67c7c056d3c33429e2",
            "isKey": false,
            "numCitedBy": 3436,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences."
            },
            "slug": "Hierarchical-Attention-Networks-for-Document-Yang-Yang",
            "title": {
                "fragments": [],
                "text": "Hierarchical Attention Networks for Document Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35025299"
                        ],
                        "name": "Peter J. Liu",
                        "slug": "Peter-J.-Liu",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Liu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter J. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144413479"
                        ],
                        "name": "Mohammad Saleh",
                        "slug": "Mohammad-Saleh",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Saleh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Saleh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38627717"
                        ],
                        "name": "Etienne Pot",
                        "slug": "Etienne-Pot",
                        "structuredName": {
                            "firstName": "Etienne",
                            "lastName": "Pot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Etienne Pot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065067542"
                        ],
                        "name": "Ben Goodrich",
                        "slug": "Ben-Goodrich",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Goodrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Goodrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35474601"
                        ],
                        "name": "Ryan Sepassi",
                        "slug": "Ryan-Sepassi",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Sepassi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Sepassi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 155
                            }
                        ],
                        "text": "Recently, there is a rising enthusiasm for applying purely attention-based neural networks to model sequential data for their effectiveness and efficiency [30, 32, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3608234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7570afa31c68e24fce1342b7d67c591787219bc1",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that generating English Wikipedia articles can be approached as a multi- document summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder- decoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations."
            },
            "slug": "Generating-Wikipedia-by-Summarizing-Long-Sequences-Liu-Saleh",
            "title": {
                "fragments": [],
                "text": "Generating Wikipedia by Summarizing Long Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "It is shown that generating English Wikipedia articles can be approached as a multi- document summarization of source documents and a neural abstractive model is introduced, which can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32646084"
                        ],
                        "name": "B. Sarwar",
                        "slug": "B.-Sarwar",
                        "structuredName": {
                            "firstName": "Badrul",
                            "lastName": "Sarwar",
                            "middleNames": [
                                "Munir"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sarwar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50877490"
                        ],
                        "name": "G. Karypis",
                        "slug": "G.-Karypis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Karypis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Karypis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2478310"
                        ],
                        "name": "J. Konstan",
                        "slug": "J.-Konstan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Konstan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Konstan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579342"
                        ],
                        "name": "J. Riedl",
                        "slug": "J.-Riedl",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Riedl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Riedl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 56
                            }
                        ],
                        "text": "Another line of work is item-based neighborhood methods [20, 25, 31, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 146
                            }
                        ],
                        "text": "Early works on recommendation systems typically use Collaborative Filtering (CF) to model users\u2019 preferences based on their interaction histories [26, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8047550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f82c52452c7de8cd6472202c1be2cce9fbcb8dda",
            "isKey": false,
            "numCitedBy": 8423,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems apply knowledge discovery techniques to the problem of making personalized recommendations for information, products or services during a live interaction. These systems, especially the k-nearest neighbor collaborative ltering based ones, are achieving widespread success on the Web. The tremendous growth in the amount of available information and the number of visitors to Web sites in recent years poses some key challenges for recommender systems. These are: producing high quality recommendations, performing many recommendations per second for millions of users and items and achieving high coverage in the face of data sparsity. In traditional collaborative ltering systems the amount of work increases with the number of participants in the system. New recommender system technologies are needed that can quickly produce high quality recommendations, even for very large-scale problems. To address these issues we have explored item-based collaborative ltering techniques. Item-based techniques rst analyze the user-item matrix to identify relationships between di erent items, and then use these relationships to indirectly compute recommendations for users. In this paper we analyze di erent item-based recommendation generation algorithms. We look into di erent techniques for computing item-item similarities (e.g., item-item correlation vs. cosine similarities between item vectors) and di erent techniques for obtaining recommendations from them (e.g., weighted sum vs. regression model). Finally, we experimentally evaluate our results and compare them to the basic k-nearest neighbor approach. Our experiments suggest that item-based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms."
            },
            "slug": "Item-based-collaborative-filtering-recommendation-Sarwar-Karypis",
            "title": {
                "fragments": [],
                "text": "Item-based collaborative filtering recommendation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper analyzes item-based collaborative ltering techniques and suggests that item- based algorithms provide dramatically better performance than user-based algorithms, while at the same time providing better quality than the best available userbased algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51131802"
                        ],
                        "name": "J. Kiros",
                        "slug": "J.-Kiros",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Kiros",
                            "middleNames": [
                                "Ryan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8236317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fb4e3d45bb098e27e0071448b6152217bd35a5",
            "isKey": false,
            "numCitedBy": 3496,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques."
            },
            "slug": "Layer-Normalization-Ba-Kiros",
            "title": {
                "fragments": [],
                "text": "Layer Normalization"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145192090"
                        ],
                        "name": "F. M. Harper",
                        "slug": "F.-M.-Harper",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Harper",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. M. Harper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2478310"
                        ],
                        "name": "J. Konstan",
                        "slug": "J.-Konstan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Konstan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Konstan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "\u2022 MovieLens [8]: This is a popular benchmark dataset for evaluating recommendation algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16619709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "276ebc620a8976026bd2d03582b9ecfa3738d43c",
            "isKey": false,
            "numCitedBy": 2909,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research."
            },
            "slug": "The-MovieLens-Datasets:-History-and-Context-Harper-Konstan",
            "title": {
                "fragments": [],
                "text": "The MovieLens Datasets: History and Context"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The history of MovieLens and the MovieLens datasets is documents, including a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization, and best practices and limitations of using the Movie Lens datasets in new research are documented."
            },
            "venue": {
                "fragments": [],
                "text": "TIIS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Another very similar work is Continuous Bag-ofWords (CBOW) and Skip-Gram (SG) [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": false,
            "numCitedBy": 23262,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422872"
                        ],
                        "name": "Dan Hendrycks",
                        "slug": "Dan-Hendrycks",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Hendrycks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Hendrycks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In this work, following OpenAI GPT [37] and BERT [6], we use a smoother GELU [13] activation rather than the standard ReLu activation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "Assuming that we mask the item vt at time step t , we then predict the masked items vt base on hLt as shown in Figure 1b. Specifically, we apply a two-layer feed-forward network with GELU activation in between to produce an output distribution over target items:\nP(v) = softmax ( GELU(hLtW P + bP )E\u22a4 + bO ) (7)\nwhereW P is the learnable projection matrix, bP , and bO are bias terms, E \u2208 R |V |\u00d7d is the embedding matrix for the item setV ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "It consists of two affine transformations with a Gaussian Error Linear Unit (GELU) activation in between:\nPFFN(H l ) = [ FFN(hl1)\u22a4; . . . ; FFN(hlt )\u22a4 ]\u22a4 FFN(x) = GELU ( xW (1) + b(1) ) W (2) + b(2)\nGELU(x) = x\u03a6(x) (3)\nwhere \u03a6(x) is the cumulative distribution function of the standard gaussian distribution,W (1) \u2208 Rd\u00d74d ,W (2) \u2208 R4d\u00d7d , b(1) \u2208 R4d and b(2) \u2208 Rd are learnable parameters and shared across all positions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2359786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4361e64f2d12d63476fdc88faf72a0f70d9a2ffb",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic regularizer which randomly applies the identity or zero map, combining the intuitions of dropout and zoneout while respecting neuron values. This connection suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks."
            },
            "slug": "Bridging-Nonlinearities-and-Stochastic-Regularizers-Hendrycks-Gimpel",
            "title": {
                "fragments": [],
                "text": "Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and finding performance improvements across all tasks suggests a new probabilistic understanding of nonlinearities."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113591957"
                        ],
                        "name": "Robert M. Bell",
                        "slug": "Robert-M.-Bell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146362"
                        ],
                        "name": "C. Volinsky",
                        "slug": "C.-Volinsky",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Volinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Volinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 222
                            }
                        ],
                        "text": "Among various CF methods, Matrix Factorization (MF) is the most popular one, which projects users and items into a shared vector space and estimate a user\u2019s preference on an item by the inner product between their vectors [26, 27, 41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58370896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4bbcc842f22547eaf5884251eaa68251895dccb",
            "isKey": false,
            "numCitedBy": 7016,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels."
            },
            "slug": "Matrix-Factorization-Techniques-for-Recommender-Koren-Bell",
            "title": {
                "fragments": [],
                "text": "Matrix Factorization Techniques for Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47324198"
                        ],
                        "name": "W. L. Taylor",
                        "slug": "W.-L.-Taylor",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Taylor",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. L. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "In order to efficiently train our proposed model, we apply a new objective: Cloze task [50] (also known as \u201cMasked Language Model\u201d in [6]) to sequential recommendation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "To tackle this problem, we introduce the Cloze task [6, 50] to take the place of the objective in unidirectional models (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206666846,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd",
            "isKey": false,
            "numCitedBy": 2106,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Here is the first comprehensive statement of a research method and its theory which were introduced briefly during a workshop at the 1953 AEJ convention. Included are findings from three pilot studies and two experiments in which \u201ccloze procedure\u201d results are compared with those of two readability formulas."
            },
            "slug": "\u201cCloze-Procedure\u201d:-A-New-Tool-for-Measuring-Taylor",
            "title": {
                "fragments": [],
                "text": "\u201cCloze Procedure\u201d: A New Tool for Measuring Readability"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This is the first comprehensive statement of a research method and its theory and findings from three pilot studies and two experiments in which \u201ccloze procedure\u201d results are compared with those of two readability formulas."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49387725"
                        ],
                        "name": "Jeff Wu",
                        "slug": "Jeff-Wu",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48422824"
                        ],
                        "name": "Rewon Child",
                        "slug": "Rewon-Child",
                        "structuredName": {
                            "firstName": "Rewon",
                            "lastName": "Child",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rewon Child"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150970919"
                        ],
                        "name": "D. Luan",
                        "slug": "D.-Luan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2698777"
                        ],
                        "name": "Dario Amodei",
                        "slug": "Dario-Amodei",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Amodei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dario Amodei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 160025533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "isKey": false,
            "numCitedBy": 7073,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations."
            },
            "slug": "Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu",
            "title": {
                "fragments": [],
                "text": "Language Models are Unsupervised Multitask Learners"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText, suggesting a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71003878"
                        ],
                        "name": "Jian Li",
                        "slug": "Jian-Li",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909321"
                        ],
                        "name": "Zhaopeng Tu",
                        "slug": "Zhaopeng-Tu",
                        "structuredName": {
                            "firstName": "Zhaopeng",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaopeng Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21299583"
                        ],
                        "name": "Baosong Yang",
                        "slug": "Baosong-Yang",
                        "structuredName": {
                            "firstName": "Baosong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baosong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38144094"
                        ],
                        "name": "T. Zhang",
                        "slug": "T.-Zhang",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53081097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdbdd4e0461d23905104460a02a176907d945f44",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization, which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads. Experimental results on widely-used WMT14 English-German and WMT17 Chinese-English translation tasks demonstrate the effectiveness and universality of the proposed approach."
            },
            "slug": "Multi-Head-Attention-with-Disagreement-Li-Tu",
            "title": {
                "fragments": [],
                "text": "Multi-Head Attention with Disagreement Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes three types of disagreement regularization, which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49795005"
                        ],
                        "name": "Xu Chen",
                        "slug": "Xu-Chen",
                        "structuredName": {
                            "firstName": "Xu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468306"
                        ],
                        "name": "H. Xu",
                        "slug": "H.-Xu",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739818"
                        ],
                        "name": "Yongfeng Zhang",
                        "slug": "Yongfeng-Zhang",
                        "structuredName": {
                            "firstName": "Yongfeng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongfeng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3431394"
                        ],
                        "name": "Jiaxi Tang",
                        "slug": "Jiaxi-Tang",
                        "structuredName": {
                            "firstName": "Jiaxi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaxi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145014675"
                        ],
                        "name": "Yixin Cao",
                        "slug": "Yixin-Cao",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145458349"
                        ],
                        "name": "Zheng Qin",
                        "slug": "Zheng-Qin",
                        "structuredName": {
                            "firstName": "Zheng",
                            "lastName": "Qin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zheng Qin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145203884"
                        ],
                        "name": "H. Zha",
                        "slug": "H.-Zha",
                        "structuredName": {
                            "firstName": "Hongyuan",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 117
                            }
                        ],
                        "text": "Other than recurrent neural networks, various deep learning models are also introduced for sequential recommendation [3, 22, 33, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207562781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc6a927b079fc1c4189f00108ff792a6d3d190e7",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "User preferences are usually dynamic in real-world recommender systems, and a user\u00bbs historical behavior records may not be equally important when predicting his/her future interests. Existing recommendation algorithms -- including both shallow and deep approaches -- usually embed a user\u00bbs historical records into a single latent vector/representation, which may have lost the per item- or feature-level correlations between a user\u00bbs historical records and future interests. In this paper, we aim to express, store, and manipulate users\u00bb historical records in a more explicit, dynamic, and effective manner. To do so, we introduce the memory mechanism to recommender systems. Specifically, we design a memory-augmented neural network (MANN) integrated with the insights of collaborative filtering for recommendation. By leveraging the external memory matrix in MANN, we store and update users\u00bb historical records explicitly, which enhances the expressiveness of the model. We further adapt our framework to both item- and feature-level versions, and design the corresponding memory reading/writing operations according to the nature of personalized recommendation scenarios. Compared with state-of-the-art methods that consider users\u00bb sequential behavior for recommendation, e.g., sequential recommenders with recurrent neural networks (RNN) or Markov chains, our method achieves significantly and consistently better performance on four real-world datasets. Moreover, experimental analyses show that our method is able to extract the intuitive patterns of how users\u00bb future actions are affected by previous behaviors."
            },
            "slug": "Sequential-Recommendation-with-User-Memory-Networks-Chen-Xu",
            "title": {
                "fragments": [],
                "text": "Sequential Recommendation with User Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A memory-augmented neural network (MANN) integrated with the insights of collaborative filtering for recommendation is designed, which store and update users\u00bb historical records explicitly, which enhances the expressiveness of the model."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159009"
                        ],
                        "name": "Liang Hu",
                        "slug": "Liang-Hu",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148761004"
                        ],
                        "name": "Longbing Cao",
                        "slug": "Longbing-Cao",
                        "structuredName": {
                            "firstName": "Longbing",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longbing Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116951322"
                        ],
                        "name": "Shoujin Wang",
                        "slug": "Shoujin-Wang",
                        "structuredName": {
                            "firstName": "Shoujin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shoujin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747560"
                        ],
                        "name": "Guandong Xu",
                        "slug": "Guandong-Xu",
                        "structuredName": {
                            "firstName": "Guandong",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guandong Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128217"
                        ],
                        "name": "Jian Cao",
                        "slug": "Jian-Cao",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48424210"
                        ],
                        "name": "Zhiping Gu",
                        "slug": "Zhiping-Gu",
                        "structuredName": {
                            "firstName": "Zhiping",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiping Gu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 106
                            }
                        ],
                        "text": "In fact, the choices of items in a user\u2019s historical interactions may not follow a rigid order assumption [18, 54] due to various unobservable external factors [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8527315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d2ce4298934ea1355031bf451413c1f81eaa408",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems (RS) have become an integral part of our daily life. However, most current RS often repeatedly recommend items to users with similar profiles. We argue that recommendation should be diversified by leveraging session contexts with personalized user profiles. For this, current session-based RS (SBRS) often assume a rigidly ordered sequence over data which does not fit in many real-world cases. Moreover, personalization is often omitted in current SBRS. Accordingly, a personalized SBRS over relaxedly ordered user-session contexts is more pragmatic. In doing so, deep-structured models tend to be too complex to serve for online SBRS owing to the large number of users and items. Therefore, we design an efficient SBRS with shallow wide-in-wide-out networks, inspired by the successful experience in modern language modelings. The experiments on a real-world e-commerce dataset show the superiority of our model over the state-of-the-art methods."
            },
            "slug": "Diversifying-Personalized-Recommendation-with-Hu-Cao",
            "title": {
                "fragments": [],
                "text": "Diversifying Personalized Recommendation with User-session Context"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that recommendation should be diversified by leveraging session contexts with personalized user profiles, and an efficient SBRS with shallow wide-in-wide-out networks is designed, inspired by the successful experience in modern language modelings."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 42,
            "methodology": 22,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 61,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/BERT4Rec:-Sequential-Recommendation-with-Encoder-Sun-Liu/690edf44e8739fd80bdfb76f40c9a4a222f3bba8?sort=total-citations"
}