{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29912342"
                        ],
                        "name": "Philipp Moritz",
                        "slug": "Philipp-Moritz",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Moritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Moritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16046818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66cdc28dc084af6507e979767755e99fe0b46b39",
            "isKey": false,
            "numCitedBy": 3977,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters."
            },
            "slug": "Trust-Region-Policy-Optimization-Schulman-Levine",
            "title": {
                "fragments": [],
                "text": "Trust Region Policy Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A method for optimizing control policies, with guaranteed monotonic improvement, by making several approximations to the theoretically-justified scheme, called Trust Region Policy Optimization (TRPO)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29912342"
                        ],
                        "name": "Philipp Moritz",
                        "slug": "Philipp-Moritz",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Moritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Moritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3075448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d316c82c12cf4c45f9e85211ef3d1fa62497bff8",
            "isKey": false,
            "numCitedBy": 1689,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. \nOur approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time."
            },
            "slug": "High-Dimensional-Continuous-Control-Using-Advantage-Schulman-Moritz",
            "title": {
                "fragments": [],
                "text": "High-Dimensional Continuous Control Using Generalized Advantage Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work addresses the large number of samples typically required and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36045539"
                        ],
                        "name": "Adri\u00e0 Puigdom\u00e8nech Badia",
                        "slug": "Adri\u00e0-Puigdom\u00e8nech-Badia",
                        "structuredName": {
                            "firstName": "Adri\u00e0",
                            "lastName": "Badia",
                            "middleNames": [
                                "Puigdom\u00e8nech"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adri\u00e0 Puigdom\u00e8nech Badia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3367786"
                        ],
                        "name": "Tim Harley",
                        "slug": "Tim-Harley",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Harley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6875312,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69e76e16740ed69f4dc55361a3d319ac2f1293dd",
            "isKey": false,
            "numCitedBy": 5389,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input."
            },
            "slug": "Asynchronous-Methods-for-Deep-Reinforcement-Mnih-Badia",
            "title": {
                "fragments": [],
                "text": "Asynchronous Methods for Deep Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers and shows that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801204"
                        ],
                        "name": "N. Heess",
                        "slug": "N.-Heess",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Heess",
                            "middleNames": [
                                "Manfred",
                                "Otto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Heess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22216833"
                        ],
                        "name": "TB Dhruva",
                        "slug": "TB-Dhruva",
                        "structuredName": {
                            "firstName": "TB",
                            "lastName": "Dhruva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "TB Dhruva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054369418"
                        ],
                        "name": "S. Sriram",
                        "slug": "S.-Sriram",
                        "structuredName": {
                            "firstName": "Srinivasan",
                            "lastName": "Sriram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sriram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144083287"
                        ],
                        "name": "Jay Lemmon",
                        "slug": "Jay-Lemmon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Lemmon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay Lemmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879232"
                        ],
                        "name": "J. Merel",
                        "slug": "J.-Merel",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Merel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Merel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89504302"
                        ],
                        "name": "Greg Wayne",
                        "slug": "Greg-Wayne",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Wayne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Wayne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109481"
                        ],
                        "name": "Yuval Tassa",
                        "slug": "Yuval-Tassa",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Tassa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Tassa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968210"
                        ],
                        "name": "T. Erez",
                        "slug": "T.-Erez",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Erez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Erez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648071"
                        ],
                        "name": "S. Eslami",
                        "slug": "S.-Eslami",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Eslami",
                            "middleNames": [
                                "M.",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eslami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30099687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a762ae907b7dd71a59bd8bd98aba69dfe2de13a2",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The reinforcement learning paradigm allows, in principle, for complex behaviours to be learned directly from simple reward signals. In practice, however, it is common to carefully hand-design the reward function to encourage a particular solution, or to derive it from demonstration data. In this paper explore how a rich environment can help to promote the learning of complex behavior. Specifically, we train agents in diverse environmental contexts, and find that this encourages the emergence of robust behaviours that perform well across a suite of tasks. We demonstrate this principle for locomotion -- behaviours that are known for their sensitivity to the choice of reward. We train several simulated bodies on a diverse set of challenging terrains and obstacles, using a simple reward function based on forward progress. Using a novel scalable variant of policy gradient reinforcement learning, our agents learn to run, jump, crouch and turn as required by the environment without explicit reward-based guidance. A visual depiction of highlights of the learned behavior can be viewed following this https URL ."
            },
            "slug": "Emergence-of-Locomotion-Behaviours-in-Rich-Heess-Dhruva",
            "title": {
                "fragments": [],
                "text": "Emergence of Locomotion Behaviours in Rich Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper explores how a rich environment can help to promote the learning of complex behavior, and finds that this encourages the emergence of robust behaviours that perform well across a suite of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2603033"
                        ],
                        "name": "V. Bapst",
                        "slug": "V.-Bapst",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Bapst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Bapst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801204"
                        ],
                        "name": "N. Heess",
                        "slug": "N.-Heess",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Heess",
                            "middleNames": [
                                "Manfred",
                                "Otto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Heess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10296217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a43d91c8d883e3463b358571125fa0ec7298b3a",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an actor-critic deep reinforcement learning agent with experience replay that is stable, sample efficient, and performs remarkably well on challenging environments, including the discrete 57-game Atari domain and several continuous control problems. To achieve this, the paper introduces several innovations, including truncated importance sampling with bias correction, stochastic dueling network architectures, and a new trust region policy optimization method."
            },
            "slug": "Sample-Efficient-Actor-Critic-with-Experience-Wang-Bapst",
            "title": {
                "fragments": [],
                "text": "Sample Efficient Actor-Critic with Experience Replay"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents an actor-critic deep reinforcement learning agent with experience replay that is stable, sample efficient, and performs remarkably well on challenging environments, including the discrete 57-game Atari domain and several continuous control problems."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144581158"
                        ],
                        "name": "Yan Duan",
                        "slug": "Yan-Duan",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192764"
                        ],
                        "name": "Xi Chen",
                        "slug": "Xi-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127100"
                        ],
                        "name": "Rein Houthooft",
                        "slug": "Rein-Houthooft",
                        "structuredName": {
                            "firstName": "Rein",
                            "lastName": "Houthooft",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rein Houthooft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12296499,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1464776f20e2bccb6182f183b5ff2e15b0ae5e56",
            "isKey": false,
            "numCitedBy": 1260,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at this https URL in order to facilitate experimental reproducibility and to encourage adoption by other researchers."
            },
            "slug": "Benchmarking-Deep-Reinforcement-Learning-for-Duan-Chen",
            "title": {
                "fragments": [],
                "text": "Benchmarking Deep Reinforcement Learning for Continuous Control"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, task with partial observations, and tasks with hierarchical structure."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294249"
                        ],
                        "name": "Yavar Naddaf",
                        "slug": "Yavar-Naddaf",
                        "structuredName": {
                            "firstName": "Yavar",
                            "lastName": "Naddaf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yavar Naddaf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1552061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f82e4ff4f003581330338aaae71f60316e58dd26",
            "isKey": false,
            "numCitedBy": 2086,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available."
            },
            "slug": "The-Arcade-Learning-Environment:-An-Evaluation-for-Bellemare-Naddaf",
            "title": {
                "fragments": [],
                "text": "The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The promise of ALE is illustrated by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning, and an evaluation methodology made possible by ALE is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5268,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 91740,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228824"
                        ],
                        "name": "Andrei A. Rusu",
                        "slug": "Andrei-A.-Rusu",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Rusu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei A. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145600108"
                        ],
                        "name": "A. Fidjeland",
                        "slug": "A.-Fidjeland",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fidjeland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fidjeland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273072"
                        ],
                        "name": "Georg Ostrovski",
                        "slug": "Georg-Ostrovski",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Ostrovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Ostrovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48348688"
                        ],
                        "name": "Stig Petersen",
                        "slug": "Stig-Petersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Petersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stig Petersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50388928"
                        ],
                        "name": "Charlie Beattie",
                        "slug": "Charlie-Beattie",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Beattie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Beattie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49813280"
                        ],
                        "name": "A. Sadik",
                        "slug": "A.-Sadik",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Sadik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sadik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143776287"
                        ],
                        "name": "Helen King",
                        "slug": "Helen-King",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34313265"
                        ],
                        "name": "S. Legg",
                        "slug": "S.-Legg",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205242740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d",
            "isKey": false,
            "numCitedBy": 16393,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "slug": "Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Human-level control through deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144832491"
                        ],
                        "name": "E. Todorov",
                        "slug": "E.-Todorov",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Todorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Todorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968210"
                        ],
                        "name": "T. Erez",
                        "slug": "T.-Erez",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Erez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Erez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109481"
                        ],
                        "name": "Yuval Tassa",
                        "slug": "Yuval-Tassa",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Tassa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Tassa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "for each algorithm variant, we chose a computationally cheap benchmark to test the algorithms on. Namely, we used 7 simulated robotics tasks 2 implemented in OpenAI Gym [Bro+16], which use the MuJoCo [TET12] physics engine. We do one million timesteps of training on each one. Besides the hyperparameters used for clipping ( ) and the KL penalty ( ;d targ ), which we search over, the other hyperparameters"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5230692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b354ee518bfc1ac0d8ac447eece9edb69e92eae1",
            "isKey": false,
            "numCitedBy": 2804,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new physics engine tailored to model-based control. Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms. Contact responses are computed via efficient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers. Models are specified using either a high-level C++ API or an intuitive XML file format. A built-in compiler transforms the user model into an optimized data structure used for runtime computation. The engine can compute both forward and inverse dynamics. The latter are well-defined even in the presence of contacts and equality constraints. The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles). To facilitate optimal control applications and in particular sampling and finite differencing, the dynamics can be evaluated for different states and controls in parallel. Around 400,000 dynamics evaluations per second are possible on a 12-core machine, for a 3D homanoid with 18 dofs and 6 active contacts. We have already used the engine in a number of control applications. It will soon be made publicly available."
            },
            "slug": "MuJoCo:-A-physics-engine-for-model-based-control-Todorov-Erez",
            "title": {
                "fragments": [],
                "text": "MuJoCo: A physics engine for model-based control"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A new physics engine tailored to model-based control, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers, which can compute both forward and inverse dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742557"
                        ],
                        "name": "I. Szita",
                        "slug": "I.-Szita",
                        "structuredName": {
                            "firstName": "Istv\u00e1n",
                            "lastName": "Szita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Szita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32414762"
                        ],
                        "name": "Andr\u00e1s L\u00f6rincz",
                        "slug": "Andr\u00e1s-L\u00f6rincz",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "L\u00f6rincz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e1s L\u00f6rincz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18515264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff188986e48d17fc4b59e6c4c00681794c9fd08",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The cross-entropy method is an efficient and general optimization algorithm. However, its applicability in reinforcement learning (RL) seems to be limited because it often converges to suboptimal policies. We apply noise for preventing early convergence of the cross-entropy method, using Tetris, a computer game, for demonstration. The resulting policy outperforms previous RL algorithms by almost two orders of magnitude."
            },
            "slug": "Learning-Tetris-Using-the-Noisy-Cross-Entropy-Szita-L\u00f6rincz",
            "title": {
                "fragments": [],
                "text": "Learning Tetris Using the Noisy Cross-Entropy Method"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Noise is applied for preventing early convergence of the cross-entropy method, using Tetris, a computer game, for demonstration, and the resulting policy outperforms previous RL algorithms by almost two orders of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065151121"
                        ],
                        "name": "Greg Brockman",
                        "slug": "Greg-Brockman",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Brockman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Brockman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34415167"
                        ],
                        "name": "Vicki Cheung",
                        "slug": "Vicki-Cheung",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Cheung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicki Cheung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152877508"
                        ],
                        "name": "Ludwig Pettersson",
                        "slug": "Ludwig-Pettersson",
                        "structuredName": {
                            "firstName": "Ludwig",
                            "lastName": "Pettersson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ludwig Pettersson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113526509"
                        ],
                        "name": "Jonas Schneider",
                        "slug": "Jonas-Schneider",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonas Schneider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109541439"
                        ],
                        "name": "Jie Tang",
                        "slug": "Jie-Tang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16099293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff7f3277c6fa759e84e1ab7664efdac1c1cec76b",
            "isKey": false,
            "numCitedBy": 2542,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "OpenAI Gym1 is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software."
            },
            "slug": "OpenAI-Gym-Brockman-Cheung",
            "title": {
                "fragments": [],
                "text": "OpenAI Gym"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695232"
                        ],
                        "name": "S. Kakade",
                        "slug": "S.-Kakade",
                        "structuredName": {
                            "firstName": "Sham",
                            "lastName": "Kakade",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kakade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "r(old ) = 1. TRPO maximizes a \\surrogate&quot; objective L CPI () = E^ t    (at jst)   old (at jst) A^ t  = E^ t h rt()A^t i : (6) The superscript CPI refers to conservative policy iteration [KL02], where this objective was proposed. Without a constraint, maximization of L CPI would lead to an excessively large policy update; hence, we now consider how to modify the objective, to penalize chang"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31442909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "523b4ce1c2a1336962444abc1dec215756c2f3e6",
            "isKey": false,
            "numCitedBy": 665,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Approximately-Optimal-Approximate-Reinforcement-Kakade-Langford",
            "title": {
                "fragments": [],
                "text": "Approximately Optimal Approximate Reinforcement Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trust region policy optimization \u201d Learning Tetris using the noisy cross - entropy method \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Proximal-Policy-Optimization-Algorithms-Schulman-Wolski/dce6f9d4017b1785979e7520fd0834ef8cf02f4b?sort=total-citations"
}