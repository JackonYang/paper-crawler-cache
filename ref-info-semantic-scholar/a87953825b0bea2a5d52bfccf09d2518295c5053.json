{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9344018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Rumelhart (1987), has proposed a method for choosing minimal or \"simple\" representations during learning in Back-propagation networks. This approach can be used to (a) dynamically select the number of hidden units, (b) construct a representation that is appropriate for the problem and (c) thus improve the generalization ability of Back-propagation networks. The method Rumelhart suggests involves adding penalty terms to the usual error function. In this paper we introduce Rumelhart's minimal networks idea and compare two possible biases on the weight search space. These biases are compared in both simple counting problems and a speech recognition problem. In general, the constrained search does seem to minimize the number of hidden units required with an expected increase in local minima."
            },
            "slug": "Comparing-Biases-for-Minimal-Network-Construction-Hanson-Pratt",
            "title": {
                "fragments": [],
                "text": "Comparing Biases for Minimal Network Construction with Back-Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces Rumelhart's minimal networks idea and compares two possible biases on the weight search space that are compared in both simple counting problems and a speech recognition problem."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15784283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28b0563fcd3364077dfc39f42c9684ec00dcd249",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a variation of the back-propagation algorithm that makes optimal use of a network hidden units by decrasing an \"energy\" term written as a function of the squared activations of these hidden units. The algorithm can automatically find optimal or nearly optimal architectures necessary to solve known Boolean functions, facilitate the interpretation of the activation of the remaining hidden units and automatically estimate the complexity of architectures appropriate for phonetic labeling problems. The general principle of the algorithm can also be adapted to different tasks: for example, it can be used to eliminate the [0, 0] local minimum of the [-1. +1] logistic activation function while preserving a much faster convergence and forcing binary activations over the set of hidden units."
            },
            "slug": "A-Back-Propagation-Algorithm-with-Optimal-Use-of-Chauvin",
            "title": {
                "fragments": [],
                "text": "A Back-Propagation Algorithm with Optimal Use of Hidden Units"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A variation of the back-propagation algorithm that makes optimal use of a network hidden units by decrasing an \"energy\" term written as a function of the squared activations of these hidden units is presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12926318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de996c32045df6f7b404dda2a753b6a9becf3c08",
            "isKey": false,
            "numCitedBy": 1888,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "slug": "Parallel-Networks-that-Learn-to-Pronounce-English-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "Parallel Networks that Learn to Pronounce English Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "H hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units, which suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023259"
                        ],
                        "name": "D. Medin",
                        "slug": "D.-Medin",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Medin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Medin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2231007"
                        ],
                        "name": "W. D. Wattenmaker",
                        "slug": "W.-D.-Wattenmaker",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Wattenmaker",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. D. Wattenmaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 11317097,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "59337def82e45c86b812c789e21f4864fd737b60",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper examines constraints and preferences employed by people in learning decision rules from preclassified examples. Results from four experiments with human subjects were analyzed and compared with artificial intelligence (AI) inductive learning programs. The results showed the people's rule inductions tended to emphasize category validity (probability of some property, given a category) more than cue validity (probability that an entity is a member of a category given that it has some property) to a greater extent than did the AI programs. Although the relative proportions of different rule types (e.g., conjunctive vs. disjunctive) changed across experiments, a single process model provided a good account of the data from each study. These observations are used to argue for describing constraints in terms of processes embodied in models rather than in terms of products or outputs. Thus AI induction programs become candidate psychological process models and results from inductive learning experiments can suggest new algorithms. More generally, the results show that human inductive generalizations tend toward greater specificity than would be expected if conceptual simplicity were the key constraint on inductions. This bias toward specificity may be due to the fact that this criterion both maximizes inferences that may be drawn from category membership and protects rule induction systems from developing over-generalizations."
            },
            "slug": "Constraints-and-Preferences-in-Inductive-Learning:-Medin-Wattenmaker",
            "title": {
                "fragments": [],
                "text": "Constraints and Preferences in Inductive Learning: An Experimental Study of Human and Machine Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Al induction programs become condidote psychological process models ond results from inductive learning experiments con suggest new algorithms, and results show that humon inductive generolizotions tend toword greater specificity than would be expected if conceptual simplicity were the key constraint on inductions."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92579735"
                        ],
                        "name": "Peter Craven",
                        "slug": "Peter-Craven",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Craven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145733439"
                        ],
                        "name": "G. Wahba",
                        "slug": "G.-Wahba",
                        "structuredName": {
                            "firstName": "Grace",
                            "lastName": "Wahba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wahba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14094416,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b477dd12dd49e44a62c1a303501df5fb6706c7e9",
            "isKey": false,
            "numCitedBy": 3546,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "SummarySmoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline.We consider the modelyi(ti)+\u03b5i,i=1, 2, ...,n,ti\u2208[0, 1], whereg\u2208W2(m)={f:f,f\u2032, ...,f(m\u22121) abs. cont.,f(m)\u2208\u21122[0,1]}, and the {\u03b5i} are random errors withE\u03b5i=0,E\u03b5i\u03b5j=\u03c32\u03b4ij. The error variance \u03c32 may be unknown. As an estimate ofg we take the solutiongn, \u03bb to the problem: Findf\u2208W2(m) to minimize\n$$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 + \\lambda \\int\\limits_0^1 {(f^{(m)} (u))^2 du} }$$\n. The functiongn, \u03bb is a smoothing polynomial spline of degree 2m\u22121. The parameter \u03bb controls the tradeoff between the \u201croughness\u201d of the solution, as measured by\n$$\\int\\limits_0^1 {[f^{(m)} (u)]^2 du}$$\n, and the infidelity to the data as measured by\n$$\\frac{1}{n}\\sum\\limits_{j = 1}^n {(f(t_j ) - y_j )^2 }$$\n, and so governs the average square errorR(\u03bb; g)=R(\u03bb) defined by\n$$R(\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g_{n,\\lambda } (t_j ) - g(t_j ))^2 }$$\n. We provide an estimate\n$$\\hat \\lambda$$\n, called the generalized cross-validation estimate, for the minimizer ofR(\u03bb). The estimate\n$$\\hat \\lambda$$\n is the minimizer ofV(\u03bb) defined by\n$$V(\\lambda ) = \\frac{1}{n}\\parallel (I - A(\\lambda ))y\\parallel ^2 /\\left[ {\\frac{1}{n}{\\text{Trace(}}I - A(\\lambda ))} \\right]^2$$\n, wherey=(y1, ...,yn)t andA(\u03bb) is then\u00d7n matrix satisfying(gn, \u03bb (t1), ...,gn, \u03bb (tn))t=A (\u03bb) y. We prove that there exist a sequence of minimizers\n$$\\tilde \\lambda = \\tilde \\lambda (n)$$\n ofEV(\u03bb), such that as the (regular) mesh{ti}i=1n becomes finer,\n$$\\mathop {\\lim }\\limits_{n \\to \\infty } ER(\\tilde \\lambda )/\\mathop {\\min }\\limits_\\lambda ER(\\lambda ) \\downarrow 1$$\n. A Monte Carlo experiment with several smoothg's was tried withm=2,n=50 and several values of \u03c32, and typical values of\n$$R(\\hat \\lambda )/\\mathop {\\min }\\limits_\\lambda R(\\lambda )$$\n were found to be in the range 1.01\u20131.4. The derivativeg\u2032 ofg can be estimated by\n$$g'_{n,\\hat \\lambda } (t)$$\n. In the Monte Carlo examples tried, the minimizer of\n$$R_D (\\lambda ) = \\frac{1}{n}\\sum\\limits_{j = 1}^n {(g'_{n,\\lambda } (t_j ) - } g'(t_j ))$$\n tended to be close to the minimizer ofR(\u03bb), so that\n$$\\hat \\lambda$$\n was also a good value of the smoothing parameter for estimating the derivative."
            },
            "slug": "Smoothing-noisy-data-with-spline-functions-Craven-Wahba",
            "title": {
                "fragments": [],
                "text": "Smoothing noisy data with spline functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 411526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50a42ed2f81b9fe150883a6c89194c88a9647106",
            "isKey": false,
            "numCitedBy": 42248,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples."
            },
            "slug": "A-new-look-at-the-statistical-model-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "A new look at the statistical model identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2547829"
                        ],
                        "name": "B. Yandell",
                        "slug": "B.-Yandell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Yandell",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yandell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122765020,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "56c810594ae2ec5d72f5f2cfd4799f75ff6f8fe2",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A wheeled toy vehicle including a drive assembly which comprises a monofilament line having one extremity connected to a manually operable control means and the opposite end connected to the running gear of the vehicle. The dimensions and configuration of the monofilament line is such as to transmit rotation of the line about its own longitudinal axis, caused by activation of the control means, directly to the running gear which may comprise a drive axle and/or one or more drive wheels. Connecting means may attach the one extremity of the line to a predetermined outer portion of an axle or wheel by means of forming a socket therein correspondingly shaped to at least partially enclose a finger attached to the extremity of the line means cooperating therewith. Alternately, a finger can be connected to the extremity of the drive axle and be disposed so as to be enclosed within a socket formed within a sleeve which is connected to the extremity of the line and comprises another embodiment of the connecting means."
            },
            "slug": "Spline-smoothing-and-nonparametric-regression-Yandell",
            "title": {
                "fragments": [],
                "text": "Spline smoothing and nonparametric regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11933040"
                        ],
                        "name": "A. Buse",
                        "slug": "A.-Buse",
                        "structuredName": {
                            "firstName": "Adolf",
                            "lastName": "Buse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buse"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44478775,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f430c85980ae5c03bdff3e5bef698d789a25e9ce",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract By means of simple diagrams this note gives an intuitive account of the likelihood ratio, the Lagrange multiplier, and Wald test procedures. It is also demonstrated that if the log-likelihood function is quadratic then the three test statistics are numerically identical and have \u03c72 distributions for all sample sizes under the null hypothesis."
            },
            "slug": "The-Likelihood-Ratio,-Wald,-and-Lagrange-Multiplier-Buse",
            "title": {
                "fragments": [],
                "text": "The Likelihood Ratio, Wald, and Lagrange Multiplier Tests: An Expository Note"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064561358"
                        ],
                        "name": "Gail Gong",
                        "slug": "Gail-Gong",
                        "structuredName": {
                            "firstName": "Gail",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gail Gong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 45944920,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d69c5d6a37d8cad463a9606282deb139f6ba35ca",
            "isKey": false,
            "numCitedBy": 3135,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "An apparatus for the in-situ detection of ions in a beam of an ion implanter device includes a mass spectrometer device having inner and outer walls and, a system for generating and directing an ion implant beam through the mass spectrometer device. The mass spectrometer device generates a magnetic field for directing ions of the ion implant beam of a desirable type through an aperture for implanting into a semiconductor wafer, and causing ions of undesirable type to collide with the inner or outer wall. For in-situ detection, a detector device is disposed on the inner and outer walls of the mass spectrometer for detecting the undesirable type of ions deflected. In one embodiment, the detector device comprises electronic sensor devices for detecting a concentration of the undesirable type ions which comprise undesirable elements and compounds. In another embodiment, the detector device comprises Faraday cup devices for detecting a concentration of ions of the undesirable type, or, may comprise a moving Faraday device positioned along tracks disposed respectively along the inner and outer wall, the Faraday being driven for reciprocal movement along a respective track. Data is collected from the sensors corresponding to the positions of undesirable ion detection and is processed, in real-time, during wafer processing. In this manner potential contaminants in the ion implant beam may be determined and corrective action may be taken in response."
            },
            "slug": "A-Leisurely-Look-at-the-Bootstrap,-the-Jackknife,-Efron-Gong",
            "title": {
                "fragments": [],
                "text": "A Leisurely Look at the Bootstrap, the Jackknife, and"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 64903870,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400b45a803d642b752a84147ef547af7811e8f3f",
            "isKey": false,
            "numCitedBy": 19698,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper it is shown that the classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion. This observation shows an extension of the principle to provide answers to many practical problems of statistical model fitting."
            },
            "slug": "Information-Theory-and-an-Extension-of-the-Maximum-Akaike",
            "title": {
                "fragments": [],
                "text": "Information Theory and an Extension of the Maximum Likelihood Principle"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The classical maximum likelihood principle can be considered to be a method of asymptotic realization of an optimum estimate with respect to a very general information theoretic criterion to provide answers to many practical problems of statistical model fitting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120510150,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "22cef227af3c3700693a053655ca82f01244167b",
            "isKey": false,
            "numCitedBy": 1185,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In a recent paper by the present author [1] a simple practical procedure of predictor identification has been proposed. It is the purpose of this paper to provide a theoretical and empirical basis of the procedure."
            },
            "slug": "Statistical-predictor-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "Statistical predictor identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment ; CU-CS-421-89 Computer Science Technical Reports"
            },
            "venue": {
                "fragments": [],
                "text": "Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment ; CU-CS-421-89 Computer Science Technical Reports"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic node creation in backpropagation neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Connection Science"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 269
                            }
                        ],
                        "text": "\u2026; CUCS-421-89 Michael C. Mozer University of Colorado Boulder\nPaul Smolensky University of Colorado Boulder\nFollow this and additional works at: http://scholar.colorado.edu/csci_techreports\nThis Technical Report is brought to you for free and open access by Computer Science at CU Scholar."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some comparisons of constraints for minimal network construction with back propagation"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Network Information Processing Systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment ; CU-CS-421-89"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Science Technical Reports. Paper"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rererences"
            },
            "venue": {
                "fragments": [],
                "text": "Rererences"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On entropy maximization principleApplications of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "On entropy maximization principleApplications of Statistics"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Skeletonization:-A-Technique-for-Trimming-the-Fat-a-Mozer-Smolensky/a87953825b0bea2a5d52bfccf09d2518295c5053?sort=total-citations"
}