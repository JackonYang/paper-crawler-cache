{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809420"
                        ],
                        "name": "Loris Bazzani",
                        "slug": "Loris-Bazzani",
                        "structuredName": {
                            "firstName": "Loris",
                            "lastName": "Bazzani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Loris Bazzani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "In an earlier version of this work (Bazzani et al., 2010) we learned the gaze selection policy with a portfolio allocation algorithm called Hedge (Freund & Schapire, 1997; Auer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 18
                            }
                        ],
                        "text": "Our previous work (Bazzani et al., 2010) used Hedge (Auer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 19
                            }
                        ],
                        "text": "Our previous work (Bazzani et al., 2010) used Hedge (Auer et al., 1998a; Freund & Schapire, 1997) to learn this policy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "In an earlier version of this work (Bazzani et al., 2010) we learned the gaze selection policy with a portfolio allocation algorithm called Hedge (Freund & Schapire, 1997; Auer et al., 1998b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18874434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "011784f44d84aa80d252b0bf9a34ff0ba0e0de36",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel attentional model for simultaneous object tracking and recognition that is driven by gaze data. Motivated by theories of the human perceptual system, the model consists of two interacting pathways: ventral and dorsal. The ventral pathway models object appearance and classification using deep (factored)-restricted Boltzmann machines. At each point in time, the observations consist of retinal images; with decaying resolution toward the periphery of the gaze. The dorsal pathway models the location, orientation, scale and speed of the attended object. The posterior distribution of these states is estimated with particle filtering. Deeper in the dorsal pathway, we encounter an attentional mechanism that learns to control gazes so as to maximize different objectives. Here we demonstrate the method when the objective is to minimize the uncertainty in the posterior distribution of the states. The approach is modular (with each module easily replaceable with more sophisticated algorithms), straightforward to implement, practically efficient, and works well in simple video sequences."
            },
            "slug": "Learning-attentional-mechanisms-for-simultaneous-Bazzani",
            "title": {
                "fragments": [],
                "text": "Learning attentional mechanisms for simultaneous object tracking and recognition with deep networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The method is modular, straightforward to implement, practically efficient, and works well in simple video sequences when the objective is to minimize the uncertainty in the posterior distribution of the states."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809420"
                        ],
                        "name": "Loris Bazzani",
                        "slug": "Loris-Bazzani",
                        "structuredName": {
                            "firstName": "Loris",
                            "lastName": "Bazzani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Loris Bazzani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727204"
                        ],
                        "name": "Vittorio Murino",
                        "slug": "Vittorio-Murino",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Murino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vittorio Murino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700133"
                        ],
                        "name": "Jo-Anne Ting",
                        "slug": "Jo-Anne-Ting",
                        "structuredName": {
                            "firstName": "Jo-Anne",
                            "lastName": "Ting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo-Anne Ting"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15076966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95db1d19516ff33f61103c7703d060c4cf9ff027",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel attentional model for simultaneous object tracking and recognition that is driven by gaze data. Motivated by theories of the human perceptual system, the model consists of two interacting pathways: ventral and dorsal. The ventral pathway models object appearance and classification using deep (factored)-restricted Boltzmann machines. At each point in time, the observations consist of retinal images, with decaying resolution toward the periphery of the gaze. The dorsal pathway models the location, orientation, scale and speed of the attended object. The posterior distribution of these states is estimated with particle filtering. Deeper in the dorsal pathway, we encounter an attentional mechanism that learns to control gazes so as to minimize tracking uncertainty. The approach is modular (with each module easily replaceable with more sophisticated algorithms), straightforward to implement, practically efficient, and works well in simple video sequences."
            },
            "slug": "Learning-attentional-policies-for-tracking-and-in-Bazzani-Freitas",
            "title": {
                "fragments": [],
                "text": "Learning attentional policies for tracking and recognition in video with deep networks"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel attentional model for simultaneous object tracking and recognition that is driven by gaze data is proposed, which is modular, straightforward to implement, practically efficient, and works well in simple video sequences."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2593137"
                        ],
                        "name": "N. Butko",
                        "slug": "N.-Butko",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Butko",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Butko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741200"
                        ],
                        "name": "J. Movellan",
                        "slug": "J.-Movellan",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Movellan",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Movellan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10593146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f7e578ee854a4cff9bbfe9f80f887c2357abc17",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling eye-movements during search is important for building intelligent robotic vision systems, and for understanding how humans select relevant information and structure behavior in real time. Previous models of visual search (VS) rely on the idea of ldquosaliency mapsrdquo which indicate likely locations for targets of interest. In these models the eyes move to locations with maximum saliency. This approach has several drawbacks: (1) It assumes that oculomotor control is a greedy process, i.e., every eye movement is planned as if no further eye movements would be possible after it. (2) It does not account for temporal dynamics and how information is integrated as over time. (3) It does not provide a formal basis to understand how optimal search should vary as a function of the operating characteristics of the visual system. To address these limitations, we reformulate the problem of VS as an Information-gathering Partially Observable Markov Decision Process (I-POMDP). We find that the optimal control law depends heavily on the Foveal-Peripheral Operating Characteristic (FPOC) of the visual system."
            },
            "slug": "I-POMDP:-An-infomax-model-of-eye-movement-Butko-Movellan",
            "title": {
                "fragments": [],
                "text": "I-POMDP: An infomax model of eye movement"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work reformulates the problem of visual search as an Information-gathering Partially Observable Markov Decision Process (I-POMDP) and finds that the optimal control law depends heavily on the Foveal-Peripheral Operating Characteristic (FPOC) of the visual system."
            },
            "venue": {
                "fragments": [],
                "text": "2008 7th IEEE International Conference on Development and Learning"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40538579"
                        ],
                        "name": "J. Vogel",
                        "slug": "J.-Vogel",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Vogel and de Freitas ( 2008 ) also considered the use of policy search to reduce uncertainty in a gaze planning task with discrete actions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14252040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "357d505ba6803c83dc843ac4dc88e7ff1c7c4aff",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "It is widely agreed that efficient visual search requires the integration of target-driven top-down information and image-driven bottom-up information. Yet the problem of gaze planning - that is, selecting the next best gaze location given the current observations - remains largely unsolved. We propose a probabilistic system that models the gaze sequence as a finite-horizon Bayesian sequential decision process. Direct policy search is used to reason about the next best gaze locations. The system integrates bottom-up saliency information, top-down target knowledge and additional context information through principled Bayesian priors. This results in proposal gaze locations that depend not only the featural visual saliency, but also on prior knowledge and the spatial likelihood of locating the target. The system has been implemented using state-of- the-art object detectors and evaluated on a real-world dataset by comparing it to gaze sequences proposed by a pure bottom-up saliency-based process and to an object detection approach that analyzes the full image. The target-directed attention system is shown to result in higher object detection precision than both competitors, to attend to more relevant targets than the bottom-up attention system, and to require significantly less computation time than the exhaustive approach."
            },
            "slug": "Target-directed-attention:-Sequential-for-gaze-Vogel-Freitas",
            "title": {
                "fragments": [],
                "text": "Target-directed attention: Sequential decision-making for gaze planning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A probabilistic system that models the gaze sequence as a finite-horizon Bayesian sequential decision process that results in proposal gaze locations that depend not only the featural visual saliency, but also on prior knowledge and the spatial likelihood of locating the target."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Conference on Robotics and Automation"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 62
                            }
                        ],
                        "text": "Our attentional model can be seen as building a saliency map (Koch & Ullman, 1985) over the target template."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45203429,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6",
            "isKey": false,
            "numCitedBy": 3964,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Psychophysical and physiological evidence indicates that the visual system of primates and humans has evolved a specialized processing focus moving across the visual scene. This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention. Specifically, we propose the following: (1) A number of elementary features, such as color, orientation, direction of movement, disparity etc. are represented in parallel in different topographical maps, called the early representation. (2) There exists a selective mapping from the early topographic representation into a more central non-topographic representation, such that at any instant the central representation contains the properties of only a single location in the visual scene, the selected location. We suggest that this mapping is the principal expression of early selective visual attention. One function of selective attention is to fuse information from different maps into one coherent whole. (3) Certain selection rules determine which locations will be mapped into the central representation. The major rule, using the conspicuity of locations in the early representation, is implemented using a so-called Winner-Take-All network. Inhibiting the selected location in this network causes an automatic shift towards the next most conspicious location. Additional rules are proximity and similarity preferences. We discuss how these rules can be implemented in neuron-like networks and suggest a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "slug": "Shifts-in-selective-visual-attention:-towards-the-Koch-Ullman",
            "title": {
                "fragments": [],
                "text": "Shifts in selective visual attention: towards the underlying neural circuitry."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study addresses the question of how simple networks of neuron-like elements can account for a variety of phenomena associated with this shift of selective visual attention and suggests a possible role for the extensive back-projection from the visual cortex to the LGN."
            },
            "venue": {
                "fragments": [],
                "text": "Human neurobiology"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48927140"
                        ],
                        "name": "J. Najemnik",
                        "slug": "J.-Najemnik",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Najemnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Najemnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2966196"
                        ],
                        "name": "W. Geisler",
                        "slug": "W.-Geisler",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Geisler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Geisler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 68669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2207d3952e4823280d297513226c2e075a3ff04c",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "To perform visual search, humans, like many mammals, encode a large field of view with retinas having variable spatial resolution, and then use high-speed eye movements to direct the highest-resolution region, the fovea, towards potential target locations. Good search performance is essential for survival, and hence mammals may have evolved efficient strategies for selecting fixation locations. Here we address two questions: what are the optimal eye movement strategies for a foveated visual system faced with the problem of finding a target in a cluttered environment, and do humans employ optimal eye movement strategies during a search? We derive the ideal bayesian observer for search tasks in which a target is embedded at an unknown location within a random background that has the spectral characteristics of natural scenes. Our ideal searcher uses precise knowledge about the statistics of the scenes in which the target is embedded, and about its own visual system, to make eye movements that gain the most information about target location. We find that humans achieve nearly optimal search performance, even though humans integrate information poorly across fixations. Analysis of the ideal searcher reveals that there is little benefit from perfect integration across fixations\u2014much more important is efficient processing of information on each fixation. Apparently, evolution has exploited this fact to achieve efficient eye movement strategies with minimal neural resources devoted to memory."
            },
            "slug": "Optimal-eye-movement-strategies-in-visual-search-Najemnik-Geisler",
            "title": {
                "fragments": [],
                "text": "Optimal eye movement strategies in visual search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work derives the ideal bayesian observer for search tasks in which a target is embedded at an unknown location within a random background that has the spectral characteristics of natural scenes and finds that humans achieve nearly optimal search performance, even though humans integrate information poorly across fixations."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 51
                            }
                        ],
                        "text": "These features can be computed from static images (Torralba et al., 2006), or from local regions of spacetime (Gaborski et al., 2004) for video."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 50
                            }
                        ],
                        "text": "These features can be computed from static images (Torralba et al., 2006), or from local regions of spacetime (Gaborski et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5875815,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b35e4d00d9a9bfae83a8b0914eb1073a77a11d78",
            "isKey": false,
            "numCitedBy": 1568,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "slug": "Contextual-guidance-of-eye-movements-and-attention-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An original approach of attentional guidance by global scene context is presented that combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80317385"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Olshausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143718183"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392063491"
                        ],
                        "name": "D. van Essen",
                        "slug": "D.-van-Essen",
                        "structuredName": {
                            "firstName": "D. C.",
                            "lastName": "van Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 97
                            }
                        ],
                        "text": "Many other dualpathway architectures have been proposed in computational neuroscience, including Olshausen et al. (1993b) and Postma et al. (1997), but we believe ours has the advantage that it is very simple, modular (with each module easily replaceable), suitable for large datasets and easy to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 232
                            }
                        ],
                        "text": "This separation of responsibility is a common feature in models from the computational neuroscience literature as it is believed to reflect a separation of information processing into ventral and dorsal pathways in the human brain (Olshausen et al., 1993a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1118263,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "700bbcd3518ca8cb3dac50a89fc69cad3dc1a579",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 146,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world. The model relies on a set of control neurons to dynamically modify the synaptic strengths of intracortical connections so that information from a windowed region of primary visual cortex (V1) is selectively routed to higher cortical areas. Local spatial relationships (i.e., topography) within the attentional window are preserved as information is routed through the cortex. This enables attended objects to be represented in higher cortical areas within an object-centered reference frame that is position and scale invariant. We hypothesize that the pulvinar may provide the control signals for routing information through the cortex. The dynamics of the control neurons are governed by simple differential equations that could be realized by neurobiologically plausible circuits. In preattentive mode, the control neurons receive their input from a low-level \u201csaliency map\u201d representing potentially interesting regions of a scene. During the pattern recognition phase, control neurons are driven by the interaction between top-down (memory) and bottom-up (retinal input) sources. The model respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "slug": "A-neurobiological-model-of-visual-attention-and-on-Olshausen-Anderson",
            "title": {
                "fragments": [],
                "text": "A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A biologically plausible model of an attentional mechanism for forming position- and scale-invariant representations of objects in the visual world that respects key neurophysiological, neuroanatomical, and psychophysical data relating to attention, and it makes a variety of experimentally testable predictions."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7197251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f282338fa4cd5516cdcd33cd4b6034f9739c45f4",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental operation in many vision tasks, including motion understanding, stereopsis, visual odometry, or invariant recognition, is establishing correspondences between images or between images and data from other modalities. Recently, there has been increasing interest in learning to infer correspondences from data using relational, spatiotemporal, and bilinear variants of deep learning methods. These methods use multiplicative interactions between pixels or between features to represent correlation patterns across multiple images. In this paper, we review the recent work on relational feature learning, and we provide an analysis of the role that multiplicative interactions play in learning to encode relations. We also discuss how square-pooling and complex cell models can be viewed as a way to represent multiplicative interactions and thereby as a way to encode relations."
            },
            "slug": "Learning-to-Relate-Images-Memisevic",
            "title": {
                "fragments": [],
                "text": "Learning to Relate Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper reviews the recent work on relational feature learning, and provides an analysis of the role that multiplicative interactions play in learning to encode relations, and discusses how square-pooling and complex cell models can be viewed as a way to representmultiplicative interactions and thereby as a ways to encoded relations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756934"
                        ],
                        "name": "Luke Barrington",
                        "slug": "Luke-Barrington",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Barrington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Barrington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34749896"
                        ],
                        "name": "Tim K. Marks",
                        "slug": "Tim-K.-Marks",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Marks",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim K. Marks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2392506"
                        ],
                        "name": "J. Hsiao",
                        "slug": "J.-Hsiao",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Hsiao",
                            "middleNames": [
                                "Hui-wen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hsiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 752381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73592cdc7c34c034660d1088f0170041874ebe2d",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Bayesian version of J. Lacroix, J. Murre, and E. Postma's (2006) Natural Input Memory (NIM) model of saccadic visual memory. Our model, which we call NIMBLE (NIM with Bayesian Likelihood Estimation), uses a cognitively plausible image sampling technique that provides a foveated representation of image patches. We conceive of these memorized image fragments as samples from image class distributions and model the memory of these fragments using kernel density estimation. Using these models, we derive class-conditional probabilities of new image fragments and combine individual fragment probabilities to classify images. Our Bayesian formulation of the model extends easily to handle multi-class problems. We validate our model by demonstrating human levels of performance on a face recognition memory task and high accuracy on multi-category face and object identification. We also use NIMBLE to examine the change in beliefs as more fixations are taken from an image. Using fixation data collected from human subjects, we directly compare the performance of NIMBLE's memory component to human performance, demonstrating that using human fixation locations allows NIMBLE to recognize familiar faces with only a single fixation."
            },
            "slug": "NIMBLE:-a-kernel-density-model-of-saccade-based-Barrington-Marks",
            "title": {
                "fragments": [],
                "text": "NIMBLE: a kernel density model of saccade-based visual memory."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A Bayesian version of J. Postma's Natural Input Memory (NIM) model of saccadic visual memory, which uses a cognitively plausible image sampling technique that provides a foveated representation of image patches to derive class-conditional probabilities of new image fragments and combine individual fragment probabilities to classify images."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144023706"
                        ],
                        "name": "B. Girard",
                        "slug": "B.-Girard",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Girard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Girard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706764"
                        ],
                        "name": "A. Berthoz",
                        "slug": "A.-Berthoz",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Berthoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berthoz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6076523,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ef177f0bc150090984980c178c3622d2b3c5ad85",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-brainstem-to-cortex:-Computational-models-of-Girard-Berthoz",
            "title": {
                "fragments": [],
                "text": "From brainstem to cortex: Computational models of saccade generation circuitry"
            },
            "venue": {
                "fragments": [],
                "text": "Progress in Neurobiology"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11563784"
                        ],
                        "name": "J. Gottlieb",
                        "slug": "J.-Gottlieb",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Gottlieb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gottlieb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7942958"
                        ],
                        "name": "M. Kusunoki",
                        "slug": "M.-Kusunoki",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Kusunoki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kusunoki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144060290"
                        ],
                        "name": "M. Goldberg",
                        "slug": "M.-Goldberg",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 108
                            }
                        ],
                        "text": "There might be better ways to exploit the saliency maps, as neurophysiological experiments seem to suggest (Gottlieb et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4373687,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "839e0a5e15fec789181285d57c9fad2b26bd0042",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "When natural scenes are viewed, a multitude of objects that are stable in their environments are brought in and out of view by eye movements. The posterior parietal cortex is crucial for the analysis of space, visual attention and movement. Neurons in one of its subdivisions, the lateral intraparietal area (LIP), have visual responses to stimuli appearing abruptly at particular retinal locations (their receptive fields). We have tested the responses of LIP neurons to stimuli that entered their receptive field by saccades. Neurons had little or no response to stimuli brought into their receptive field by saccades, unless the stimuli were behaviourally significant. We established behavioural significance in two ways: either by making a stable stimulus task-relevant, or by taking advantage of the attentional attraction of an abruptly appearing stimulus. Our results show that under ordinary circumstances the entire visual world is only weakly represented in LIP. The visual representation in LIP is sparse, with only the mostsalient or behaviourally relevant objects being strongly represented."
            },
            "slug": "The-representation-of-visual-salience-in-monkey-Gottlieb-Kusunoki",
            "title": {
                "fragments": [],
                "text": "The representation of visual salience in monkey parietal cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that under ordinary circumstances the entire visual world is only weakly represented in LIP, with only the most salient or behaviourally relevant objects being strongly represented."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968210"
                        ],
                        "name": "T. Erez",
                        "slug": "T.-Erez",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Erez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Erez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31663362"
                        ],
                        "name": "J. Tramper",
                        "slug": "J.-Tramper",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Tramper",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tramper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804336"
                        ],
                        "name": "W. Smart",
                        "slug": "W.-Smart",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Smart",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Smart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805324"
                        ],
                        "name": "S. Gielen",
                        "slug": "S.-Gielen",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Gielen",
                            "middleNames": [
                                "C.",
                                "A.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gielen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 218476787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "019e960c09d763728c1a6866d4834abed750d801",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a generative model of eye-hand coordination. We use numerical optimization to solve for the joint behavior of an eye and two hands, deriving a predicted motion pattern from first principles, without imposing heuristics. We model the planar scene as a POMDP with 17 continuous state dimensions. Belief-space optimization is facilitated by using a nominal-belief heuristic, whereby we assume (during planning) that the maximum likelihood observation is always obtained. Since a globally-optimal solution for such a high-dimensional domain is computationally intractable, we employ local optimization in the belief domain. By solving for a locally-optimal plan through belief space, we generate a motion pattern of mutual coordination between hands and eye: the eye's saccades disambiguate the scene in a task-relevant manner, and the hands' motions anticipate the eye's saccades. Finally, the model is validated through a behavioral experiment, in which human subjects perform the same eye-hand coordination task. We show how simulation is congruent with the experimental results."
            },
            "slug": "A-POMDP-model-of-eye-hand-coordination-Erez-Tramper",
            "title": {
                "fragments": [],
                "text": "A POMDP model of eye-hand coordination"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A generative model of eye-hand coordination that uses numerical optimization to solve for the joint behavior of an eye and two hands, deriving a predicted motion pattern from first principles, without imposing heuristics is presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739034"
                        ],
                        "name": "R. Gaborski",
                        "slug": "R.-Gaborski",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Gaborski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaborski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502785"
                        ],
                        "name": "Vishal S. Vaingankar",
                        "slug": "Vishal-S.-Vaingankar",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Vaingankar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal S. Vaingankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2603519"
                        ],
                        "name": "Vineet Chaoji",
                        "slug": "Vineet-Chaoji",
                        "structuredName": {
                            "firstName": "Vineet",
                            "lastName": "Chaoji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vineet Chaoji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752398"
                        ],
                        "name": "A. Teredesai",
                        "slug": "A.-Teredesai",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Teredesai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Teredesai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781452"
                        ],
                        "name": "A. Tentler",
                        "slug": "A.-Tentler",
                        "structuredName": {
                            "firstName": "Aleksey",
                            "lastName": "Tentler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tentler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 44
                            }
                        ],
                        "text": ", 2006), or from local regions of spacetime (Gaborski et al., 2004) for video."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 111
                            }
                        ],
                        "text": "These features can be computed from static images (Torralba et al., 2006), or from local regions of spacetime (Gaborski et al., 2004) for video."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14185604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "152af287f117cb0f819128e41b86abe38409332e",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans have a general understanding about their environment. We possess a sense of distinction between what is consistent and inconsistent about the environment based on our prior experience. Any aspect of the scene that does not fit into this definition of normalcy tends to be classified as an inconsistent event, also referred to as novel event. An example of this is a casual observer standing over a bridge on a freeway, tracking vehicle traffic, where the vehicles traveling at or around the same speed limit are generally ignored and a vehicle traveling at a much higher (or lower) speed is subject to one's immediate attention. In this paper, we present a computational learning based framework for novelty detection on video sequences. The framework extracts low-level features from scenes, based on the focus of attention theory and combines unsupervised learning with habituation theory for learning these features. The paper presents results from our experiments on natural video streams for identifying novelty in velocity of moving objects and static changes in the scene."
            },
            "slug": "Detection-of-inconsistent-regions-in-video-streams-Gaborski-Vaingankar",
            "title": {
                "fragments": [],
                "text": "Detection of inconsistent regions in video streams"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computational learning based framework for novelty detection on video sequences that extracts low-level features from scenes, based on the focus of attention theory and combines unsupervised learning with habituation theory for learning these features."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2036170"
                        ],
                        "name": "D. Gao",
                        "slug": "D.-Gao",
                        "structuredName": {
                            "firstName": "Dashan",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48493294"
                        ],
                        "name": "V. Mahadevan",
                        "slug": "V.-Mahadevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Mahadevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Mahadevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 122
                            }
                        ],
                        "text": "Additionally, a wide variety of different feature types have been applied to this problem, including engineered features (Gao et al., 2007) as well as features that are learned from data (Zhang et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 12
                            }
                        ],
                        "text": "The work of Gao et al. (2007) considers a similar approach to saliency by defining saliency to be the mutual information between the features at a location and the class label of an object being sought; however, in order to make their model tractable the authors are forced to use specifically\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 121
                            }
                        ],
                        "text": "Additionally, a wide variety of different feature types have been applied to this problem, including engineered features (Gao et al., 2007) as well as features that are learned from data (Zhang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 288206,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "655f212f069e2a2f16b90c02dcae3f46e8bb3c2c",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical hypothesis, that bottom-up saliency is a center-surround process, is combined with a more recent hypothesis that all saliency decisions are optimal in a decision-theoretic sense. The combined hypothesis is denoted as discriminant center-surround saliency, and the corresponding optimal saliency architecture is derived. This architecture equates the saliency of each image location to the discriminant power of a set of features with respect to the classification problem that opposes stimuli at center and surround, at that location. It is shown that the resulting saliency detector makes accurate quantitative predictions for various aspects of the psychophysics of human saliency, including non-linear properties beyond the reach of previous saliency models. Furthermore, it is shown that discriminant center-surround saliency can be easily generalized to various stimulus modalities (such as color, orientation and motion), and provides optimal solutions for many other saliency problems of interest for computer vision. Optimal solutions, under this hypothesis, are derived for a number of the former (including static natural images, dense motion fields, and even dynamic textures), and applied to a number of the latter (the prediction of human eye fixations, motion-based saliency in the presence of ego-motion, and motion-based saliency in the presence of highly dynamic backgrounds). In result, discriminant saliency is shown to predict eye fixations better than previous models, and produces background subtraction algorithms that outperform the state-of-the-art in computer vision."
            },
            "slug": "The-discriminant-center-surround-hypothesis-for-Gao-Mahadevan",
            "title": {
                "fragments": [],
                "text": "The discriminant center-surround hypothesis for bottom-up saliency"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In result, discriminant saliency is shown to predict eye fixations better than previous models, and produces background subtraction algorithms that outperform the state-of-the-art in computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9634512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several fixations. The model uses a retina that only has enough high resolution pixels to cover a small area of the image, so it must decide on a sequence of fixations and it must combine the \"glimpse\" at each fixation with the location of the fixation before integrating the information with information from other glimpses of the same object. We evaluate this model on a synthetic dataset and two image classification datasets, showing that it can perform at least as well as a model trained on whole images."
            },
            "slug": "Learning-to-combine-foveal-glimpses-with-a-machine-Larochelle-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning to combine foveal glimpses with a third-order Boltzmann machine"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several fixations is described, showing that it can perform at least as well as a model trained on whole images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "\u2026& Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and convolutional architectures (Lee et al., 2009)\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5642,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918263"
                        ],
                        "name": "Minyoung Kim",
                        "slug": "Minyoung-Kim",
                        "structuredName": {
                            "firstName": "Minyoung",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minyoung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152663162"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 67
                            }
                        ],
                        "text": "In our second experiment we use the Youtube celebrity dataset from Kim et al. (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9776222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa2f1ae7e37e7a98b83242b125280f080bc53dde",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of tracking and recognizing faces in real-world, noisy videos. We track faces using a tracker that adaptively builds a target model reflecting changes in appearance, typical of a video setting. However, adaptive appearance trackers often suffer from drift, a gradual adaptation of the tracker to non-targets. To alleviate this problem, our tracker introduces visual constraints using a combination of generative and discriminative models in a particle filtering framework. The generative term conforms the particles to the space of generic face poses while the discriminative one ensures rejection of poorly aligned targets. This leads to a tracker that significantly improves robustness against abrupt appearance changes and occlusions, critical for the subsequent recognition phase. Identity of the tracked subject is established by fusing pose-discriminant and person-discriminant features over the duration of a video sequence. This leads to a robust video-based face recognizer with state-of-the-art recognition performance. We test the quality of tracking and face recognition on real-world noisy videos from YouTube as well as the standard Honda/UCSD database. Our approach produces successful face tracking results on over 80% of all videos without video or person-specific parameter tuning. The good tracking performance induces similarly high recognition rates: 100% on Honda/UCSD and over 70% on the YouTube set containing 35 celebrities in 1500 sequences."
            },
            "slug": "Face-tracking-and-recognition-with-visual-in-videos-Kim-Kumar",
            "title": {
                "fragments": [],
                "text": "Face tracking and recognition with visual constraints in real-world videos"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work addresses the problem of tracking and recognizing faces in real-world, noisy videos using a tracker that adaptively builds a target model reflecting changes in appearance, typical of a video setting and introduces visual constraints using a combination of generative and discriminative models in a particle filtering framework."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 82
                            }
                        ],
                        "text": ", 2009), two-layer ICA (K\u00f6ster & Hyv\u00e4rinen, 2007) and convolutional architectures (Lee et al., 2009) could also be adopted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 258
                            }
                        ],
                        "text": "\u20262006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and convolutional architectures (Lee et al., 2009) could also be adopted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12008458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "isKey": false,
            "numCitedBy": 2528,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
            },
            "slug": "Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse",
            "title": {
                "fragments": [],
                "text": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11338130"
                        ],
                        "name": "K. Okuma",
                        "slug": "K.-Okuma",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Okuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Okuma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210143"
                        ],
                        "name": "Ali Taleghani",
                        "slug": "Ali-Taleghani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Taleghani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Taleghani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 216
                            }
                        ],
                        "text": "First, starting with Isard & Blake (1996), many particle filters have been proposed for image tracking, but these typically use simple observation models such as B-splines (Isard & Blake, 1996) and colour templates (Okuma et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 135
                            }
                        ],
                        "text": "However, it is possible to construct better proposal distributions, which make use of more recent observations, using object detectors (Okuma et al., 2004), saliency maps (Itti et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 136
                            }
                        ],
                        "text": "However, it is possible to construct better proposal distributions, which make use of more recent observations, using object detectors (Okuma et al., 2004), saliency maps (Itti et al., 1998), optical flow, and approximate filtering methods such as the unscented particle filter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15296463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "197c7b40c4f5ceb6b1d862de0bfc27b57e61d19d",
            "isKey": false,
            "numCitedBy": 1201,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking a varying number of non-rigid objects has two major difficulties. First, the observation models and target distributions can be highly non-linear and non-Gaussian. Second, the presence of a large, varying number of objects creates complex interactions with overlap and ambiguities. To surmount these difficulties, we introduce a vision system that is capable of learning, detecting and tracking the objects of interest. The system is demonstrated in the context of tracking hockey players using video sequences. Our approach combines the strengths of two successful algorithms: mixture particle filters and Adaboost. The mixture particle filter [17] is ideally suited to multi-target tracking as it assigns a mixture component to each player. The crucial design issues in mixture particle filters are the choice of the proposal distribution and the treatment of objects leaving and entering the scene. Here, we construct the proposal distribution using a mixture model that incorporates information from the dynamic models of each player and the detection hypotheses generated by Adaboost. The learned Adaboost proposal distribution allows us to quickly detect players entering the scene, while the filtering process enables us to keep track of the individual players. The result of interleaving Adaboost with mixture particle filters is a simple, yet powerful and fully automatic multiple object tracking system."
            },
            "slug": "A-Boosted-Particle-Filter:-Multitarget-Detection-Okuma-Taleghani",
            "title": {
                "fragments": [],
                "text": "A Boosted Particle Filter: Multitarget Detection and Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work introduces a vision system that is capable of learning, detecting and tracking the objects of interest, and interleaving Adaboost with mixture particle filters, a simple, yet powerful and fully automatic multiple object tracking system."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49488601"
                        ],
                        "name": "Matthew H Tong",
                        "slug": "Matthew-H-Tong",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Tong",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew H Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145404094"
                        ],
                        "name": "Lingyun Zhang",
                        "slug": "Lingyun-Zhang",
                        "structuredName": {
                            "firstName": "Lingyun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingyun Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 188
                            }
                        ],
                        "text": "Additionally, a wide variety of different feature types have been applied to this problem, including engineered features (Gao et al., 2007) as well as features that are learned from data (Zhang et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": ", 2007) as well as features that are learned from data (Zhang et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18924838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c772def2b56e873e27cc6eccbde8ee51aa3b6eb",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "SUNDAy: Saliency Using Natural Statistics for Dynamic Analysis of Scenes Lingyun Zhang (lingyun@cs.ucsd.edu) Matthew H. Tong (mhtong@cs.ucsd.edu) Garrison W. Cottrell(gary@cs.ucsd.edu) Deptartment of Computer Science and Engineering University of California, San Diego 9500 Gilman Dr., Dept. 0404, La Jolla, CA 92037-0404 Abstract The notion that novelty attracts attention is core to many ac- counts of visual saliency. However, a consensus has not been reached on how to best define novelty. Various interpretations of novelty lead to different bottom-up saliency models that have been proposed for static images and more recently for dynamic scenes. In previous work, we assumed that a basic goal of the visual system is to locate targets such as predators and food that are potentially important for survival, and devel- oped a probabilistic model of salience (Zhang, Tong, Marks, Shan, & Cottrell, 2008). The probabilistic description of this goal naturally leads a definition of novelty as self-information, an idea that has appeared in other work. However, our notion uses the idea that the statistics used to determine novelty are learned from prior experience, rather than on the current im- age, leading to an efficient implementation that explains sev- eral search asymmetries other models fail to predict. In this pa- per, we generalize our saliency framework to dynamic scenes and develop a simple, efficient, and online bottom-up saliency algorithm. Our algorithm matches the performance of more complex state of the art algorithms in predicting human fixa- tions during free-viewing of videos. Introduction It is of great research interest to understand how the visual system rapidly and efficiently samples the available visual in- formation. One major line of this research stems from the intuition that novel objects or statistical outliers attract at- tention. Koch and Ullman (1985) introduced the notion of a saliency map based around the notion that a region is intrin- sically salient if it differs substantially from its surroundings. A number of models stem from a similar intuition that being a local outlier makes a point salient (Itti, Koch, & Niebur, 1998; Gao & Vasconcelos, 2007a; Bruce & Tsotsos, 2006; Torralba, Oliva, Castelhano, & Henderson, 2006). As the small foreground items are often statistically different from the large background, locating statistical outliers in an image can facilitate detecting interesting objects. In addition, as low probability events contain more information (in an informa- tion theoretic sense), the definition of saliency as low proba- bility event connects the selective process of visual attention with maximally sampling information. Since humans live in a dynamic world, video and interac- tive environments provide a more faithful representation of the task facing the visual system than the static images fre- quently used in experiments. Studies also show that static measures of saliency do not perform as well as measures that use temporal information in predicting human fixations(Itti, 2005). Thus it is of interest to investigate saliency for dy- namic scenes. The notion that statistical outliers attract atten- tion applies equally well to the spatiotemporal domain and again, one sees variants of local outliers. Gaborski, Vain- gankar, Chaoji, Teredesai, and Tentler (2004) used mixtures of Gaussians to model what has occurred over a spatiotem- poral region of a video; an event is novel and salient if it cannot be accounted for by the model. Gao and Vasconce- los (2007b) extended their static image saliency to dynamic scenes: saliency is measured as KL divergence between the histogram of features in a location and the surround region, with the features implemented as optic flow. Itti and Baldi (2008) related saliency to Bayesian surprise which defines saliency as a deviation from what is expected based on a set of internal models of the local visual world. It is reasonable to assume that one goal of the visual system is to locate targets that are potentially important for survival. In our previous work, we developed a visual saliency model that is based on this simple assumption. From the resulting probabilistic description of this goal, the self-information of the features falls out as bottom-up, task-independent saliency (Zhang et al., 2008). Self-information in this context, learned from natural statistics over development, corresponds with findings that novel items attract attention in visual search (Wolfe, 2001). The reliance of learned natural statistics forms the basis of our model: Saliency Using Natural statistics (SUN). The definition of novelty in SUN, however, is dif- ferent from that has been used in previous computational saliency models in that statistical outliers are not based only on the current image. In all the models discussed, the statis- tics were local; for static images, the statistics were gath- ered solely from the current image, while for video they are gathered over some local spatiotemporal region. In previous work, we showed that feature distributions learned from ex- perience with natural scene images provide a straightforward account for human search asymmetries, a phenomenon that is difficult for models that rely solely on the current image\u2019s statistics, as they would find a vertical bar among tilted bars just as salient as a tilted bar among vertical bars. Further- more, the implementation of SUN performs as well as or bet- ter than previous models in predicting human fixations when free viewing images, and is computationally much more effi- cient(Zhang et al., 2008). In this paper, we use spatiotemporal visual features to gen- eralize the static image saliency model to dynamic scenes. We develop an efficient algorithm in which saliency is up- dated online upon each new frame. The model\u2019s performance in predicting human fixations while watching videos is com- parable to previous methods, with the advantage of being sub-"
            },
            "slug": "SUNDAy:-Saliency-Using-Natural-Statistics-for-of-Cottrell-Tong",
            "title": {
                "fragments": [],
                "text": "SUNDAy: Saliency Using Natural Statistics for Dynamic Analysis of Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work generalizes the saliency framework to dynamic scenes and develops a simple, efficient, and online bottom-up saliency algorithm that matches the performance of more complex state of the art algorithms in predicting human fixa- tions during free-viewing of videos."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145989594"
                        ],
                        "name": "M. Goodale",
                        "slug": "M.-Goodale",
                        "structuredName": {
                            "firstName": "Melvyn",
                            "lastName": "Goodale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goodale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153558474"
                        ],
                        "name": "A. Milner",
                        "slug": "A.-Milner",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Milner",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Milner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Separation of responsibility is a common feature in models from the computational neuroscience literature, as it is believed to reflect a separation of information processing into ventral and dorsal pathways in the human brain (Ungerleider & Mishkin,  1982 ; Goodale & Milner,  1992 ; Olshausen, Anderson, & Van Essen,  1993 ; O'Reilly,  2010 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 793980,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "0a995afa8d3c114b2b431c4e2737777a0e051bff",
            "isKey": false,
            "numCitedBy": 5717,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Separate-visual-pathways-for-perception-and-action-Goodale-Milner",
            "title": {
                "fragments": [],
                "text": "Separate visual pathways for perception and action"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Neurosciences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729457"
                        ],
                        "name": "E. Postma",
                        "slug": "E.-Postma",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Postma",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Postma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685622"
                        ],
                        "name": "H. J. V. Herik",
                        "slug": "H.-J.-V.-Herik",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Herik",
                            "middleNames": [
                                "Jaap",
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J. V. Herik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745116"
                        ],
                        "name": "P. Hudson",
                        "slug": "P.-Hudson",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hudson",
                            "middleNames": [
                                "T.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hudson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 126
                            }
                        ],
                        "text": "Many other dualpathway architectures have been proposed in computational neuroscience, including Olshausen et al. (1993b) and Postma et al. (1997), but we believe ours has the advantage that it is very simple, modular (with each module easily replaceable), suitable for large datasets and easy to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11818552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aaa84584b95db0f1c757a160e5a5471b0680efe",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SCAN:-A-Scalable-Model-of-Attentional-Selection-Postma-Herik",
            "title": {
                "fragments": [],
                "text": "SCAN: A Scalable Model of Attentional Selection"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653462"
                        ],
                        "name": "Ronald A. Rensink",
                        "slug": "Ronald-A.-Rensink",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rensink",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald A. Rensink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6740010,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "00e64fb34f407f5939612481ebc93a44d571c9c7",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the more powerful impressions created by vision is that of a coherent, richly detailed world where everything is present simultaneously. Indeed, this impression is so compelling that we tend to ascribe these properties not only to the external world, but to our internal representations as well. But results from several recent experiments argue against this latter ascription. For example, changes in images of real-world scenes often go unnoticed when made during a saccade, flicker, blink, or movie cut. This \u201cchange blindness\u201d provides strong evidence against the idea that our brains contain a picture-like representation of the scene that is everywhere detailed and coherent.\r\nHow then do we represent a scene? It is argued here that focused attention provides spatiotemporal coherence for the stable representation of one object at a time. It is then argued that the allocation of attention can be co-ordinated to create a \u201cvirtual representation\u201d. In such a scheme, a stable object representation is formed whenever needed, making it appear to higher levels as if all objects in the scene are represented in detail simultaneously."
            },
            "slug": "The-Dynamic-Representation-of-Scenes-Rensink",
            "title": {
                "fragments": [],
                "text": "The Dynamic Representation of Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 173
                            }
                        ],
                        "text": "For the synthetic digit videos, we trained the first-layer RBMs on the foveated images, while for the real videos we trained factoredRBMs on foveated natural image patches (Ranzato & Hinton, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 76
                            }
                        ],
                        "text": "For the first layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 92
                            }
                        ],
                        "text": "We also assume that readers are familiar with these models and, if otherwise, refer them to Ranzato & Hinton (2010) and Swersky et al. (2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9068522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2c04849a3802715d5a9d89179c9f161014d6c2a",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "slug": "Modeling-pixel-means-and-covariances-using-machines-Ranzato-Hinton",
            "title": {
                "fragments": [],
                "text": "Modeling pixel means and covariances using factorized third-order boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33259752"
                        ],
                        "name": "B. McNaughton",
                        "slug": "B.-McNaughton",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "McNaughton",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. McNaughton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144273828"
                        ],
                        "name": "F. Battaglia",
                        "slug": "F.-Battaglia",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Battaglia",
                            "middleNames": [
                                "Paolo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Battaglia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820484"
                        ],
                        "name": "O. Jensen",
                        "slug": "O.-Jensen",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Jensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Jensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855190"
                        ],
                        "name": "E. Moser",
                        "slug": "E.-Moser",
                        "structuredName": {
                            "firstName": "Edvard",
                            "lastName": "Moser",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Moser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37661215"
                        ],
                        "name": "M. Moser",
                        "slug": "M.-Moser",
                        "structuredName": {
                            "firstName": "May-Britt",
                            "lastName": "Moser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 134
                            }
                        ],
                        "text": "We make no attempt to implement such states with neural architectures, but it seems clear that they could be encoded with grid cells (McNaughton et al., 2006) and retinotopic maps as in V1 and the superior colliculus (Rosa, 2002; Girard & Berthoz, 2005)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16928213,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "946e75e6548017341fde96e1008b9538bf5a96f9",
            "isKey": false,
            "numCitedBy": 1593,
            "numCiting": 165,
            "paperAbstract": {
                "fragments": [],
                "text": "The hippocampal formation can encode relative spatial location, without reference to external cues, by the integration of linear and angular self-motion (path integration). Theoretical studies, in conjunction with recent empirical discoveries, suggest that the medial entorhinal cortex (MEC) might perform some of the essential underlying computations by means of a unique, periodic synaptic matrix that could be self-organized in early development through a simple, symmetry-breaking operation. The scale at which space is represented increases systematically along the dorsoventral axis in both the hippocampus and the MEC, apparently because of systematic variation in the gain of a movement-speed signal. Convergence of spatially periodic input at multiple scales, from so-called grid cells in the entorhinal cortex, might result in non-periodic spatial firing patterns (place fields) in the hippocampus."
            },
            "slug": "Path-integration-and-the-neural-basis-of-the-map'-McNaughton-Battaglia",
            "title": {
                "fragments": [],
                "text": "Path integration and the neural basis of the 'cognitive map'"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Theoretical studies suggest that the medial entorhinal cortex might perform some of the essential underlying computations by means of a unique, periodic synaptic matrix that could be self-organized in early development through a simple, symmetry-breaking operation."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Reviews Neuroscience"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290098"
                        ],
                        "name": "Christopher Kanan",
                        "slug": "Christopher-Kanan",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Kanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Kanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Kanan and Cottrell ( 2010 ) proposed another model and applied it to the task of estimating the class of some input image from multiple fixations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14474281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d8685fb5add2378cae7baa3506ea22d06f092a6",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification of images in many category datasbets has rapidly improved in recent years. However, systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g., requiring a face detector or extensive retuning of parameters), insufficient translation invariance, inability to cope with partial views and occlusion, or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type, our approach achieves 78.5% accuracy on Caltech-101 and 75.2% on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7% accuracy on the AR Face database with 1 training instance per person. The same features and parameters are used across these datasets to illustrate its robust performance."
            },
            "slug": "Robust-classification-of-objects,-faces,-and-using-Kanan-Cottrell",
            "title": {
                "fragments": [],
                "text": "Robust classification of objects, faces, and flowers using natural image statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work uses a biologically-inspired filters model that combines sequential visual attention using fixations with sparse coding and unsupervised learning applied to natural image patches to overcome challenges in classification of images in many category datasbets."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "First, starting with Isard & Blake (1996), many particle filters have been proposed for image tracking, but these typically use simple observation models such as B-splines (Isard & Blake, 1996) and colour templates (Okuma et al., 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8369379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c5a0951cea300222834497c8e12ac2be99cd11e",
            "isKey": false,
            "numCitedBy": 1435,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is a challenging one. Trackers based on Kalman filters are of limited use; because they are based on Gaussian densities which are unimodal, they cannot represent simultaneous alternative hypotheses. Extensions to the Kalman filter to handle multiple data associations work satisfactorily in the simple case of point targets, but do not extend naturally to continuous curves. A new, stochastic algorithm is proposed here, the Condensation algorithm \u2014 Conditional Density Propagation over time. It uses \u2018factored sampling\u2019, a method previously applied to interpretation of static images, in which the distribution of possible interpretations is represented by a randomly generated set of representatives. The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time. The result is highly robust tracking of agile motion in clutter, markedly superior to what has previously been attainable from Kalman filtering. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "Contour-Tracking-by-Stochastic-Propagation-of-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "Contour Tracking by Stochastic Propagation of Conditional Density"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time, and is markedly superior to what has previously been attainable from Kalman filtering."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271571"
                        ],
                        "name": "E. Niebur",
                        "slug": "E.-Niebur",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Niebur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Niebur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": ", 2004), saliency maps (Itti et al., 1998), optical flow, and approximate filtering methods such as the unscented particle filter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 172
                            }
                        ],
                        "text": "However, it is possible to construct better proposal distributions, which make use of more recent observations, using object detectors (Okuma et al., 2004), saliency maps (Itti et al., 1998), optical flow, and approximate filtering methods such as the unscented particle filter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3108956,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4816f0b6f0d05da3901441bfa5cc7be044b4da8b",
            "isKey": false,
            "numCitedBy": 9799,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail."
            },
            "slug": "A-Model-of-Saliency-Based-Visual-Attention-for-Itti-Koch",
            "title": {
                "fragments": [],
                "text": "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented, which breaks down the complex problem of scene understanding by rapidly selecting conspicuous locations to be analyzed in detail."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758219"
                        ],
                        "name": "Matthew B. Blaschko",
                        "slug": "Matthew-B.-Blaschko",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Blaschko",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. Blaschko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From the computer vision perspective, Lampert, Blaschko, and Hofmann ( 2008 ) proposed a top-down, branch-and-bound method (faster than standard sliding window) to select the salient parts of the image for purposes of object detection and localization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6131848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b224478a63e33441c651175c522f3702062fc4",
            "isKey": false,
            "numCitedBy": 801,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the chi2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition."
            },
            "slug": "Beyond-sliding-windows:-Object-localization-by-Lampert-Blaschko",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows: Object localization by efficient subwindow search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages and converges to a globally optimal solution typically in sublinear time is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144595715"
                        ],
                        "name": "M. Rosa",
                        "slug": "M.-Rosa",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Rosa",
                            "middleNames": [
                                "G.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 66
                            }
                        ],
                        "text": ", 2006) and retinotopic maps as in V1 and the superior colliculus (Rosa, 2002; Girard & Berthoz, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 218
                            }
                        ],
                        "text": "We make no attempt to implement such states with neural architectures, but it seems clear that they could be encoded with grid cells (McNaughton et al., 2006) and retinotopic maps as in V1 and the superior colliculus (Rosa, 2002; Girard & Berthoz, 2005)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14699141,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e4d9a1e2455826c4f859084faa4c5532ac7e7181",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the topology of cortical visuotopic maps in adult primates is reviewed, with emphasis on recent studies. The observed visuotopic organisation can be summarised with reference to two basic rules. First, adjacent radial columns in the cortex represent partially overlapping regions of the visual field, irrespective of whether these columns are part of the same or different cortical areas. This primary rule is seldom, if ever, violated. Second, adjacent regions of the visual field tend to be represented in adjacent radial columns of a same area. This rule is not as rigid as the first, as many cortical areas form discontinuous, second-order representations of the visual field. A developmental model based on these physiological observations, and on comparative studies of cortical organisation, is then proposed, in order to explain how a combination of molecular specification steps and activity-driven processes can generate the variety of visuotopic organisations observed in adult cortex."
            },
            "slug": "Visual-maps-in-the-adult-primate-cerebral-cortex:-Rosa",
            "title": {
                "fragments": [],
                "text": "Visual maps in the adult primate cerebral cortex: some implications for brain development and evolution."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A developmental model is proposed in order to explain how a combination of molecular specification steps and activity-driven processes can generate the variety of visuotopic organisations observed in adult cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Brazilian journal of medical and biological research = Revista brasileira de pesquisas medicas e biologicas"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2791125"
                        ],
                        "name": "Zdenek Kalal",
                        "slug": "Zdenek-Kalal",
                        "structuredName": {
                            "firstName": "Zdenek",
                            "lastName": "Kalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zdenek Kalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 169
                            }
                        ],
                        "text": "This is essential to extend the results to long video sequences where the object undergoes significant transformations (e.g. as is done in the predator tracking system (Kalal et al., 2010))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 43
                            }
                        ],
                        "text": "as is done in the predator tracking system (Kalal et al., 2010))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5170951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eebc4a70509aca8491c2302c8a4241fd82c9007f",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel system for long-term tracking of a human face in unconstrained videos is built on Tracking-Learning-Detection (TLD) approach. The system extends TLD with the concept of a generic detector and a validator which is designed for real-time face tracking resistent to occlusions and appearance changes. The off-line trained detector localizes frontal faces and the online trained validator decides which faces correspond to the tracked subject. Several strategies for building the validator during tracking are quantitatively evaluated. The system is validated on a sitcom episode (23 min.) and a surveillance (8 min.) video. In both cases the system detects-tracks the face and automatically learns a multi-view model from a single frontal example and an unlabeled video."
            },
            "slug": "Face-TLD:-Tracking-Learning-Detection-applied-to-Kalal-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Face-TLD: Tracking-Learning-Detection applied to faces"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A novel system for long-term tracking of a human face in unconstrained videos is built on Tracking-Learning-Detection approach with the concept of a generic detector and a validator which is designed for real-time face tracking resistent to occlusions and appearance changes."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Image Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 23
                            }
                        ],
                        "text": ", 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (K\u00f6ster & Hyv\u00e4rinen, 2007) and convolutional architectures (Lee et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 157
                            }
                        ],
                        "text": "\u20262006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and convolutional architectures (Lee et al., 2009) could also be adopted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10516905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54a9c2553138932426faebcaa67a63a84a56b55d",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recently-proposed architectures for high-performance object recognition are composed of two main stages: a feature extraction stage that extracts locally-invariant feature vectors from regularly spaced image patches, and a somewhat generic supervised classifier. The first stage is often composed of three main modules: (1) a bank of filters (often oriented edge detectors); (2) a non-linear transform, such as a point-wise squashing functions, quantization, or normalization; (3) a spatial pooling operation which combines the outputs of similar filters over neighboring regions. We propose a method that automatically learns such feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together. The method automatically generates topographic maps of similar filters that extract features of orientations, scales, and positions. These similar filters are pooled together, producing locally-invariant outputs. The learned feature descriptors give comparable results as SIFT on image recognition tasks for which SIFT is well suited, and better results than SIFT on tasks for which SIFT is less well suited."
            },
            "slug": "Learning-invariant-features-through-topographic-Kavukcuoglu-Ranzato",
            "title": {
                "fragments": [],
                "text": "Learning invariant features through topographic filter maps"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a method that automatically learns feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 58
                            }
                        ],
                        "text": "Recently, a dynamic RBM state-space model was proposed in Taylor et al. (2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16974865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20b97fd491a05b289dfd666a87c545664b25bb67",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new class of probabilistic latent variable model called the Implicit Mixture of Conditional Restricted Boltzmann Machines (imCRBM) for use in human pose tracking. Key properties of the imCRBM are as follows: (1) learning is linear in the number of training exemplars so it can be learned from large datasets; (2) it learns coherent models of multiple activities; (3) it automatically discovers atomic \u201cmovemes\u201d and (4) it can infer transitions between activities, even when such transitions are not present in the training set. We describe the model and how it is learned and we demonstrate its use in the context of Bayesian filtering for multi-view and monocular pose tracking. The model handles difficult scenarios including multiple activities and transitions among activities. We report state-of-the-art results on the HumanEva dataset."
            },
            "slug": "Dynamical-binary-latent-variable-models-for-3D-pose-Taylor-Sigal",
            "title": {
                "fragments": [],
                "text": "Dynamical binary latent variable models for 3D human pose tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new class of probabilistic latent variable model called the Implicit Mixture of Conditional Restricted Boltzmann Machines (imCRBM) for use in human pose tracking and its use in the context of Bayesian filtering for multi-view and monocular pose tracking is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Martinez-Cantin, de Freitas, Doucet, and Castellanos ( 2007 ) applied Bayesian optimization to guide policy search so as to minimize the uncertainty in the location of visual features in the setting of a robot exploring and mapping its environment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2077953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45aa6a67ce508ccbe74b74f5d60acb626727e914",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes. The algorithm is tested in the domain of robot navigation and exploration under uncertainty. In such a setting, the expected cost, that must be minimized, is a function of the belief state (filtering distribution). This filtering distribution is in turn nonlinear and subject to discontinuities, which arise because constraints in the robot motion and control models. As a result, the expected cost is non-differentiable and very expensive to simulate. The new algorithm overcomes the first difficulty and reduces the number of required simulations as follows. First, it assumes that we have carried out previous simulations which returned values of the expected cost for different corresponding policy parameters. Second, it fits a Gaussian process (GP) regression model to these values, so as to approximate the expected cost as a function of the policy parameters. Third, it uses the GP predicted mean and variance to construct a statistical measure that determines which policy parameters should be used in the next simulation. The process is then repeated using the new parameters and the newly gathered expected cost observation. Since the objective is to find the policy parameters that minimize the expected cost, this iterative active learning approach effectively trades-off between exploration (in regions where the GP variance is large) and exploitation (where the GP mean is low). In our experiments, a robot uses the proposed algorithm to plan an optimal path for accomplishing a series of tasks, while maximizing the information about its pose and map estimates. These estimates are obtained with a standard filter for simultaneous localization and mapping. Upon gathering new observations, the robot updates the state estimates and is able to replan a new path in the spirit of open-loop feedback control."
            },
            "slug": "Active-Policy-Learning-for-Robot-Planning-and-under-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "Active Policy Learning for Robot Planning and Exploration under Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes, tested in the domain of robot navigation and exploration under uncertainty, which effectively trades-off between exploration and exploitation."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144998829"
                        ],
                        "name": "N. Gordon",
                        "slug": "N.-Gordon",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gordon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 63
                            }
                        ],
                        "text": "The localization module is implemented with a particle filter (Doucet et al., 2001) which estimates the location, velocity and scale of the target object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 78
                            }
                        ],
                        "text": "The use of a selection step is key to making the SMC procedure effective; see Doucet et al. (2001) for details on how to implement this black box routine."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 177
                            }
                        ],
                        "text": "This separation of responsibility is a common feature in models from the computational neuroscience literature as it is believed to reflect a separation of information processing into ventral and dorsal pathways in the human brain (Olshausen et al., 1993a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "We refer readers to Doucet et al. (2001) for a more in depth treatment of these sequential Monte Carlo methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30176573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "875c77b0daf65f2db77b48e784cb68fb312edea3",
            "isKey": false,
            "numCitedBy": 3708,
            "numCiting": 368,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte Carlo methods are revolutionizing the on-line analysis of data in fields as diverse as financial modeling, target tracking and computer vision. These methods, appearing under the names of bootstrap filters, condensation, optimal Monte Carlo filters, particle filters and survival of the fittest, have made it possible to solve numerically many complex, non-standard problems that were previously intractable. This book presents the first comprehensive treatment of these techniques, including convergence results and applications to tracking, guidance, automated target recognition, aircraft navigation, robot navigation, econometrics, financial modeling, neural networks, optimal control, optimal filtering, communications, reinforcement learning, signal enhancement, model averaging and selection, computer vision, semiconductor design, population biology, dynamic Bayesian networks, and time series analysis. This will be of great value to students, researchers and practitioners, who have some basic knowledge of probability. Arnaud Doucet received the Ph. D. degree from the University of Paris-XI Orsay in 1997. From 1998 to 2000, he conducted research at the Signal Processing Group of Cambridge University, UK. He is currently an assistant professor at the Department of Electrical Engineering of Melbourne University, Australia. His research interests include Bayesian statistics, dynamic models and Monte Carlo methods. Nando de Freitas obtained a Ph.D. degree in information engineering from Cambridge University in 1999. He is presently a research associate with the artificial intelligence group of the University of California at Berkeley. His main research interests are in Bayesian statistics and the application of on-line and batch Monte Carlo methods to machine learning. Neil Gordon obtained a Ph.D. in Statistics from Imperial College, University of London in 1993. He is with the Pattern and Information Processing group at the Defence Evaluation and Research Agency in the United Kingdom. His research interests are in time series, statistical data analysis, and pattern recognition with a particular emphasis on target tracking and missile guidance."
            },
            "slug": "Sequential-Monte-Carlo-Methods-in-Practice-Doucet-Freitas",
            "title": {
                "fragments": [],
                "text": "Sequential Monte Carlo Methods in Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book presents the first comprehensive treatment of Monte Carlo techniques, including convergence results and applications to tracking, guidance, automated target recognition, aircraft navigation, robot navigation, econometrics, financial modeling, neural networks, optimal control, optimal filtering, communications, reinforcement learning, signal enhancement, model averaging and selection."
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5944993"
                        ],
                        "name": "Jonathan D. Nelson",
                        "slug": "Jonathan-D.-Nelson",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Nelson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan D. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518433"
                        ],
                        "name": "C. Mckenzie",
                        "slug": "C.-Mckenzie",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Mckenzie",
                            "middleNames": [
                                "R.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mckenzie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Nelson, McKenzie, Cottrell, & Sejnowski ( 2010 ), for example, presented various measures of uncertainty used in decision making for Bayesian optimal-experimental design: probability gain, Shannon entropy, Kullback-Leibler distance, and impact."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2397591,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "11042ad0a5207a3e79f53a0979a4e330b9e22890",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Deciding which piece of information to acquire or attend to is fundamental to perception, categorization, medical diagnosis, and scientific inference. Four statistical theories of the value of information\u2014information gain, Kullback-Liebler distance, probability gain (error minimization), and impact\u2014are equally consistent with extant data on human information acquisition. Three experiments, designed via computer optimization to be maximally informative, tested which of these theories best describes human information search. Experiment 1, which used natural sampling and experience-based learning to convey environmental probabilities, found that probability gain explained subjects\u2019 information search better than the other statistical theories or the probability-of-certainty heuristic. Experiments 1 and 2 found that subjects behaved differently when the standard method of verbally presented summary statistics (rather than experience-based learning) was used to convey environmental probabilities. Experiment 3 found that subjects\u2019 preference for probability gain is robust, suggesting that the other models contribute little to subjects\u2019 search behavior."
            },
            "slug": "Experience-Matters-Nelson-Mckenzie",
            "title": {
                "fragments": [],
                "text": "Experience Matters"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Four statistical theories of the value of information\u2014information gain, Kullback-Liebler distance, probability gain (error minimization), and impact\u2014are equally consistent with extant data on human information acquisition, and three experiments tested which of these theories best describes human information search."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 16
                            }
                        ],
                        "text": "Equation 2 is a Gaussian Process estimate of the reward surface and can be used to select a fixation point for the next time step."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 234
                            }
                        ],
                        "text": "In this extended paper we show that a straightforward adaptation of our previous approach to the partial information setting results in poor performance, and we propose an alternative method based on modelling the reward surface as a Gaussian Process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 74
                            }
                        ],
                        "text": "We model the latent reward function rt(at|bt) , r(at|bt,\u03b8t) as a zero mean Gaus-\nsian Process\nr(at|bt,\u03b8t) \u223c GP(0, k(at, a\u2032t|bt,\u03b8t)) ,\nwhere bt is the belief state (see Section 3.1), and \u03b8t are the model hyperparameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 100
                            }
                        ],
                        "text": "We can instead learn a continuous policy by estimating the reward surface using a Gaussian Process (Rasmussen & Williams, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "The Gaussian Process regression is controlled by several hyperparameters (see Figure 6): \u03c32m controls the overall magnitude of the covariance, and \u03c3 2 n controls the amount of observation noise."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 52
                            }
                        ],
                        "text": "Gaussian Process priors encode this type of belief (Rasmussen & Williams, 2006), and have been used extensively for optimization of cost functions when it is important to minimize the total number of function evaluations (Brochu et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 24
                            }
                        ],
                        "text": "This is the strength of Gaussian Processes for this type of optimization problem, since the predictions can be used to balance exploration (choosing a fixation point where the reward is highly uncertain) and exploitation (choosing a point we are confident will have high reward)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 71
                            }
                        ],
                        "text": "MAP estimates can be made quickly using gradient optimization methods (Rasmussen & Williams, 2006), and informative priors provide resistance to the problems encountered with ML."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 209
                            }
                        ],
                        "text": "We show that a straightforward extension of the existing approach to the partial information setting results in poor performance, and we propose an alternative method based on modeling the reward surface as a Gaussian Process."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59860283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d41d6ec4805f80b84a1ccd17f6753ba71e107f7",
            "isKey": true,
            "numCitedBy": 2549,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-(Adaptive-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and includes detailed algorithms for supervised-learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49627521"
                        ],
                        "name": "Urs K\u00f6ster",
                        "slug": "Urs-K\u00f6ster",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "K\u00f6ster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs K\u00f6ster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18039559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cca5a7c3327f6075c58361d7f98188dc4f9d7c",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Capturing regularities in high-dimensional data is an important problem in machine learning and signal processing. Here we present a statistical model that learns a nonlinear representation from the data that reflects abstract, invariant properties of the signal without making requirements about the kind of signal that can be processed. The model has a hierarchy of two layers, with the first layer broadly corresponding to Independent Component Analysis (ICA) and a second layer to represent higher order structure. We estimate the model using the mathematical framework of Score Matching (SM), a novel method for the estimation of non-normalized statistical models. The model incorporates a squaring nonlinearity, which we propose to be suitable for forming a higher-order code of invariances. Additionally the squaring can be viewed as modelling subspaces to capture residual dependencies, which linear models cannot capture."
            },
            "slug": "A-Two-Layer-ICA-Like-Model-Estimated-by-Score-K\u00f6ster-Hyv\u00e4rinen",
            "title": {
                "fragments": [],
                "text": "A Two-Layer ICA-Like Model Estimated by Score Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A statistical model is presented that learns a nonlinear representation from the data that reflects abstract, invariant properties of the signal without making requirements about the kind of signal that can be processed."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 16
                            }
                        ],
                        "text": "Equation 2 is a Gaussian Process estimate of the reward surface and can be used to select a fixation point for the next time step."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 234
                            }
                        ],
                        "text": "In this extended paper we show that a straightforward adaptation of our previous approach to the partial information setting results in poor performance, and we propose an alternative method based on modelling the reward surface as a Gaussian Process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 74
                            }
                        ],
                        "text": "We model the latent reward function rt(at|bt) , r(at|bt,\u03b8t) as a zero mean Gaus-\nsian Process\nr(at|bt,\u03b8t) \u223c GP(0, k(at, a\u2032t|bt,\u03b8t)) ,\nwhere bt is the belief state (see Section 3.1), and \u03b8t are the model hyperparameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 100
                            }
                        ],
                        "text": "We can instead learn a continuous policy by estimating the reward surface using a Gaussian Process (Rasmussen & Williams, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "The Gaussian Process regression is controlled by several hyperparameters (see Figure 6): \u03c32m controls the overall magnitude of the covariance, and \u03c3 2 n controls the amount of observation noise."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 52
                            }
                        ],
                        "text": "Gaussian Process priors encode this type of belief (Rasmussen & Williams, 2006), and have been used extensively for optimization of cost functions when it is important to minimize the total number of function evaluations (Brochu et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 24
                            }
                        ],
                        "text": "This is the strength of Gaussian Processes for this type of optimization problem, since the predictions can be used to balance exploration (choosing a fixation point where the reward is highly uncertain) and exploitation (choosing a point we are confident will have high reward)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 71
                            }
                        ],
                        "text": "MAP estimates can be made quickly using gradient optimization methods (Rasmussen & Williams, 2006), and informative priors provide resistance to the problems encountered with ML."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 209
                            }
                        ],
                        "text": "We show that a straightforward extension of the existing approach to the partial information setting results in poor performance, and we propose an alternative method based on modeling the reward surface as a Gaussian Process."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1430472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "isKey": true,
            "numCitedBy": 18076,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and deals with the supervised learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": ", 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 207168299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843959ffdccf31c6694d135fad07425924f785b1",
            "isKey": false,
            "numCitedBy": 5533,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite."
            },
            "slug": "Extracting-and-composing-robust-features-with-Vincent-Larochelle",
            "title": {
                "fragments": [],
                "text": "Extracting and composing robust features with denoising autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805742"
                        ],
                        "name": "Benjamin M Marlin",
                        "slug": "Benjamin-M-Marlin",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Marlin",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin M Marlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 120
                            }
                        ],
                        "text": "We also assume that readers are familiar with these models and, if otherwise, refer them to Ranzato & Hinton (2010) and Swersky et al. (2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2093667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f57625ce4c359c0f7aa082b364c7ea671fc7ac93",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "In this study, we provide a direct comparison of the Stochastic Maximum Likelihood algorithm and Contrastive Divergence for training Restricted Boltzmann Machines using the MNIST data set. We demonstrate that Stochastic Maximum Likelihood is superior when using the Restricted Boltzmann Machine as a classifier, and that the algorithm can be greatly improved using the technique of iterate averaging from the field of stochastic approximation. We further show that training with optimal parameters for classification does not necessarily lead to optimal results when Restricted Boltzmann Machines are stacked to form a Deep Belief Network. In our experiments we observe that fine tuning a Deep Belief Network significantly changes the distribution of the latent data, even though the parameter changes are negligible."
            },
            "slug": "A-tutorial-on-stochastic-approximation-algorithms-Swersky-Chen",
            "title": {
                "fragments": [],
                "text": "A tutorial on stochastic approximation algorithms for training Restricted Boltzmann Machines and Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is demonstrated that Stochastic Maximum Likelihood is superior when using the Restricted Boltzmann Machine as a classifier, and that the algorithm can be greatly improved using the technique of iterate averaging from the field of stochastic approximation."
            },
            "venue": {
                "fragments": [],
                "text": "2010 Information Theory and Applications Workshop (ITA)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143789814"
                        ],
                        "name": "J. Colombo",
                        "slug": "J.-Colombo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Colombo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Colombo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9806289,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "83e765296fdc1ab8f2130984feebf45aa78afdae",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past decade, the study of attention in infancy has seen dramatic progress. This review delineates four attentional functions (alertness, spatial orienting, attention to object features, and endogenous attention) that are relevant to infancy and uses these functions as a framework for summarizing the developmental course of attention in infancy. Rudimentary forms of various attentional functions are present at birth, but each of the functions exhibits different and apparently dissociable periods of postnatal change during the first years of life. The role of attention in development should therefore be considered in the context of interaction among different systems at different levels of maturity during the first years of life."
            },
            "slug": "The-development-of-visual-attention-in-infancy.-Colombo",
            "title": {
                "fragments": [],
                "text": "The development of visual attention in infancy."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This review delineates four attentional functions (alertness, spatial orienting, attention to object features, and endogenous attention) that are relevant to infancy and uses these functions as a framework for summarizing the developmental course of attention in infancy."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of psychology"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ba566223e426677d12a9a18418c023a4deec77e",
            "isKey": false,
            "numCitedBy": 13593,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390067049"
                        ],
                        "name": "R. O\u2019Reilly",
                        "slug": "R.-O\u2019Reilly",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "O\u2019Reilly",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. O\u2019Reilly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 86
                            }
                        ],
                        "text": "Deeper in the control pathway, we encounter an attentional mechanism that learns to select gazes so as to minimize tracking uncertainty."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140205235,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "bb35508ef1e1064037b57436fb18a17ff808161d",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-What-and-How-of-prefrontal-cortical-O\u2019Reilly",
            "title": {
                "fragments": [],
                "text": "The What and How of prefrontal cortical organization"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Neurosciences"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6483010"
                        ],
                        "name": "D. Buchman",
                        "slug": "D.-Buchman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Buchman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Buchman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805742"
                        ],
                        "name": "Benjamin M Marlin",
                        "slug": "Benjamin-M-Marlin",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Marlin",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin M Marlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 45
                            }
                        ],
                        "text": "For the first layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 122
                            }
                        ],
                        "text": "For the first layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 5450782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d851f681f82c71a934aebd16e8112adf1239f85",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider estimation methods for the class of continuous-data energy based models (EBMs). Our main result shows that estimating the parameters of an EBM using score matching when the conditional distribution over the visible units is Gaussian corresponds to training a particular form of regularized autoencoder. We show how different Gaussian EBMs lead to different autoencoder architectures, providing deep links between these two families of models. We compare the score matching estimator for the mPoT model, a particular Gaussian EBM, to several other training methods on a variety of tasks including image denoising and unsupervised feature extraction. We show that the regularization function induced by score matching leads to superior classification performance relative to a standard autoencoder. We also show that score matching yields classification results that are indistinguishable from better-known stochastic approximation maximum likelihood estimators."
            },
            "slug": "On-Autoencoders-and-Score-Matching-for-Energy-Based-Swersky-Ranzato",
            "title": {
                "fragments": [],
                "text": "On Autoencoders and Score Matching for Energy Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work compares the score matching estimator for the mPoT model, a particular Gaussian EBM, to several other training methods on a variety of tasks including image denoising and unsupervised feature extraction and shows that the regularization function induced by score matching leads to superior classification performance relative to a standard autoencoder."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 533055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f7476037408ac3d993f5088544aab427bc319c1",
            "isKey": false,
            "numCitedBy": 1959,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : At this early stage in the development of cognitive science, methodological issues are both open and central. There may have been times when developments in neuroscience, artificial intelligence, or cognitive psychology seduced researchers into believing that their discipline was on the verge of discovering the secret of intelligence. But a humbling history of hopes disappointed has produced the realization that understanding the mind will challenge the power of all these methodologies combined. The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis. The success of cognitive science, like that of many other sciences, will, I believe, depend upon the construction of a solid body of theoretical results: results that express in a mathematical language the conceptual insights of the field; results that squeeze all possible implications out of those insights by exploiting powerful mathematical techniques. This body of results, which I will call the theory of information processing, exists because information is a concept that lends itself to mathematical formalization. One part of the theory of information processing is already well-developed. The classical theory of computation provides powerful and elegant results about the notion of effective procedure, including languages for precisely expressing them and theoretical machines for realizing them."
            },
            "slug": "Information-processing-in-dynamical-systems:-of-Smolensky",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical systems: foundations of harmony theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709512"
                        ],
                        "name": "L. Kaelbling",
                        "slug": "L.-Kaelbling",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Kaelbling",
                            "middleNames": [
                                "Pack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kaelbling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2453007"
                        ],
                        "name": "A. Cassandra",
                        "slug": "A.-Cassandra",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Cassandra",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cassandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In doing so, the new reward becomes the expectation of the immediate reward with respect to the belief state (Kaelbling, Littman, & Cassandra,  1998 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5613003,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "116d7798c1123cf7fad4176e98f58fd49de4f8f1",
            "isKey": false,
            "numCitedBy": 3979,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Planning-and-Acting-in-Partially-Observable-Domains-Kaelbling-Littman",
            "title": {
                "fragments": [],
                "text": "Planning and Acting in Partially Observable Stochastic Domains"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Given a collection of randomly sampled fixations, the first-layer RBM weights  W  and biases  d ,  b  can be trained using contrastive divergence (Hinton,  2002 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4595,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144998829"
                        ],
                        "name": "N. Gordon",
                        "slug": "N.-Gordon",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gordon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 63
                            }
                        ],
                        "text": "The localization module is implemented with a particle filter (Doucet et al., 2001) which estimates the location, velocity and scale of the target object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 78
                            }
                        ],
                        "text": "The use of a selection step is key to making the SMC procedure effective; see Doucet et al. (2001) for details on how to implement this black box routine."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "We refer readers to Doucet et al. (2001) for a more in depth treatment of these sequential Monte Carlo methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115173091,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "29a7909befef95c6149032b3f3a47d5e7088c0f5",
            "isKey": false,
            "numCitedBy": 1163,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world data analysis tasks involve estimating unknown quantities from some given observations. In most of these applications, prior knowledge about the phenomenon being modelled is available. This knowledge allows us to formulate Bayesian models, that is prior distributions for the unknown quantities and likelihood functions relating these quantities to the observations. Within this setting, all inference on the unknown quantities is based on the posterior distribution obtained from Bayes\u2019 theorem. Often, the observations arrive sequentially in time and one is interested in performing inference on-line. It is therefore necessary to update the posterior distribution as data become available. Examples include tracking an aircraft using radar measurements, estimating a digital communications signal using noisy measurements, or estimating the volatility of financial instruments using stock market data. Computational simplicity in the form of not having to store all the data might also be an additional motivating factor for sequential methods."
            },
            "slug": "An-Introduction-to-Sequential-Monte-Carlo-Methods-Doucet-Freitas",
            "title": {
                "fragments": [],
                "text": "An Introduction to Sequential Monte Carlo Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Many real-world data analysis tasks involve estimating unknown quantities from some given observations, and all inference on the unknown quantities is based on the posterior distribution obtained from Bayes\u2019 theorem."
            },
            "venue": {
                "fragments": [],
                "text": "Sequential Monte Carlo Methods in Practice"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221163"
                        ],
                        "name": "Vlad M. Cora",
                        "slug": "Vlad-M.-Cora",
                        "structuredName": {
                            "firstName": "Vlad",
                            "lastName": "Cora",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vlad M. Cora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 98
                            }
                        ],
                        "text": "By assuming that the reward surface is smooth, we can draw on the tools of Bayesian optimization (Brochu et al., 2010) to search for the optimal gaze location using as few exploratory steps as possible."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 222
                            }
                        ],
                        "text": "Gaussian Process priors encode this type of belief (Rasmussen & Williams, 2006), and have been used extensively for optimization of cost functions when it is important to minimize the total number of function evaluations (Brochu et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1640103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd5a26b89f0799db1cbc1dff5607cb6815739fe7",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences."
            },
            "slug": "A-Tutorial-on-Bayesian-Optimization-of-Expensive-to-Brochu-Cora",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions using the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107603179"
                        ],
                        "name": "D. R. Jones",
                        "slug": "D.-R.-Jones",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563797"
                        ],
                        "name": "C. D. Perttunen",
                        "slug": "C.-D.-Perttunen",
                        "structuredName": {
                            "firstName": "Cary",
                            "lastName": "Perttunen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Perttunen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424124"
                        ],
                        "name": "B. Stuckman",
                        "slug": "B.-Stuckman",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Stuckman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stuckman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 15
                            }
                        ],
                        "text": "We use DIRECT (Jones et al., 1993) due to the existence of a readily available implementation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123674634,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7808f2ad77de7b71e83a2e79d27f2e3e12be8d5",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm for finding the global minimum of a multivariate function subject to simple bounds. The algorithm is a modification of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. This is done by carrying out simultaneous searches using all possible constants from zero to infinity. On nine standard test functions, the new algorithm converges in fewer function evaluations than most competing methods.The motivation for the new algorithm stems from a different way of looking at the Lipschitz constant. In particular, the Lipschitz constant is viewed as a weighting parameter that indicates how much emphasis to place on global versus local search. In standard Lipschitzian methods, this constant is usually large because it must equal or exceed the maximum rate of change of the objective function. As a result, these methods place a high emphasis on global search and exhibit slow convergence. In contrast, the new algorithm carries out simultaneous searches using all possible constants, and therefore operates at both the global and local level. Once the global part of the algorithm finds the basin of convergence of the optimum, the local part of the algorithm quickly and automatically exploits it. This accounts for the fast convergence of the new algorithm on the test functions."
            },
            "slug": "Lipschitzian-optimization-without-the-Lipschitz-Jones-Perttunen",
            "title": {
                "fragments": [],
                "text": "Lipschitzian optimization without the Lipschitz constant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13456135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d584316be99e2db3fec3fbf7d71f22a477f67",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model can be represented by a particular type of Boltzmann machine with a bipartite graph structure that we call the combination machine. This machine is closely related to the Harmonium model defined by Smolensky. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first learning algorithm is the standard gradient ascent heuristic for computing maximum likelihood estimates for the parameters of the model. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images."
            },
            "slug": "Unsupervised-Learning-of-Distributions-of-Binary-Freund-Haussler",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Distributions of Binary Vectors Using 2-Layer Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that arbitrary distributions of binary vectors can be approximated by the combination model and shown how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157110"
                        ],
                        "name": "Niranjan Srinivas",
                        "slug": "Niranjan-Srinivas",
                        "structuredName": {
                            "firstName": "Niranjan",
                            "lastName": "Srinivas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niranjan Srinivas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695232"
                        ],
                        "name": "S. Kakade",
                        "slug": "S.-Kakade",
                        "structuredName": {
                            "firstName": "Sham",
                            "lastName": "Kakade",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kakade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 29
                            }
                        ],
                        "text": "In this paper we use GP-UCB (Srinivas et al., 2010) which selects\nat+1 = arg max a\nmt(a) + \u221a \u03b2tst(a) (3)\nwhere \u03b2t is a parameter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 29
                            }
                        ],
                        "text": "Speed is an issue here since GP-UCB requires that we optimize a function of the posterior process at each time step so, for instance, computing Monte Carlo averages for each evaluation of Equation 2 is prohibitively slow."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 28
                            }
                        ],
                        "text": "In this paper we use GP-UCB (Srinivas et al., 2010) which selects"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59031327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c8413ab8de0c1b8f2e86402b8d737d94371610f",
            "isKey": true,
            "numCitedBy": 1656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches."
            },
            "slug": "Gaussian-Process-Optimization-in-the-Bandit-No-and-Srinivas-Krause",
            "title": {
                "fragments": [],
                "text": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work analyzes GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design and obtaining explicit sublinear regret bounds for many commonly used covariance functions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 45
                            }
                        ],
                        "text": "For the first layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 100
                            }
                        ],
                        "text": "For the first layers, we use (factored)-RBMs (Hinton & Salakhutdinov, 2006; Ranzato & Hinton, 2010; Welling et al., 2005; Swersky et al., 2011), but autoencoders (Vincent et al., 2008), sparse coding (Olshausen & Field, 1996; Kavukcuoglu et al., 2009), two-layer ICA (Ko\u0308ster & Hyva\u0308rinen, 2007) and\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2388827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2184fb6d32bc46f252b940035029273563c4fc82",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords."
            },
            "slug": "Exponential-Family-Harmoniums-with-an-Application-Welling-Rosen-Zvi",
            "title": {
                "fragments": [],
                "text": "Exponential Family Harmoniums with an Application to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An alternative two-layer model based on exponential family distributions and the semantics of undirected models is proposed, which performs well on document retrieval tasks and provides an elegant solution to searching with keywords."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are many selection methods available in the literature that offer different trade-offs between these two criteria (Hoffman, Brochu, & de Freitas,  2011 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8053165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa068e347fe8fcec0b5c6497a9d3c7790dc46f56",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the model's estimate of the objective and the uncertainty at any given point. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance."
            },
            "slug": "Portfolio-Allocation-for-Bayesian-Optimization-Hoffman-Brochu",
            "title": {
                "fragments": [],
                "text": "Portfolio Allocation for Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A portfolio of acquisition functions governed by an online multi-armed bandit strategy is proposed, the best of which is called GP-Hedge, and it is shown that this method outperforms the best individual acquisition function."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 6
                            }
                        ],
                        "text": "EXP3 (Auer et al., 2001) is a generalization of Hedge to the partial information setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 60
                            }
                        ],
                        "text": "EXP3 is an extension of Hedge to partial information games (Auer et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13209702,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "26e17f6b62a7caec660b3356d49e879e6e0eeabc",
            "isKey": false,
            "numCitedBy": 1984,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In the multiarmed bandit problem, a gambler must decide which arm of K nonidentical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. \nIn this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the per-round payoff of our algorithm approaches that of the best arm at the rate O(T-1/2). We show by a matching lower bound that this is the best possible. \nWe also prove that our algorithm approaches the per-round payoff of any set of strategies at a similar rate: if the best strategy is chosen from a pool of N strategies, then our algorithm approaches the per-round payoff of the strategy at the rate O((log N1/2 T-1/2). Finally, we apply our results to the problem of playing an unknown repeated matrix game. We show that our algorithm approaches the minimax payoff of the unknown game at the rate O(T-1/2)."
            },
            "slug": "The-Nonstochastic-Multiarmed-Bandit-Problem-Auer-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "The Nonstochastic Multiarmed Bandit Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14754,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 53
                            }
                        ],
                        "text": "Our previous work (Bazzani et al., 2010) used Hedge (Auer et al., 1998a; Freund & Schapire, 1997) to learn this policy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 172
                            }
                        ],
                        "text": "In an earlier version of this work (Bazzani et al., 2010) we learned the gaze selection policy with a portfolio allocation algorithm called Hedge (Freund & Schapire, 1997; Auer et al., 1998b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 39
                            }
                        ],
                        "text": "To use Hedge (Freund & Schapire, 1997; Auer et al., 1998b) for gaze selection we must first discretize the action space by selecting a fixed finite number of possible fixation points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8963242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "305d689afb6574ffec7b01e24431d541d0ce6f5d",
            "isKey": false,
            "numCitedBy": 829,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the expected per-round payoff of our algorithm approaches that of the best arm at the rate O(T/sup -1/3/), and we give an improved rate of convergence when the best arm has fairly low payoff. We also consider a setting in which the player has a team of \"experts\" advising him on which arm to play; here, we give a strategy that will guarantee expected payoff close to that of the best expert. Finally, we apply our result to the problem of learning to play an unknown repeated matrix game against an all-powerful adversary."
            },
            "slug": "Gambling-in-a-rigged-casino:-The-adversarial-bandit-Auer-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "Gambling in a rigged casino: The adversarial multi-armed bandit problem"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs is given."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE 36th Annual Foundations of Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145313556"
                        ],
                        "name": "D. McDermott",
                        "slug": "D.-McDermott",
                        "structuredName": {
                            "firstName": "Drew",
                            "lastName": "McDermott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McDermott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207056046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7d927cda381864aeaf4f4d2aa15d5ec05ffcdee",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A new theory of problem solving is presented, which embeds problem solving in the theory of action; in this theory, a problem is just a difficult action. Making this work requires a sophisticated language for talking about plans and their execution. This language allows a broad range of types of action, and can also be used to express rules for choosing and scheduling plans. To ensure flexibility, the problem solver consists of an interpreter driven by a theorem prover which actually manipulates formulas of the language. Many examples of the use of the system are given, including an extended treatment of the world of blocks. Limitations and extensions of the system are discussed at length. It is concluded that a rule-based problem solver is necessary and feasible, but that much more work remains to be done on the underlying theory of planning and acting."
            },
            "slug": "Planning-and-Acting-McDermott",
            "title": {
                "fragments": [],
                "text": "Planning and Acting"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is concluded that a rule-based problem solver is necessary and feasible, but that much more work remains to be done on the underlying theory of planning and acting."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21145246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e95d3934e51107da7610acd0b1bcb6551671f9f1",
            "isKey": false,
            "numCitedBy": 2752,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines (RBMs) have been used as generative models of many different types of data. RBMs are usually trained using the contrastive divergence learning procedure. This requires a certain amount of practical experience to decide how to set the values of numerical meta-parameters. Over the last few years, the machine learning group at the University of Toronto has acquired considerable expertise at training RBMs and this guide is an attempt to share this expertise with other machine learning researchers."
            },
            "slug": "A-Practical-Guide-to-Training-Restricted-Boltzmann-Hinton",
            "title": {
                "fragments": [],
                "text": "A Practical Guide to Training Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This guide is an attempt to share expertise at training restricted Boltzmann machines with other machine learning researchers."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 53
                            }
                        ],
                        "text": "Our previous work (Bazzani et al., 2010) used Hedge (Auer et al., 1998a; Freund & Schapire, 1997) to learn this policy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 172
                            }
                        ],
                        "text": "In an earlier version of this work (Bazzani et al., 2010) we learned the gaze selection policy with a portfolio allocation algorithm called Hedge (Freund & Schapire, 1997; Auer et al., 1998b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 13
                            }
                        ],
                        "text": "To use Hedge (Freund & Schapire, 1997; Auer et al., 1998) for gaze selection, we must first discretize the action space by selecting a fixed finite number of possible fixation points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 39
                            }
                        ],
                        "text": "To use Hedge (Freund & Schapire, 1997; Auer et al., 1998b) for gaze selection we must first discretize the action space by selecting a fixed finite number of possible fixation points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gambling in a rigged"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830863"
                        ],
                        "name": "Leslie G. Ungerleider",
                        "slug": "Leslie-G.-Ungerleider",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Ungerleider",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leslie G. Ungerleider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Separation of responsibility is a common feature in models from the computational neuroscience literature, as it is believed to reflect a separation of information processing into ventral and dorsal pathways in the human brain (Ungerleider & Mishkin,  1982 ; Goodale & Milner,  1992 ; Olshausen, Anderson, & Van Essen,  1993 ; O'Reilly,  2010 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 142774685,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2d095a0107e849fdf8fb982daca3a0499ea9881a",
            "isKey": false,
            "numCitedBy": 4916,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-cortical-visual-systems-Ungerleider",
            "title": {
                "fragments": [],
                "text": "Two cortical visual systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The discriminant center-surround"
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging (pp. 202\u2013210)"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to sequential Monte Carlo meth"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two cortial visual systems. pp. 549\u2013586"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition (pp. 1605\u20131612)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 13
                            }
                        ],
                        "text": "Najemnik and Geisler (2005) is another example of a model performing estimation and control, but in a visual search task in which the estimation of belief is nonlinear and the control policy is greedy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The representation of visual"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Monte Carlo methods in practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 6
                            }
                        ],
                        "text": "Deeper in the control pathway, we encounter an attentional mechanism that learns to select gazes so as to minimize tracking uncertainty."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two cortial visual systems"
            },
            "venue": {
                "fragments": [],
                "text": "Two cortial visual systems"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 30,
            "methodology": 20
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 71,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Where-to-Attend-with-Deep-Architectures-Denil-Bazzani/72829d537f0ec8b1cc0ced2f278bb56ce89f1b0c?sort=total-citations"
}