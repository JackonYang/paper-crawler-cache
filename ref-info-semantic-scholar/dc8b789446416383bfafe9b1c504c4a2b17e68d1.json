{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145834074"
                        ],
                        "name": "Han Cai",
                        "slug": "Han-Cai",
                        "structuredName": {
                            "firstName": "Han",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Han Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117181341"
                        ],
                        "name": "Tianyao Chen",
                        "slug": "Tianyao-Chen",
                        "structuredName": {
                            "firstName": "Tianyao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianyao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108309275"
                        ],
                        "name": "Weinan Zhang",
                        "slug": "Weinan-Zhang",
                        "structuredName": {
                            "firstName": "Weinan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weinan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39055225"
                        ],
                        "name": "Jun Wang",
                        "slug": "Jun-Wang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 42
                            }
                        ],
                        "text": "Furthermore, compared with PathLevel EAS (Cai et al., 2018b) that also explores the tree-structured architecture space, both Proxyless-G and Proxyless-R achieves similar or lower test error rate results with half fewer parameters."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For CIFAR-10 experiments, we use the tree-structured architecture space that is introduced by Cai et al. (2018b) with PyramidNet (Han et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 191
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 191
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "For CIFAR-10 experiments, we use the tree-structured architecture space that is introduced by Cai et al. (2018b) with PyramidNet (Han et al., 2017) as the backbone3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 98
                            }
                        ],
                        "text": "For further details about the tree-structured architecture space, we refer to the original paper (Cai et al., 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 108
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7918068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84e65a5bdb735d62eef4f72c2f01af354b2285ba",
            "isKey": false,
            "numCitedBy": 422,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Techniques for automatically designing deep neural network architectures such as reinforcement learning based approaches have recently shown promising results. However, their success is based on vast computational resources (e.g. hundreds of GPUs), making them difficult to be widely used. A noticeable limitation is that they still design and train each network from scratch during the exploration of the architecture space, which is highly inefficient. In this paper, we propose a new framework toward efficient architecture search by exploring the architecture space based on the current network and reusing its weights. We employ a reinforcement learning agent as the meta-controller, whose action is to grow the network depth or layer width with function-preserving transformations. As such, the previously validated networks can be reused for further exploration, thus saves a large amount of computational cost. We apply our method to explore the architecture space of the plain convolutional neural networks (no skip-connections, branching etc.) on image benchmark datasets (CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our method can design highly competitive networks that outperform existing networks using the same design scheme. On CIFAR-10, our model without skip-connections achieves 4.23% test error rate, exceeding a vast majority of modern architectures and approaching DenseNet. Furthermore, by applying our method to explore the DenseNet architecture space, we are able to achieve more accurate networks with fewer parameters.\n \n"
            },
            "slug": "Efficient-Architecture-Search-by-Network-Cai-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Architecture Search by Network Transformation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a new framework toward efficient architecture search by exploring the architecture space based on the current network and reusing its weights, and employs a reinforcement learning agent as the meta-controller, whose action is to grow the network depth or layer width with function-preserving transformations."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143950636"
                        ],
                        "name": "Hieu Pham",
                        "slug": "Hieu-Pham",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Pham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152565355"
                        ],
                        "name": "M. Guan",
                        "slug": "M.-Guan",
                        "structuredName": {
                            "firstName": "Melody",
                            "lastName": "Guan",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48448318"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Pham et al. (2018) propose to share weights among all sampled networks under the standard NAS framework (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 39
                            }
                        ],
                        "text": "Some recent works (Brock et al., 2018; Pham et al., 2018) try to improve the efficiency of this meta-learning process by reducing the cost of getting an evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 258
                            }
                        ],
                        "text": "2 RELATED WORK The use of machine learning techniques, such as reinforcement learning or neuro-evolution, to replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 212
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3638969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7",
            "isKey": true,
            "numCitedBy": 1735,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. In ENAS, a controller learns to discover neural network architectures by searching for an optimal subgraph within a large computational graph. The controller is trained with policy gradient to select a subgraph that maximizes the expected reward on the validation set. Meanwhile the model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Thanks to parameter sharing between child models, ENAS is fast: it delivers strong empirical performances using much fewer GPU-hours than all existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On the Penn Treebank dataset, ENAS discovers a novel architecture that achieves a test perplexity of 55.8, establishing a new state-of-the-art among all methods without post-training processing. On the CIFAR-10 dataset, ENAS designs novel architectures that achieve a test error of 2.89%, which is on par with NASNet (Zoph et al., 2018), whose test error is 2.65%."
            },
            "slug": "Efficient-Neural-Architecture-Search-via-Parameter-Pham-Guan",
            "title": {
                "fragments": [],
                "text": "Efficient Neural Architecture Search via Parameter Sharing"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Efficient Neural Architecture Search is a fast and inexpensive approach for automatic model design that establishes a new state-of-the-art among all methods without post-training processing and delivers strong empirical performances using much fewer GPU-hours."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068605434"
                        ],
                        "name": "Ningning Ma",
                        "slug": "Ningning-Ma",
                        "structuredName": {
                            "firstName": "Ningning",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ningning Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16215052"
                        ],
                        "name": "Haitao Zheng",
                        "slug": "Haitao-Zheng",
                        "structuredName": {
                            "firstName": "Haitao",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haitao Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5) (Ma et al., 2018) 72."
                    },
                    "intents": []
                }
            ],
            "corpusId": 51880435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c02b909a514af6b9255315e2d50112845ca5ed0e",
            "isKey": false,
            "numCitedBy": 1910,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, the neural network architecture design is mostly guided by the indirect metric of computation complexity, i.e., FLOPs. However, the direct metric, e.g., speed, also depends on the other factors such as memory access cost and platform characterics. Thus, this work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs. Based on a series of controlled experiments, this work derives several practical guidelines for efficient network design. Accordingly, a new architecture is presented, called ShuffleNet V2. Comprehensive ablation experiments verify that our model is the state-of-the-art in terms of speed and accuracy tradeoff."
            },
            "slug": "ShuffleNet-V2:-Practical-Guidelines-for-Efficient-Ma-Zhang",
            "title": {
                "fragments": [],
                "text": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs, and derives several practical guidelines for efficient network design, called ShuffleNet V2."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065040247"
                        ],
                        "name": "Andrew Brock",
                        "slug": "Andrew-Brock",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Brock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Brock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067962067"
                        ],
                        "name": "Theodore Lim",
                        "slug": "Theodore-Lim",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodore Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50361260"
                        ],
                        "name": "J. Ritchie",
                        "slug": "J.-Ritchie",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Ritchie",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ritchie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32233090"
                        ],
                        "name": "Nick Weston",
                        "slug": "Nick-Weston",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 19
                            }
                        ],
                        "text": "Some recent works (Brock et al., 2018; Pham et al., 2018) try to improve the efficiency of this meta-learning process by reducing the cost of getting an evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 258
                            }
                        ],
                        "text": "2 RELATED WORK The use of machine learning techniques, such as reinforcement learning or neuro-evolution, to replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 231
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Brock et al. (2018), a hypernetwork is utilized to generate weights for each sampled network and hence can evaluate the architecture without training it."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3489117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e56b10f7cd4bf037beac84da5925dc4544fab974",
            "isKey": true,
            "numCitedBy": 525,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing architectures for deep neural networks requires expert knowledge and substantial computation time. We propose a technique to accelerate architecture selection by learning an auxiliary HyperNet that generates the weights of a main model conditioned on that model's architecture. By comparing the relative validation performance of networks with HyperNet-generated weights, we can effectively search over a wide range of architectures at the cost of a single training run. To facilitate this search, we develop a flexible mechanism based on memory read-writes that allows us to define a wide range of network connectivity patterns, with ResNet, DenseNet, and FractalNet blocks as special cases. We validate our method (SMASH) on CIFAR-10 and CIFAR-100, STL-10, ModelNet10, and Imagenet32x32, achieving competitive performance with similarly-sized hand-designed networks. Our code is available at this https URL"
            },
            "slug": "SMASH:-One-Shot-Model-Architecture-Search-through-Brock-Lim",
            "title": {
                "fragments": [],
                "text": "SMASH: One-Shot Model Architecture Search through HyperNetworks"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A technique to accelerate architecture selection by learning an auxiliary HyperNet that generates the weights of a main model conditioned on that model's architecture is proposed, achieving competitive performance with similarly-sized hand-designed networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120805419"
                        ],
                        "name": "Mingxing Tan",
                        "slug": "Mingxing-Tan",
                        "structuredName": {
                            "firstName": "Mingxing",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxing Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34320634"
                        ],
                        "name": "Ruoming Pang",
                        "slug": "Ruoming-Pang",
                        "structuredName": {
                            "firstName": "Ruoming",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruoming Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51891697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "693c97ecedb0a84539b7162c95e89fa3cd84ca73",
            "isKey": false,
            "numCitedBy": 1613,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8\u00d7 faster than MobileNetV2 with 0.5% higher accuracy and 2.3\u00d7 faster than NASNet with 1.2% higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet."
            },
            "slug": "MnasNet:-Platform-Aware-Neural-Architecture-Search-Tan-Chen",
            "title": {
                "fragments": [],
                "text": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2501244"
                        ],
                        "name": "T. Elsken",
                        "slug": "T.-Elsken",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Elsken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Elsken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2708564"
                        ],
                        "name": "J. H. Metzen",
                        "slug": "J.-H.-Metzen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Metzen",
                            "middleNames": [
                                "Hendrik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Metzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i.e. latency)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 272
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 126360911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7645f35545a66b0669c56c6d34d2df3c8eacdabf",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Architecture search aims at automatically finding neural architectures that are competitive with architectures designed by human experts. While recent approaches have come close to matching the predictive performance of manually designed architectures for image recognition, these approaches are problematic under constrained resources for two reasons: first, the architecture search itself requires vast computational resources for most proposed methods. Secondly, the found neural architectures are solely optimized for high predictive performance without penalizing excessive resource consumption. We address the first shortcoming by proposing NASH, an architecture search which considerable reduces the computational resources required for training novel architectures by applying network morphisms and aggressive learning rate schedules. On CIFAR10, NASH finds architectures with errors below 4% in only 3 days. We address the second shortcoming by proposing Pareto-NASH, a method for multi-objective architecture search that allows approximating the Pareto-front of architectures under multiple objective, such as predictive performance and number of parameters, in a single run of the method. Within 56 GPU days of architecture search, Pareto-NASH finds a model with 4M parameters and test error of 3.5%, as well as a model with less than 1M parameters and test error of 4.6%."
            },
            "slug": "Multi-objective-Architecture-Search-for-CNNs-Elsken-Metzen",
            "title": {
                "fragments": [],
                "text": "Multi-objective Architecture Search for CNNs"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work proposes NASH, an architecture search which considerable reduces the computational resources required for training novel architectures by applying network morphisms and aggressive learning rate schedules and proposes Pareto-NASH, a method for multi-objective architecture search that allows approximating the Pare to-front of architectures under multiple objective, such as predictive performance and number of parameters, in a single run of the method."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2501244"
                        ],
                        "name": "T. Elsken",
                        "slug": "T.-Elsken",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Elsken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Elsken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2708564"
                        ],
                        "name": "J. H. Metzen",
                        "slug": "J.-H.-Metzen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Metzen",
                            "middleNames": [
                                "Hendrik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Metzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 258
                            }
                        ],
                        "text": "2 RELATED WORK The use of machine learning techniques, such as reinforcement learning or neuro-evolution, to replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 272
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26945723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e0ee672ebd9ec0019c414d1c0524f3bb888dd6d",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks have recently had a lot of success for many tasks. However, neural network architectures that perform well are still typically designed manually by experts in a cumbersome trial-and-error process. We propose a new method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms, followed by short optimization runs by cosine annealing. Surprisingly, this simple method yields competitive results, despite only requiring resources in the same order of magnitude as training a single network. E.g., on CIFAR-10, our method designs and trains networks with an error rate below 6% in only 12 hours on a single GPU; training for one day reduces this error further, to almost 5%."
            },
            "slug": "Simple-And-Efficient-Architecture-Search-for-Neural-Elsken-Metzen",
            "title": {
                "fragments": [],
                "text": "Simple And Efficient Architecture Search for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Surprisingly, this simple method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms, followed by short optimization runs by cosine annealing yields competitive results."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46181955"
                        ],
                        "name": "Jin-Dong Dong",
                        "slug": "Jin-Dong-Dong",
                        "structuredName": {
                            "firstName": "Jin-Dong",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-Dong Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26921530"
                        ],
                        "name": "A. Cheng",
                        "slug": "A.-Cheng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854012"
                        ],
                        "name": "Da-Cheng Juan",
                        "slug": "Da-Cheng-Juan",
                        "structuredName": {
                            "firstName": "Da-Cheng",
                            "lastName": "Juan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Da-Cheng Juan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149192010"
                        ],
                        "name": "Wei Wei",
                        "slug": "Wei-Wei",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718481"
                        ],
                        "name": "Min Sun",
                        "slug": "Min-Sun",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 44
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i.e. latency)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49338430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8563b6545a8ff8d17a74da1f70f57c4a7d9a38bc",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent breakthroughs in Neural Architectural Search (NAS) have achieved state-of-the-art performances in applications such as image classification and language modeling. However, these techniques typically ignore device-related objectives such as inference time, memory usage, and power consumption. Optimizing neural architecture for device-related objectives is immensely crucial for deploying deep networks on portable devices with limited computing resources. We propose DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures, optimizing for both device-related (e.g., inference time and memory usage) and device-agnostic (e.g., accuracy and model size) objectives. DPP-Net employs a compact search space inspired by current state-of-the-art mobile CNNs, and further improves search efficiency by adopting progressive search (Liu et al. 2017). Experimental results on CIFAR-10 are poised to demonstrate the effectiveness of Pareto-optimal networks found by DPP-Net, for three different devices: (1) a workstation with Titan X GPU, (2) NVIDIA Jetson TX1 embedded system, and (3) mobile phone with ARM Cortex-A53. Compared to CondenseNet and NASNet (Mobile), DPP-Net achieves better performances: higher accuracy & shorter inference time on various devices. Additional experimental results show that models found by DPP-Net also achieve considerably-good performance on ImageNet as well."
            },
            "slug": "DPP-Net:-Device-aware-Progressive-Search-for-Neural-Dong-Cheng",
            "title": {
                "fragments": [],
                "text": "DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "DPP-Net is proposed: Device-aware Progressive Search for Pareto-optimal Neural Architectures, optimizing for both device-related and device-agnostic objectives, which achieves better performances: higher accuracy & shorter inference time on various devices."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391802"
                        ],
                        "name": "Hanxiao Liu",
                        "slug": "Hanxiao-Liu",
                        "structuredName": {
                            "firstName": "Hanxiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanxiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "Unlike previous NAS works (Zoph et al., 2018; Liu et al., 2018c) that first learn CNN blocks on CIFAR-10 under small-scale setting (e.g. fewer blocks), then transfer the learned block to ImageNet or CIFAR-10 under large-scale setting by repeatedly stacking it, we directly learn the architectures on\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "(3) and Figure 2, by using the binary gates rather than real-valued path weights (Liu et al., 2018c), only one path of activation is active in memory at run-time and the memory requirement of training the over-parameterized network is thus reduced to the same level of training a compact model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "However, naively including all the candidate paths leads to GPU memory explosion (Liu et al., 2018c; Bender et al., 2018), as the memory consumption grows linearly w.r.t. the number of choices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 78
                            }
                        ],
                        "text": "Our work is most closely related to One-Shot (Bender et al., 2018) and DARTS (Liu et al., 2018c), both of which get rid of the meta-controller (or hypernetwork) by modeling NAS as a single training process of an over-parameterized network that comprises all candidate paths."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "We also remove the restriction of repeating blocks in previous NAS works (Zoph et al., 2018; Liu et al., 2018c) and allow all of the blocks to be learned and specified."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "Therefore, One-Shot and DARTS roughly need N times GPU memory and GPU hours compared to training a compact model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 450,
                                "start": 445
                            }
                        ],
                        "text": "MIT Red\nM B\n1 3x\n3\nM B\n3 5x\n5\nM B\n3 7x\n7\nM B\n6 7x\n7\nM B\n3 5x\n5\nM B\n6 5x\n5\nM B\n3 3x\n3\nM B\n3 5x\n5\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 5x\n5\nM B\n6 7x\n7\nC on\nv 3x\n3\nPo ol\nin g\nFC\nM B\n3 3x\n3 4 0x\n11 2x\n11 2\n24 x1\n12 x1 12\n3x 22\n4x 22 4\n32 x5\n6x 56\n56 x2\n8x 28\n56 x2\n8x 28\n11 2x\n14 x1 4\n11 2x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n43 2x\n7x 7\n1\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\n1\ncializing network architectures for different platforms by directly incorporating the measured hardware latency into optimization objectives."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 210
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 168
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 131
                            }
                        ],
                        "text": "L G\n] 2\nD ec\n2 01\n8\n(1) Previous proxy-based approach (2) Our proxy-less approach\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\nproxy (Figure 1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 757,
                                "start": 752
                            }
                        ],
                        "text": "AAADIHicfVJNb9QwEHXCVwlfWzhysViBipBWSUuBC1IFAnHgUCS2rbSOVo4zm7Xq2JHtVBui8E+48Fe4cAAhuMGvwUnDV7vLSJaeZuZ53jw7KQQ3Ngy/e/6Zs+fOX1i7GFy6fOXqtcH69T2jSs1gzJRQ+iChBgSXMLbcCjgoNNA8EbCfHD5t6/tHoA1X8rWtCohzmkk+44xal5quew9IAhmXNRU8k5A2AcmpnSdJ/ayZdFDn9UtqQbKqifFjfOctsbCw3eQ6ESU0NaGimNMGE8tzMPj5xi8eU/KITLcWW81dfA8TEiwjJ2AddxV5e7H9P7LhWb5sMk9BOjeqP9xRF6vuebNCRKGU6DcICMj0t03TwTAchV3g0yDqwRD1sTsdfCOpYmXudDFBjZlEYWHjmmrLmQBne2mgoOyQZjBxUFInJK47kQ2+7TIpnintjrS4y/7NqGluTJUnrrMVbk7W2uSy2qS0s0dxzWVRti98PGhWCmwVbn8LTrkGZkXlAGWaO62YzammzLo/FTgTopMrnwZ7m6MoHEWv7g93nvR2rKGb6BbaQBF6iHbQC7SLxoh577wP3ifvs//e/+h/8b8et/pez7mB/gn/x09YVgHC</latexit>\nthe weights are calculated by applying softmax to N real-valued architecture parameters {\u03b1i}:\nmOne-ShotO (x) =\nN\u2211\ni=1\noi(x), m DARTS O (x) =\nN\u2211\ni=1\npioi(x) =\nN\u2211\ni=1\nexp(\u03b1i)\u2211 j exp(\u03b1j) oi(x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "GPU hour-wise, inspired by recent works (Liu et al., 2018c; Bender et al., 2018), we formulate NAS as a path-level pruning process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "DARTS additionally introduces a real-valued architecture parameter for each path and jointly train weight parameters and architecture parameters via standard gradient descent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "Notably, such kind of patterns cannot be captured in previous NAS methods as they force the blocks to share the same structure (Zoph et al., 2018; Liu et al., 2018a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 68
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "In One-Shot,mO(x) is the sum of {oi(x)}, while in DARTS,mO(x) is weighted sum of {oi(x)}where\nMIT Red\nTrainer Latency Model\nDirect measurement: expensive and slow\nLatency modeling: cheap, fast and differentiable\nMIT Red-1\nLearnable Block i - 1\nLearnable Block i\n\u2026\u2026\nLearnable Block i + 1\n\u2026\u2026\nINPUT\nOUTPUT\n...\n\u03b1 \u03b2 \u03c3 \u2026 \u03b6 CONV\n5x5 POOL 3x3 CONV 3x3 Identity\nE[latency] = X\ni E[latencyi]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 49411844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1f457e31b611da727f9aef76c283a18157dfa83",
            "isKey": true,
            "numCitedBy": 2237,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques. Our implementation has been made publicly available to facilitate further research on efficient architecture search algorithms."
            },
            "slug": "DARTS:-Differentiable-Architecture-Search-Liu-Simonyan",
            "title": {
                "fragments": [],
                "text": "DARTS: Differentiable Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The proposed algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90833706"
                        ],
                        "name": "Zhaobai Zhong",
                        "slug": "Zhaobai-Zhong",
                        "structuredName": {
                            "firstName": "Zhaobai",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaobai Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721677"
                        ],
                        "name": "Junjie Yan",
                        "slug": "Junjie-Yan",
                        "structuredName": {
                            "firstName": "Junjie",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junjie Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39533001"
                        ],
                        "name": "Wei Wu",
                        "slug": "Wei-Wu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388486428"
                        ],
                        "name": "Jing Shao",
                        "slug": "Jing-Shao",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 188
                            }
                        ],
                        "text": "1 1 INTRODUCTION Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 229
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3866935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a1ce657dd41a4f49990a4769000dc8049b83404",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks have gained a remarkable success in computer vision. However, most usable network architectures are hand-crafted and usually require expertise and elaborate design. In this paper, we provide a block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy. The optimal network block is constructed by the learning agent which is trained sequentially to choose component layers. We stack the block to construct the whole auto-generated network. To accelerate the generation process, we also propose a distributed asynchronous framework and an early stop strategy. The block-wise generation brings unique advantages: (1) it performs competitive results in comparison to the hand-crafted state-of-the-art networks on image classification, additionally, the best network generated by BlockQNN achieves 3.54% top-1 error rate on CIFAR-10 which beats all existing auto-generate networks. (2) in the meanwhile, it offers tremendous reduction of the search space in designing networks which only spends 3 days with 32 GPUs, and (3) moreover, it has strong generalizability that the network built on CIFAR also performs well on a larger-scale ImageNet dataset."
            },
            "slug": "Practical-Block-Wise-Neural-Network-Architecture-Zhong-Yan",
            "title": {
                "fragments": [],
                "text": "Practical Block-Wise Neural Network Architecture Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy and offers tremendous reduction of the search space in designing networks which only spends 3 days with 32 GPUs."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145719986"
                        ],
                        "name": "J. David",
                        "slug": "J.-David",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. David"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 18
                            }
                        ],
                        "text": "In BinaryConnect (Courbariaux et al., 2015), the real-valued weight is updated using the gradient w.r.t. its corresponding binary gate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 97
                            }
                        ],
                        "text": "We propose a gradient-based approach to train these binarized parameters based on BinaryConnect (Courbariaux et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 21
                            }
                        ],
                        "text": "As an alternative to BinaryConnect, we can utilize REINFORCE to train binarized weights as well."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 7
                            }
                        ],
                        "text": "Unlike Courbariaux et al. (2015) which binarize individual weights, we binarize entire paths."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 17
                            }
                        ],
                        "text": "In BinaryConnect (Courbariaux et al., 2015), the real-valued weight is updated using the gradient w."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1518846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5733ff08daff727af834345b9cfff1d0aa109ec",
            "isKey": true,
            "numCitedBy": 2134,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "slug": "BinaryConnect:-Training-Deep-Neural-Networks-with-Courbariaux-Bengio",
            "title": {
                "fragments": [],
                "text": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "BinaryConnect is introduced, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated, and near state-of-the-art results with BinaryConnect are obtained on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118505169"
                        ],
                        "name": "Jianguo Li",
                        "slug": "Jianguo-Li",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145314568"
                        ],
                        "name": "Zhiqiang Shen",
                        "slug": "Zhiqiang-Shen",
                        "structuredName": {
                            "firstName": "Zhiqiang",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiqiang Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024017"
                        ],
                        "name": "Shoumeng Yan",
                        "slug": "Shoumeng-Yan",
                        "structuredName": {
                            "firstName": "Shoumeng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shoumeng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 181
                            }
                        ],
                        "text": "Another relevant topic is network pruning (Han et al., 2016) that aim to improve the efficiency of neural networks by removing insignificant neurons (Han et al., 2015) or channels (Liu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2015) or channels (Liu et al., 2017)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5993328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90a16f34d109b63d95ab4da2d491cbe3a1c8b656",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20\u00d7 reduction in model size and a 5\u00d7 reduction in computing operations."
            },
            "slug": "Learning-Efficient-Convolutional-Networks-through-Liu-Li",
            "title": {
                "fragments": [],
                "text": "Learning Efficient Convolutional Networks through Network Slimming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach is called network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47325862"
                        ],
                        "name": "Jeff Pool",
                        "slug": "Jeff-Pool",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Pool",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Pool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 150
                            }
                        ],
                        "text": "Another relevant topic is network pruning (Han et al., 2016) that aim to improve the efficiency of neural networks by removing insignificant neurons (Han et al., 2015) or channels (Liu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2016) that aim to improve the efficiency of neural networks by removing insignificant neurons (Han et al., 2015) or channels (Liu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2238772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "isKey": false,
            "numCitedBy": 4076,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy."
            },
            "slug": "Learning-both-Weights-and-Connections-for-Efficient-Han-Pool",
            "title": {
                "fragments": [],
                "text": "Learning both Weights and Connections for Efficient Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections, and prunes redundant connections using a three-step method."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145834074"
                        ],
                        "name": "Han Cai",
                        "slug": "Han-Cai",
                        "structuredName": {
                            "firstName": "Han",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Han Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141054362"
                        ],
                        "name": "Jiacheng Yang",
                        "slug": "Jiacheng-Yang",
                        "structuredName": {
                            "firstName": "Jiacheng",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiacheng Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108309275"
                        ],
                        "name": "Weinan Zhang",
                        "slug": "Weinan-Zhang",
                        "structuredName": {
                            "firstName": "Weinan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weinan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 42
                            }
                        ],
                        "text": "Furthermore, compared with PathLevel EAS (Cai et al., 2018b) that also explores the tree-structured architecture space, both Proxyless-G and Proxyless-R achieves similar or lower test error rate results with half fewer parameters."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 191
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 191
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "For CIFAR-10 experiments, we use the tree-structured architecture space that is introduced by Cai et al. (2018b) with PyramidNet (Han et al., 2017) as the backbone3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 98
                            }
                        ],
                        "text": "For further details about the tree-structured architecture space, we refer to the original paper (Cai et al., 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 108
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46985193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcc808993310a8a64fdd5efa9e46d0022ff12c27",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new function-preserving transformation for efficient neural architecture search. This network transformation allows reusing previously trained networks and existing successful architectures that improves sample efficiency. We aim to address the limitation of current network transformation operations that can only perform layer-level architecture modifications, such as adding (pruning) filters or inserting (removing) a layer, which fails to change the topology of connection paths. Our proposed path-level transformation operations enable the meta-controller to modify the path topology of the given network while keeping the merits of reusing weights, and thus allow efficiently designing effective structures with complex path topologies like Inception models. We further propose a bidirectional tree-structured reinforcement learning meta-controller to explore a simple yet highly expressive tree-structured architecture space that can be viewed as a generalization of multi-branch architectures. We experimented on the image classification datasets with limited computational resources (about 200 GPU-hours), where we observed improved parameter efficiency and better test results (97.70% test accuracy on CIFAR-10 with 14.3M parameters and 74.6% top-1 accuracy on ImageNet in the mobile setting), demonstrating the effectiveness and transferability of our designed architectures."
            },
            "slug": "Path-Level-Network-Transformation-for-Efficient-Cai-Yang",
            "title": {
                "fragments": [],
                "text": "Path-Level Network Transformation for Efficient Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work introduces a new function-preserving transformation for efficient neural architecture search and proposes a bidirectional tree-structured reinforcement learning meta-controller to explore a simple yet highly expressive tree- Structured architecture space that can be viewed as a generalization of multi-branch architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "Similarly, Pham et al. (2018) propose to share weights among all sampled networks under the standard NAS framework (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 44
                            }
                        ],
                        "text": "(8) has a similar form to the standard NAS (Zoph & Le, 2017), while it is not a sequential decision-making process and no RNN meta-controller is used in our case."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 151
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 272
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12713052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d968c7450878190e45ac7886746de867bf673d",
            "isKey": true,
            "numCitedBy": 3482,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214."
            },
            "slug": "Neural-Architecture-Search-with-Reinforcement-Zoph-Le",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses a recurrent network to generate the model descriptions of neural networks and trains this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346186"
                        ],
                        "name": "Forrest N. Iandola",
                        "slug": "Forrest-N.-Iandola",
                        "structuredName": {
                            "firstName": "Forrest",
                            "lastName": "Iandola",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Forrest N. Iandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2318023"
                        ],
                        "name": "M. Moskewicz",
                        "slug": "M.-Moskewicz",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Moskewicz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moskewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059241"
                        ],
                        "name": "Khalid Ashraf",
                        "slug": "Khalid-Ashraf",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Ashraf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Khalid Ashraf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 101
                            }
                        ],
                        "text": "2 EXPERIMENTS ON IMAGENET For ImageNet experiments, we focus on learning efficient CNN architectures (Iandola et al., 2016; Howard et al., 2017; Sandler et al., 2018; Zhu et al., 2018) that have not only high accuracy but also low latency on specific hardware platforms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14136028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "969fbdcd0717bec06228053788c2ff78bbb4daac",
            "isKey": false,
            "numCitedBy": 4092,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). \nThe SqueezeNet architecture is available for download here: this https URL"
            },
            "slug": "SqueezeNet:-AlexNet-level-accuracy-with-50x-fewer-Iandola-Moskewicz",
            "title": {
                "fragments": [],
                "text": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a small DNN architecture called SqueezeNet, which achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters and is able to compress to less than 0.5MB (510x smaller than AlexNet)."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39838894"
                        ],
                        "name": "Yihui He",
                        "slug": "Yihui-He",
                        "structuredName": {
                            "firstName": "Yihui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46698300"
                        ],
                        "name": "Ji Lin",
                        "slug": "Ji-Lin",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47781592"
                        ],
                        "name": "Zhijian Liu",
                        "slug": "Zhijian-Liu",
                        "structuredName": {
                            "firstName": "Zhijian",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijian Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35446689"
                        ],
                        "name": "Hanrui Wang",
                        "slug": "Hanrui-Wang",
                        "structuredName": {
                            "firstName": "Hanrui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanrui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 44
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i.e. latency)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52048008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1717255b6aea01fe956cef998abbc3c399b5d7cf",
            "isKey": false,
            "numCitedBy": 843,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Model compression is an effective technique to efficiently deploy neural network models on mobile devices which have limited computation resources and tight power budgets. Conventional model compression techniques rely on hand-crafted features and require domain experts to explore the large design space trading off among model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4\\(\\times \\) FLOPs reduction, we achieved 2.7% better accuracy than the hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet-V1 and achieved a speedup of 1.53\\(\\times \\) on the GPU (Titan Xp) and 1.95\\(\\times \\) on an Android phone (Google Pixel 1), with negligible loss of accuracy."
            },
            "slug": "AMC:-AutoML-for-Model-Compression-and-Acceleration-He-Lin",
            "title": {
                "fragments": [],
                "text": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality and achieves state-of-the-art model compression results in a fully automated way without any human efforts."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917613"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc V.",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 47
                            }
                        ],
                        "text": "Additionally, when the DropPath regularization (Zoph et al., 2018; Huang et al., 2016) is adopted, we further increase the number of training epochs to 600 (Zoph et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 75
                            }
                        ],
                        "text": "Specifically, OneShot trains the over-parameterized network with DropPath (Zoph et al., 2018) that drops out each path with some fixed probability."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 26
                            }
                        ],
                        "text": "Unlike previous NAS works (Zoph et al., 2018; Liu et al., 2018c) that first learn CNN blocks on CIFAR-10 under small-scale setting (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 27
                            }
                        ],
                        "text": "Unlike previous NAS works (Zoph et al., 2018; Liu et al., 2018c) that first learn CNN blocks on CIFAR-10 under small-scale setting (e.g. fewer blocks), then transfer the learned block to ImageNet or CIFAR-10 under large-scale setting by repeatedly stacking it, we directly learn the architectures on\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "Additionally, when the DropPath regularization (Zoph et al., 2018; Huang et al., 2016) is adopted, we further increase the number of training epochs to 600 (Zoph et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 188
                            }
                        ],
                        "text": "1 1 INTRODUCTION Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 16
                            }
                        ],
                        "text": "As a trade-off, Zoph et al. (2018) propose to search for building blocks on proxy tasks, such as training for fewer epochs, starting with a smaller dataset (e.g. CIFAR-10), or learning with fewer blocks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 74
                            }
                        ],
                        "text": "We also remove the restriction of repeating blocks in previous NAS works (Zoph et al., 2018; Liu et al., 2018c) and allow all of the blocks to be learned and specified."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 172
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 77
                            }
                        ],
                        "text": ", 2016) is adopted, we further increase the number of training epochs to 600 (Zoph et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 128
                            }
                        ],
                        "text": "Notably, such kind of patterns cannot be captured in previous NAS methods as they force the blocks to share the same structure (Zoph et al., 2018; Liu et al., 2018a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12227989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0611891b9e8a7c5731146097b6f201578f47b2f",
            "isKey": true,
            "numCitedBy": 3538,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset."
            },
            "slug": "Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan",
            "title": {
                "fragments": [],
                "text": "Learning Transferable Architectures for Scalable Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to search for an architectural building block on a small dataset and then transfer the block to a larger dataset and introduces a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 43
                            }
                        ],
                        "text": "Another relevant topic is network pruning (Han et al., 2016) that aim to improve the efficiency of neural networks by removing insignificant neurons (Han et al., 2015) or channels (Liu et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 120
                            }
                        ],
                        "text": "\u2022 We provide a new path-level pruning perspective for NAS, showing a close connection between NAS and model compression (Han et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 42
                            }
                        ],
                        "text": "Another relevant topic is network pruning (Han et al., 2016) that aim to improve the efficiency of neural networks by removing insignificant neurons (Han et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2134321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "isKey": false,
            "numCitedBy": 5732,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
            },
            "slug": "Deep-Compression:-Compressing-Deep-Neural-Network-Han-Mao",
            "title": {
                "fragments": [],
                "text": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065121524"
                        ],
                        "name": "Gabriel Bender",
                        "slug": "Gabriel-Bender",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Bender",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Bender"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113697"
                        ],
                        "name": "Pieter-Jan Kindermans",
                        "slug": "Pieter-Jan-Kindermans",
                        "structuredName": {
                            "firstName": "Pieter-Jan",
                            "lastName": "Kindermans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pieter-Jan Kindermans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 45
                            }
                        ],
                        "text": "Our work is most closely related to One-Shot (Bender et al., 2018) and DARTS (Liu et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "However, naively including all the candidate paths leads to GPU memory explosion (Liu et al., 2018c; Bender et al., 2018), as the memory consumption grows linearly w.r.t. the number of choices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "Our work is most closely related to One-Shot (Bender et al., 2018) and DARTS (Liu et al., 2018c), both of which get rid of the meta-controller (or hypernetwork) by modeling NAS as a single training process of an over-parameterized network that comprises all candidate paths."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "Therefore, One-Shot and DARTS roughly need N times GPU memory and GPU hours compared to training a compact model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 251
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 729,
                                "start": 721
                            }
                        ],
                        "text": "AAADIHicfVJNb9QwEHXCVwlfWzhysViBipBWSUuBC1IFAnHgUCS2rbSOVo4zm7Xq2JHtVBui8E+48Fe4cAAhuMGvwUnDV7vLSJaeZuZ53jw7KQQ3Ngy/e/6Zs+fOX1i7GFy6fOXqtcH69T2jSs1gzJRQ+iChBgSXMLbcCjgoNNA8EbCfHD5t6/tHoA1X8rWtCohzmkk+44xal5quew9IAhmXNRU8k5A2AcmpnSdJ/ayZdFDn9UtqQbKqifFjfOctsbCw3eQ6ESU0NaGimNMGE8tzMPj5xi8eU/KITLcWW81dfA8TEiwjJ2AddxV5e7H9P7LhWb5sMk9BOjeqP9xRF6vuebNCRKGU6DcICMj0t03TwTAchV3g0yDqwRD1sTsdfCOpYmXudDFBjZlEYWHjmmrLmQBne2mgoOyQZjBxUFInJK47kQ2+7TIpnintjrS4y/7NqGluTJUnrrMVbk7W2uSy2qS0s0dxzWVRti98PGhWCmwVbn8LTrkGZkXlAGWaO62YzammzLo/FTgTopMrnwZ7m6MoHEWv7g93nvR2rKGb6BbaQBF6iHbQC7SLxoh577wP3ifvs//e/+h/8b8et/pez7mB/gn/x09YVgHC</latexit>\nthe weights are calculated by applying softmax to N real-valued architecture parameters {\u03b1i}:\nmOne-ShotO (x) =\nN\u2211\ni=1\noi(x), m DARTS O (x) =\nN\u2211\ni=1\npioi(x) =\nN\u2211\ni=1\nexp(\u03b1i)\u2211 j exp(\u03b1j) oi(x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "GPU hour-wise, inspired by recent works (Liu et al., 2018c; Bender et al., 2018), we formulate NAS as a path-level pruning process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 407,
                                "start": 258
                            }
                        ],
                        "text": "2 RELATED WORK The use of machine learning techniques, such as reinforcement learning or neuro-evolution, to replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In One-Shot,mO(x) is the sum of {oi(x)}, while in DARTS,mO(x) is weighted sum of {oi(x)}where\nMIT Red\nTrainer Latency Model\nDirect measurement: expensive and slow\nLatency modeling: cheap, fast and differentiable\nMIT Red-1\nLearnable Block i - 1\nLearnable Block i\n\u2026\u2026\nLearnable Block i + 1\n\u2026\u2026\nINPUT\nOUTPUT\n...\n\u03b1 \u03b2 \u03c3 \u2026 \u03b6 CONV\n5x5 POOL 3x3 CONV 3x3 Identity\nE[latency] = X\ni E[latencyi]"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 81
                            }
                        ],
                        "text": "However, naively including all the candidate paths leads to GPU memory explosion (Liu et al., 2018c; Bender et al., 2018), as the memory consumption grows linearly w."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51763580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b7b5514a65126d39a51d5a68da53e7aa244c1f",
            "isKey": true,
            "numCitedBy": 508,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "There is growing interest in automating neural network architecture design. Existing architecture search methods can be computationally expensive, requiring thousands of different architectures to be trained from scratch. Recent work has explored weight sharing across models to amortize the cost of training. Although previous methods reduced the cost of architecture search by orders of magnitude, they remain complex, requiring hypernetworks or reinforcement learning controllers. We aim to understand weight sharing for one-shot architecture search. With careful experimental analysis, we show that it is possible to efficiently identify promising architectures from a complex search space without either hypernetworks or RL."
            },
            "slug": "Understanding-and-Simplifying-One-Shot-Architecture-Bender-Kindermans",
            "title": {
                "fragments": [],
                "text": "Understanding and Simplifying One-Shot Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "With careful experimental analysis, it is shown that it is possible to efficiently identify promising architectures from a complex search space without either hypernetworks or reinforcement learning controllers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50557601"
                        ],
                        "name": "Chenxi Liu",
                        "slug": "Chenxi-Liu",
                        "structuredName": {
                            "firstName": "Chenxi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chenxi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052830834"
                        ],
                        "name": "Wei Hua",
                        "slug": "Wei-Hua",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Hua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136435893"
                        ],
                        "name": "Jonathan Huang",
                        "slug": "Jonathan-Huang",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702318"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "Unlike previous NAS works (Zoph et al., 2018; Liu et al., 2018c) that first learn CNN blocks on CIFAR-10 under small-scale setting (e.g. fewer blocks), then transfer the learned block to ImageNet or CIFAR-10 under large-scale setting by repeatedly stacking it, we directly learn the architectures on\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "(3) and Figure 2, by using the binary gates rather than real-valued path weights (Liu et al., 2018c), only one path of activation is active in memory at run-time and the memory requirement of training the over-parameterized network is thus reduced to the same level of training a compact model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "However, naively including all the candidate paths leads to GPU memory explosion (Liu et al., 2018c; Bender et al., 2018), as the memory consumption grows linearly w.r.t. the number of choices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 78
                            }
                        ],
                        "text": "Our work is most closely related to One-Shot (Bender et al., 2018) and DARTS (Liu et al., 2018c), both of which get rid of the meta-controller (or hypernetwork) by modeling NAS as a single training process of an over-parameterized network that comprises all candidate paths."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "We also remove the restriction of repeating blocks in previous NAS works (Zoph et al., 2018; Liu et al., 2018c) and allow all of the blocks to be learned and specified."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "Therefore, One-Shot and DARTS roughly need N times GPU memory and GPU hours compared to training a compact model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 450,
                                "start": 445
                            }
                        ],
                        "text": "MIT Red\nM B\n1 3x\n3\nM B\n3 5x\n5\nM B\n3 7x\n7\nM B\n6 7x\n7\nM B\n3 5x\n5\nM B\n6 5x\n5\nM B\n3 3x\n3\nM B\n3 5x\n5\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 5x\n5\nM B\n6 7x\n7\nC on\nv 3x\n3\nPo ol\nin g\nFC\nM B\n3 3x\n3 4 0x\n11 2x\n11 2\n24 x1\n12 x1 12\n3x 22\n4x 22 4\n32 x5\n6x 56\n56 x2\n8x 28\n56 x2\n8x 28\n11 2x\n14 x1 4\n11 2x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n43 2x\n7x 7\n1\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\n1\ncializing network architectures for different platforms by directly incorporating the measured hardware latency into optimization objectives."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 210
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 168
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 131
                            }
                        ],
                        "text": "L G\n] 2\nD ec\n2 01\n8\n(1) Previous proxy-based approach (2) Our proxy-less approach\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\nproxy (Figure 1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 757,
                                "start": 752
                            }
                        ],
                        "text": "AAADIHicfVJNb9QwEHXCVwlfWzhysViBipBWSUuBC1IFAnHgUCS2rbSOVo4zm7Xq2JHtVBui8E+48Fe4cAAhuMGvwUnDV7vLSJaeZuZ53jw7KQQ3Ngy/e/6Zs+fOX1i7GFy6fOXqtcH69T2jSs1gzJRQ+iChBgSXMLbcCjgoNNA8EbCfHD5t6/tHoA1X8rWtCohzmkk+44xal5quew9IAhmXNRU8k5A2AcmpnSdJ/ayZdFDn9UtqQbKqifFjfOctsbCw3eQ6ESU0NaGimNMGE8tzMPj5xi8eU/KITLcWW81dfA8TEiwjJ2AddxV5e7H9P7LhWb5sMk9BOjeqP9xRF6vuebNCRKGU6DcICMj0t03TwTAchV3g0yDqwRD1sTsdfCOpYmXudDFBjZlEYWHjmmrLmQBne2mgoOyQZjBxUFInJK47kQ2+7TIpnintjrS4y/7NqGluTJUnrrMVbk7W2uSy2qS0s0dxzWVRti98PGhWCmwVbn8LTrkGZkXlAGWaO62YzammzLo/FTgTopMrnwZ7m6MoHEWv7g93nvR2rKGb6BbaQBF6iHbQC7SLxoh577wP3ifvs//e/+h/8b8et/pez7mB/gn/x09YVgHC</latexit>\nthe weights are calculated by applying softmax to N real-valued architecture parameters {\u03b1i}:\nmOne-ShotO (x) =\nN\u2211\ni=1\noi(x), m DARTS O (x) =\nN\u2211\ni=1\npioi(x) =\nN\u2211\ni=1\nexp(\u03b1i)\u2211 j exp(\u03b1j) oi(x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "GPU hour-wise, inspired by recent works (Liu et al., 2018c; Bender et al., 2018), we formulate NAS as a path-level pruning process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "DARTS additionally introduces a real-valued architecture parameter for each path and jointly train weight parameters and architecture parameters via standard gradient descent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "Notably, such kind of patterns cannot be captured in previous NAS methods as they force the blocks to share the same structure (Zoph et al., 2018; Liu et al., 2018a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 68
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "In One-Shot,mO(x) is the sum of {oi(x)}, while in DARTS,mO(x) is weighted sum of {oi(x)}where\nMIT Red\nTrainer Latency Model\nDirect measurement: expensive and slow\nLatency modeling: cheap, fast and differentiable\nMIT Red-1\nLearnable Block i - 1\nLearnable Block i\n\u2026\u2026\nLearnable Block i + 1\n\u2026\u2026\nINPUT\nOUTPUT\n...\n\u03b1 \u03b2 \u03c3 \u2026 \u03b6 CONV\n5x5 POOL 3x3 CONV 3x3 Identity\nE[latency] = X\ni E[latencyi]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 40430109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f79398057bf0bbda9ff50067bc1f2950c2a2266",
            "isKey": true,
            "numCitedBy": 1377,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms. Our approach uses a sequential model-based optimization (SMBO) strategy, in which we search for structures in order of increasing complexity, while simultaneously learning a surrogate model to guide the search through structure space. Direct comparison under the same search space shows that our method is up to 5 times more efficient than the RL method of Zoph et al. (2018) in terms of number of models evaluated, and 8 times faster in terms of total compute. The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and ImageNet."
            },
            "slug": "Progressive-Neural-Architecture-Search-Liu-Zoph",
            "title": {
                "fragments": [],
                "text": "Progressive Neural Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work proposes a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms using a sequential model-based optimization (SMBO) strategy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117103358"
                        ],
                        "name": "Yu Sun",
                        "slug": "Yu-Sun",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371029"
                        ],
                        "name": "Daniel Sedra",
                        "slug": "Daniel-Sedra",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sedra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Sedra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 47
                            }
                        ],
                        "text": "Additionally, when the DropPath regularization (Zoph et al., 2018; Huang et al., 2016) is adopted, we further increase the number of training epochs to 600 (Zoph et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 67
                            }
                        ],
                        "text": "Additionally, when the DropPath regularization (Zoph et al., 2018; Huang et al., 2016) is adopted, we further increase the number of training epochs to 600 (Zoph et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6773885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51db1f3c8dfc7d4077da39c96bb90a6358128111",
            "isKey": false,
            "numCitedBy": 1458,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Very deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91 % on CIFAR-10)."
            },
            "slug": "Deep-Networks-with-Stochastic-Depth-Huang-Sun",
            "title": {
                "fragments": [],
                "text": "Deep Networks with Stochastic Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Stochastic depth is proposed, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time and reduces training time substantially and improves the test error significantly on almost all data sets that were used for evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32097919"
                        ],
                        "name": "Terrance Devries",
                        "slug": "Terrance-Devries",
                        "structuredName": {
                            "firstName": "Terrance",
                            "lastName": "Devries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terrance Devries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 169
                            }
                        ],
                        "text": "The test error rate results of our proposed method and other state-of-the-art architectures on CIFAR10 are summarized in Table 1, where \u201cc/o\u201d indicates the use of Cutout (DeVries & Taylor, 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23714201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb35fdc11a325f21a8ce0ca65058f7480a2fc91f",
            "isKey": false,
            "numCitedBy": 1727,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at this https URL"
            },
            "slug": "Improved-Regularization-of-Convolutional-Neural-Devries-Taylor",
            "title": {
                "fragments": [],
                "text": "Improved Regularization of Convolutional Neural Networks with Cutout"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper shows that the simple regularization technique of randomly masking out square regions of input during training, which is called cutout, can be used to improve the robustness and overall performance of convolutional neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3440939"
                        ],
                        "name": "Renqian Luo",
                        "slug": "Renqian-Luo",
                        "structuredName": {
                            "firstName": "Renqian",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Renqian Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143853336"
                        ],
                        "name": "Fei Tian",
                        "slug": "Fei-Tian",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826491"
                        ],
                        "name": "Tao Qin",
                        "slug": "Tao-Qin",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Qin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Qin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110264337"
                        ],
                        "name": "Tie-Yan Liu",
                        "slug": "Tie-Yan-Liu",
                        "structuredName": {
                            "firstName": "Tie-Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tie-Yan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 164
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52071151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a740ec7cddfc02a58412b6b4b5067cec19e3597",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic neural architecture design has shown its potential in discovering powerful neural network architectures. Existing methods, no matter based on reinforcement learning or evolutionary algorithms (EA), conduct architecture search in a discrete space, which is highly inefficient. In this paper, we propose a simple and efficient method to automatic neural architecture design based on continuous optimization. We call this new approach neural architecture optimization (NAO). There are three key components in our proposed approach: (1) An encoder embeds/maps neural network architectures into a continuous space. (2) A predictor takes the continuous representation of a network as input and predicts its accuracy. (3) A decoder maps a continuous representation of a network back to its architecture. The performance predictor and the encoder enable us to perform gradient based optimization in the continuous space to find the embedding of a new architecture with potentially better accuracy. Such a better embedding is then decoded to a network by the decoder. Experiments show that the architecture discovered by our method is very competitive for image classification task on CIFAR-10 and language modeling task on PTB, outperforming or on par with the best results of previous architecture search methods with a significantly reduction of computational resources. Specifically we obtain $2.11\\%$ test set error rate for CIFAR-10 image classification task and $56.0$ test set perplexity of PTB language modeling task. The best discovered architectures on both tasks are successfully transferred to other tasks such as CIFAR-100 and WikiText-2. Furthermore, combined with the recent proposed weight sharing mechanism, we discover powerful architecture on CIFAR-10 (with error rate $3.53\\%$) and on PTB (with test set perplexity $56.6$), with very limited computational resources (less than $10$ GPU hours) for both tasks."
            },
            "slug": "Neural-Architecture-Optimization-Luo-Tian",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experiments show that the architecture discovered by this simple and efficient method to automatic neural architecture design based on continuous optimization is very competitive for image classification task on CIFAR-10 and language modeling task on PTB, outperforming or on par with the best results of previous architecture search methods with a significantly reduction of computational resources."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2501244"
                        ],
                        "name": "T. Elsken",
                        "slug": "T.-Elsken",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Elsken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Elsken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2708564"
                        ],
                        "name": "J. H. Metzen",
                        "slug": "J.-H.-Metzen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Metzen",
                            "middleNames": [
                                "Hendrik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Metzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i.e. latency)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 272
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52016139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "114a32bc872f160b58f503aca13f887556b5006e",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy."
            },
            "slug": "Neural-Architecture-Search:-A-Survey-Elsken-Metzen",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An overview of existing work in this field of research is provided and neural architecture search methods are categorized according to three dimensions: search space, search strategy, and performance estimation strategy."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086576"
                        ],
                        "name": "Dongyoon Han",
                        "slug": "Dongyoon-Han",
                        "structuredName": {
                            "firstName": "Dongyoon",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongyoon Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207648"
                        ],
                        "name": "Jiwhan Kim",
                        "slug": "Jiwhan-Kim",
                        "structuredName": {
                            "firstName": "Jiwhan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwhan Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769295"
                        ],
                        "name": "Junmo Kim",
                        "slug": "Junmo-Kim",
                        "structuredName": {
                            "firstName": "Junmo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junmo Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 154
                            }
                        ],
                        "text": "Specifically,\n3The list of operations in the candidate set is provided in the appendix.\nwe replace all 3 \u00d7 3 convolution layers in the residual blocks of a PyramidNet with tree-structured cells, each of which has a depth of 3 and the number of branches is set to be 2 at each node (except the leaf nodes)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 130
                            }
                        ],
                        "text": "For CIFAR-10 experiments, we use the tree-structured architecture space that is introduced by Cai et al. (2018b) with PyramidNet (Han et al., 2017) as the backbone3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 24
                            }
                        ],
                        "text": "(2018b) with PyramidNet (Han et al., 2017) as the backbone3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5398883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bdf07c9897ca70788fff61dec56178a2bd0c29c",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (DCNNs) have shown remarkable performance in image classification tasks in recent years. Generally, deep neural network architectures are stacks consisting of a large number of convolutional layers, and they perform downsampling along the spatial dimension via pooling to reduce memory usage. Concurrently, the feature map dimension (i.e., the number of channels) is sharply increased at downsampling locations, which is essential to ensure effective performance because it increases the diversity of high-level attributes. This also applies to residual networks and is very closely related to their performance. In this research, instead of sharply increasing the feature map dimension at units that perform downsampling, we gradually increase the feature map dimension at all units to involve as many locations as possible. This design, which is discussed in depth together with our new insights, has proven to be an effective means of improving generalization ability. Furthermore, we propose a novel residual unit capable of further improving the classification accuracy with our new network architecture. Experiments on benchmark CIFAR-10, CIFAR-100, and ImageNet datasets have shown that our network architecture has superior generalization ability compared to the original residual networks. Code is available at https://github.com/jhkim89/PyramidNet."
            },
            "slug": "Deep-Pyramidal-Residual-Networks-Han-Kim",
            "title": {
                "fragments": [],
                "text": "Deep Pyramidal Residual Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This research gradually increases the feature map dimension at all units to involve as many locations as possible in the network architecture and proposes a novel residual unit capable of further improving the classification accuracy with the new network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892780"
                        ],
                        "name": "Esteban Real",
                        "slug": "Esteban-Real",
                        "structuredName": {
                            "firstName": "Esteban",
                            "lastName": "Real",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Esteban Real"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737322"
                        ],
                        "name": "A. Aggarwal",
                        "slug": "A.-Aggarwal",
                        "structuredName": {
                            "firstName": "Alok",
                            "lastName": "Aggarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145438541"
                        ],
                        "name": "Yanping Huang",
                        "slug": "Yanping-Huang",
                        "structuredName": {
                            "firstName": "Yanping",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanping Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 9
                            }
                        ],
                        "text": "Notably, AmoebaNet-B uses 34.9M parameters while our model only uses 5.7M parameters which is 6\u00d7 fewer than AmoebaNet-B."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "Specifically, Proxyless-G reaches a test error rate of 2.08% which is slightly better than AmoebaNet-B (Real et al., 2018) (the previous best architecture on CIFAR-10)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "08% which is slightly better than AmoebaNet-B (Real et al., 2018) (the previous best architecture on CIFAR-10)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 89
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3640974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50bdda28de3dcf82a0e10f9ec13eea248b19edb5",
            "isKey": true,
            "numCitedBy": 1843,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically. Although evolutionary algorithms have been repeatedly applied to neural network topologies, the image classifiers thus discovered have remained inferior to human-crafted ones. Here, we evolve an image classifier\u2014 AmoebaNet-A\u2014that surpasses hand-designs for the first time. To do this, we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes. Matching size, AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods. Scaled to larger size, AmoebaNet-A sets a new state-of-theart 83.9% top-1 / 96.6% top-5 ImageNet accuracy. In a controlled comparison against a well known reinforcement learning algorithm, we give evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search. This is relevant when fewer compute resources are available. Evolution is, thus, a simple method to effectively discover high-quality architectures."
            },
            "slug": "Regularized-Evolution-for-Image-Classifier-Search-Real-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Regularized Evolution for Image Classifier Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work evolves an image classifier---AmoebaNet-A---that surpasses hand-designs for the first time and gives evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "Model Top-1 Top-5 GPU latency MobileNetV2 (Sandler et al., 2018) 72."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 92
                            }
                        ],
                        "text": "On ImageNet, our model achieves 75.1% top-1 accuracy which is 3.1% higher than MobileNetV2 (Sandler et al., 2018) while being 1.2\u00d7 faster."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "We use MobileNetV2 (Sandler et al., 2018) as the backbone to build the architecture space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 27
                            }
                        ],
                        "text": "1% higher than MobileNetV2 (Sandler et al., 2018) while being 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 72
                            }
                        ],
                        "text": "Furthermore, by rescaling the width of the networks using a multiplier (Sandler et al., 2018; Tan et al., 2018), it is shown in Figure 4 that our model consistently outperforms MobileNetV2 by a significant margin under all latency settings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": true,
            "numCitedBy": 7406,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20515689"
                        ],
                        "name": "Ligeng Zhu",
                        "slug": "Ligeng-Zhu",
                        "structuredName": {
                            "firstName": "Ligeng",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ligeng Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38343750"
                        ],
                        "name": "Ruizhi Deng",
                        "slug": "Ruizhi-Deng",
                        "structuredName": {
                            "firstName": "Ruizhi",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruizhi Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49152600"
                        ],
                        "name": "Zhiwei Deng",
                        "slug": "Zhiwei-Deng",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145604260"
                        ],
                        "name": "P. Tan",
                        "slug": "P.-Tan",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 EXPERIMENTS ON IMAGENET For ImageNet experiments, we focus on learning efficient CNN architectures (Iandola et al., 2016; Howard et al., 2017; Sandler et al., 2018; Zhu et al., 2018) that have not only high accuracy but also low latency on specific hardware platforms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4855410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "329fe654ab3b4b480b7649bf6675ccc844b0245b",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore a key architectural aspect of deep convolutional neural networks: the pattern of internal skip connections used to aggregate outputs of earlier layers for consumption by deeper layers. Such aggregation is critical to facilitate training of very deep networks in an end-to-end manner. This is a primary reason for the widespread adoption of residual networks, which aggregate outputs via cumulative summation. While subsequent works investigate alternative aggregation operations (e.g. concatenation), we focus on an orthogonal question: which outputs to aggregate at a particular point in the network. We propose a new internal connection structure which aggregates only a sparse set of previous outputs at any given depth. Our experiments demonstrate this simple design change offers superior performance with fewer parameters and lower computational requirements. Moreover, we show that sparse aggregation allows networks to scale more robustly to 1000+ layers, thereby opening future avenues for training long-running visual processes."
            },
            "slug": "Sparsely-Aggregated-Convolutional-Networks-Zhu-Deng",
            "title": {
                "fragments": [],
                "text": "Sparsely Aggregated Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a new internal connection structure which aggregates only a sparse set of previous outputs at any given depth, and shows that sparse aggregation allows networks to scale more robustly to 1000+ layers, thereby opening future avenues for training long-running visual processes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391802"
                        ],
                        "name": "Hanxiao Liu",
                        "slug": "Hanxiao-Liu",
                        "structuredName": {
                            "firstName": "Hanxiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanxiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143939165"
                        ],
                        "name": "Chrisantha Fernando",
                        "slug": "Chrisantha-Fernando",
                        "structuredName": {
                            "firstName": "Chrisantha",
                            "lastName": "Fernando",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chrisantha Fernando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "Unlike previous NAS works (Zoph et al., 2018; Liu et al., 2018c) that first learn CNN blocks on CIFAR-10 under small-scale setting (e.g. fewer blocks), then transfer the learned block to ImageNet or CIFAR-10 under large-scale setting by repeatedly stacking it, we directly learn the architectures on\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "(3) and Figure 2, by using the binary gates rather than real-valued path weights (Liu et al., 2018c), only one path of activation is active in memory at run-time and the memory requirement of training the over-parameterized network is thus reduced to the same level of training a compact model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "However, naively including all the candidate paths leads to GPU memory explosion (Liu et al., 2018c; Bender et al., 2018), as the memory consumption grows linearly w.r.t. the number of choices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 78
                            }
                        ],
                        "text": "Our work is most closely related to One-Shot (Bender et al., 2018) and DARTS (Liu et al., 2018c), both of which get rid of the meta-controller (or hypernetwork) by modeling NAS as a single training process of an over-parameterized network that comprises all candidate paths."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "We also remove the restriction of repeating blocks in previous NAS works (Zoph et al., 2018; Liu et al., 2018c) and allow all of the blocks to be learned and specified."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "Therefore, One-Shot and DARTS roughly need N times GPU memory and GPU hours compared to training a compact model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 450,
                                "start": 445
                            }
                        ],
                        "text": "MIT Red\nM B\n1 3x\n3\nM B\n3 5x\n5\nM B\n3 7x\n7\nM B\n6 7x\n7\nM B\n3 5x\n5\nM B\n6 5x\n5\nM B\n3 3x\n3\nM B\n3 5x\n5\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 7x\n7\nM B\n6 5x\n5\nM B\n6 7x\n7\nC on\nv 3x\n3\nPo ol\nin g\nFC\nM B\n3 3x\n3 4 0x\n11 2x\n11 2\n24 x1\n12 x1 12\n3x 22\n4x 22 4\n32 x5\n6x 56\n56 x2\n8x 28\n56 x2\n8x 28\n11 2x\n14 x1 4\n11 2x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n12 8x\n14 x1 4\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n25 6x\n7x 7\n43 2x\n7x 7\n1\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\n1\ncializing network architectures for different platforms by directly incorporating the measured hardware latency into optimization objectives."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 210
                            }
                        ],
                        "text": "Neural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018; Cai et al., 2018a; Liu et al., 2018a; Zhong et al., 2018) and language modeling (Zoph & Le, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 168
                            }
                        ],
                        "text": "\u2026replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 131
                            }
                        ],
                        "text": "L G\n] 2\nD ec\n2 01\n8\n(1) Previous proxy-based approach (2) Our proxy-less approach\nNormal Train NAS Need Meta Controller\nNeed Proxy\nDARTS & One-shot No Meta Controller\nNeed Proxy\nProxyless (Ours) No Meta Controller\nNo Proxy\nGPU Hours GPU Memory\nproxy (Figure 1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 757,
                                "start": 752
                            }
                        ],
                        "text": "AAADIHicfVJNb9QwEHXCVwlfWzhysViBipBWSUuBC1IFAnHgUCS2rbSOVo4zm7Xq2JHtVBui8E+48Fe4cAAhuMGvwUnDV7vLSJaeZuZ53jw7KQQ3Ngy/e/6Zs+fOX1i7GFy6fOXqtcH69T2jSs1gzJRQ+iChBgSXMLbcCjgoNNA8EbCfHD5t6/tHoA1X8rWtCohzmkk+44xal5quew9IAhmXNRU8k5A2AcmpnSdJ/ayZdFDn9UtqQbKqifFjfOctsbCw3eQ6ESU0NaGimNMGE8tzMPj5xi8eU/KITLcWW81dfA8TEiwjJ2AddxV5e7H9P7LhWb5sMk9BOjeqP9xRF6vuebNCRKGU6DcICMj0t03TwTAchV3g0yDqwRD1sTsdfCOpYmXudDFBjZlEYWHjmmrLmQBne2mgoOyQZjBxUFInJK47kQ2+7TIpnintjrS4y/7NqGluTJUnrrMVbk7W2uSy2qS0s0dxzWVRti98PGhWCmwVbn8LTrkGZkXlAGWaO62YzammzLo/FTgTopMrnwZ7m6MoHEWv7g93nvR2rKGb6BbaQBF6iHbQC7SLxoh577wP3ifvs//e/+h/8b8et/pez7mB/gn/x09YVgHC</latexit>\nthe weights are calculated by applying softmax to N real-valued architecture parameters {\u03b1i}:\nmOne-ShotO (x) =\nN\u2211\ni=1\noi(x), m DARTS O (x) =\nN\u2211\ni=1\npioi(x) =\nN\u2211\ni=1\nexp(\u03b1i)\u2211 j exp(\u03b1j) oi(x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "GPU hour-wise, inspired by recent works (Liu et al., 2018c; Bender et al., 2018), we formulate NAS as a path-level pruning process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "DARTS additionally introduces a real-valued architecture parameter for each path and jointly train weight parameters and architecture parameters via standard gradient descent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "Notably, such kind of patterns cannot be captured in previous NAS methods as they force the blocks to share the same structure (Zoph et al., 2018; Liu et al., 2018a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 68
                            }
                        ],
                        "text": "This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b; Real et al., 2018; Cai et al., 2018b; Liu et al., 2018c; Tan et al., 2018; Luo et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "In One-Shot,mO(x) is the sum of {oi(x)}, while in DARTS,mO(x) is weighted sum of {oi(x)}where\nMIT Red\nTrainer Latency Model\nDirect measurement: expensive and slow\nLatency modeling: cheap, fast and differentiable\nMIT Red-1\nLearnable Block i - 1\nLearnable Block i\n\u2026\u2026\nLearnable Block i + 1\n\u2026\u2026\nINPUT\nOUTPUT\n...\n\u03b1 \u03b2 \u03c3 \u2026 \u03b6 CONV\n5x5 POOL 3x3 CONV 3x3 Identity\nE[latency] = X\ni E[latencyi]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 23873820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "856451974cce2d353d5d8a5a72104984a252375c",
            "isKey": true,
            "numCitedBy": 680,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore efficient neural architecture search methods and show that a simple yet powerful evolutionary algorithm can discover new architectures with excellent performance. Our approach combines a novel hierarchical genetic representation scheme that imitates the modularized design pattern commonly adopted by human experts, and an expressive search space that supports complex topologies. Our algorithm efficiently discovers architectures that outperform a large number of manually designed models for image classification, obtaining top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which is competitive with the best existing neural architecture search approaches. We also present results using random search, achieving 0.3% less top-1 accuracy on CIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36 hours down to 1 hour."
            },
            "slug": "Hierarchical-Representations-for-Efficient-Search-Liu-Simonyan",
            "title": {
                "fragments": [],
                "text": "Hierarchical Representations for Efficient Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work efficiently discovers architectures that outperform a large number of manually designed models for image classification, obtaining top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which is competitive with the best existing neural architecture search approaches."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446319"
                        ],
                        "name": "Yoshihiro Yamada",
                        "slug": "Yoshihiro-Yamada",
                        "structuredName": {
                            "firstName": "Yoshihiro",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshihiro Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859858"
                        ],
                        "name": "Takuya Akiba",
                        "slug": "Takuya-Akiba",
                        "structuredName": {
                            "firstName": "Takuya",
                            "lastName": "Akiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takuya Akiba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54445621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b842cd963a5e61c48b467c92aee035485256ee12",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Overfitting is a crucial problem in deep neural networks, even in the latest network architectures. In this paper, to relieve the overfitting effect of ResNet and its improvements (i.e., Wide ResNet, PyramidNet, and ResNeXt), we propose a new regularization method called ShakeDrop regularization. ShakeDrop is inspired by Shake-Shake, which is an effective regularization method, but can be applied to ResNeXt only. ShakeDrop is more effective than Shake-Shake and can be applied not only to ResNeXt but also ResNet, Wide ResNet, and PyramidNet. An important key is to achieve stability of training. Because effective regularization often causes unstable training, we introduce a training stabilizer, which is an unusual use of an existing regularizer. Through experiments under various conditions, we demonstrate the conditions under which ShakeDrop works well."
            },
            "slug": "Shakedrop-Regularization-for-Deep-Residual-Learning-Yamada-Iwamura",
            "title": {
                "fragments": [],
                "text": "Shakedrop Regularization for Deep Residual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a new regularization method called ShakeDrop regularization, inspired by Shake-Shake, and introduces a training stabilizer, which is an unusual use of an existing regularizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Access"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3ms ResNet-34 (He et al., 2016) 73."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065798343"
                        ],
                        "name": "Purushotham Kamath",
                        "slug": "Purushotham-Kamath",
                        "structuredName": {
                            "firstName": "Purushotham",
                            "lastName": "Kamath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Purushotham Kamath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144541718"
                        ],
                        "name": "Abhishek Singh",
                        "slug": "Abhishek-Singh",
                        "structuredName": {
                            "firstName": "Abhishek",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhishek Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46905001"
                        ],
                        "name": "Debo Dutta",
                        "slug": "Debo-Dutta",
                        "structuredName": {
                            "firstName": "Debo",
                            "lastName": "Dutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debo Dutta"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 428,
                                "start": 258
                            }
                        ],
                        "text": "2 RELATED WORK The use of machine learning techniques, such as reinforcement learning or neuro-evolution, to replace human experts in designing neural network architectures, usually referred to as neural architecture search, has drawn an increasing interest (Zoph & Le, 2017; Liu et al., 2018a;b;c; Cai et al., 2018a;b; Pham et al., 2018; Brock et al., 2018; Bender et al., 2018; Elsken et al., 2017; 2018b; Kamath et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195347198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d979ea00b2d661d73c1d4d7ccf1332607340f255",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, advances in the design of convolutional neural networks have resulted in signi\u0080cant improvements on the image classi\u0080cation and object detection problems. One of the advances is networks built by stacking complex cells, seen in such networks as InceptionNet and NasNet. \u008cese cells are either constructed by hand, generated by generative networks or discovered by search. Unlike conventional networks (where layers consist of a convolution block, sampling and non linear unit), the new cells feature more complex designs consisting of several \u0080lters and other operators connected in series and parallel. Recently, several cells have been proposed or generated that are supersets of previously proposed custom or generated cells. In\u0083uenced by this, we introduce a network construction method based on EnvelopeNets. An EnvelopeNet is a deep convolutional neural network of stacked EnvelopeCells. EnvelopeCells are supersets (or envelopes) of previously proposed handcra\u0089ed and generated cells. We propose a method to construct improved network architectures by restructuring EnvelopeNets. \u008ce algorithm restructures an EnvelopeNet by rearranging blocks in the network. It identi\u0080es blocks to be restructured using metrics derived from the featuremaps collected during a partial training run of the EnvelopeNet. \u008ce method requires less computation resources to generate an architecture than an optimized architecture search over the entire search space of blocks. \u008ce restructured networks have higher accuracy on the image classi\u0080cation problem on a representative dataset than both the generating EnvelopeNet and an equivalent arbitrary network."
            },
            "slug": "Neural-Architecture-Construction-using-EnvelopeNets-Kamath-Singh",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Construction using EnvelopeNets"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method to construct improved network architectures by restructuring EnvelopeNets, which has higher accuracy on the image classi\u0080cation problem on a representative dataset than both the generating En envelopeNet and an equivalent arbitrary network."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065798343"
                        ],
                        "name": "Purushotham Kamath",
                        "slug": "Purushotham-Kamath",
                        "structuredName": {
                            "firstName": "Purushotham",
                            "lastName": "Kamath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Purushotham Kamath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140155792"
                        ],
                        "name": "Abhishek Singh",
                        "slug": "Abhishek-Singh",
                        "structuredName": {
                            "firstName": "Abhishek",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhishek Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46905001"
                        ],
                        "name": "Debo Dutta",
                        "slug": "Debo-Dutta",
                        "structuredName": {
                            "firstName": "Debo",
                            "lastName": "Dutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debo Dutta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 55702011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb88dc75f145db60f9b8c7bd0f604334b7cbbab8",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, advances in the design of convolutional neural networks have resulted in significant improvements on the image classification and object detection problems. One of the advances is networks built by stacking complex cells, seen in such networks as InceptionNet and NasNet. These cells are either constructed by hand, generated by generative networks or discovered by search. Unlike conventional networks (where layers consist of a convolution block, sampling and non linear unit), the new cells feature more complex designs consisting of several filters and other operators connected in series and parallel. Recently, several cells have been proposed or generated that are supersets of previously proposed custom or generated cells. Influenced by this, we introduce a network construction method based on EnvelopeNets. An EnvelopeNet is a deep convolutional neural network of stacked EnvelopeCells. EnvelopeCells are supersets (or envelopes) of previously proposed handcrafted and generated cells. We propose a method to construct improved network architectures by restructuring EnvelopeNets. The algorithm restructures an EnvelopeNet by rearranging blocks in the network. It identifies blocks to be restructured using metrics derived from the featuremaps collected during a partial training run of the EnvelopeNet. The method requires less computation resources to generate an architecture than an optimized architecture search over the entire search space of blocks. The restructured networks have higher accuracy on the image classification problem on a representative dataset than both the generating EnvelopeNet and an equivalent arbitrary network."
            },
            "slug": "Fast-Neural-Architecture-Construction-using-Kamath-Singh",
            "title": {
                "fragments": [],
                "text": "Fast Neural Architecture Construction using EnvelopeNets"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method to construct improved network architectures by restructuring EnvelopeNets, which has higher accuracy on the image classification problem on a representative dataset than both the generating En envelopeNet and an equivalent arbitrary network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 101
                            }
                        ],
                        "text": "2 EXPERIMENTS ON IMAGENET For ImageNet experiments, we focus on learning efficient CNN architectures (Iandola et al., 2016; Howard et al., 2017; Sandler et al., 2018; Zhu et al., 2018) that have not only high accuracy but also low latency on specific hardware platforms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "Model Params Test error (%) DenseNet-BC (Huang et al., 2017) 25."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9433631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5694e46284460a648fe29117cbc55f6c9be3fa3c",
            "isKey": false,
            "numCitedBy": 19204,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections&#x2014;one between each layer and its subsequent layer&#x2014;our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet."
            },
            "slug": "Densely-Connected-Convolutional-Networks-Huang-Liu",
            "title": {
                "fragments": [],
                "text": "Densely Connected Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion, and has several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 106
                            }
                        ],
                        "text": "In the following discussions, we refer to these two algorithms as Proxyless-G (gradient) and Proxyless-R (REINFORCE) respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 35
                            }
                        ],
                        "text": "Therefore, according to REINFORCE (Williams, 1992), we have the following updates for binarized parameters:\nJ(\u03b1) = Eg\u223c\u03b1[R(Ng)] = \u2211\ni\npiR(N (e = oi)),\n\u2207\u03b1J(\u03b1) = \u2211\ni\nR(N (e = oi))\u2207\u03b1pi = \u2211\ni\nR(N (e = oi))pi\u2207\u03b1 log(pi),\n= Eg\u223c\u03b1[R(Ng)\u2207\u03b1 log(p(g))] \u2248 1\nM\nM\u2211\ni=1\nR(Ngi)\u2207\u03b1 log(p(gi)), (8)\nwhere gi denotes the\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "As an alternative to BinaryConnect, we can utilize REINFORCE to train binarized weights as well."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "Therefore, according to REINFORCE (Williams, 1992), we have the following updates for binarized parameters: J(\u03b1) = Eg\u223c\u03b1[R(Ng)] = \u2211"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "Additionally, we also present a REINFORCE-based (Williams, 1992) algorithm as an alternative strategy to handle hardware metrics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 259
                            }
                        ],
                        "text": "We randomly sample 5,000 images from the training set as a validation set for learning architecture parameters which are updated using the Adam optimizer with an initial learning rate of 0.006 for the gradient-based algorithm (Section 3.2.1) and 0.01 for the REINFORCEbased algorithm (Section 3.3.2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 24
                            }
                        ],
                        "text": "Therefore, according to REINFORCE (Williams, 1992), we have the following updates for binarized parameters:\nJ(\u03b1) = Eg\u223c\u03b1[R(Ng)] = \u2211\ni\npiR(N (e = oi)),\n\u2207\u03b1J(\u03b1) = \u2211\ni\nR(N (e = oi))\u2207\u03b1pi = \u2211\ni\nR(N (e = oi))pi\u2207\u03b1 log(pi),\n= Eg\u223c\u03b1[R(Ng)\u2207\u03b1 log(p(g))] \u2248 1\nM\nM\u2211\ni=1\nR(Ngi)\u2207\u03b1 log(p(gi)), (8)\nwhere gi denotes the ith sampled binary gates, p(gi) denotes the probability of sampling gi according to Eq."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "Furthermore, since both gradient-based updates and REINFORCE-based updates are essentially two different update rules to the same binarized architecture parameters, it is possible to combine them to form a new update rule for the architecture parameters."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": true,
            "numCitedBy": 5268,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110553435"
                        ],
                        "name": "Chi-Hung Hsu",
                        "slug": "Chi-Hung-Hsu",
                        "structuredName": {
                            "firstName": "Chi-Hung",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Hung Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51002562"
                        ],
                        "name": "Shu-Huan Chang",
                        "slug": "Shu-Huan-Chang",
                        "structuredName": {
                            "firstName": "Shu-Huan",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shu-Huan Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854012"
                        ],
                        "name": "Da-Cheng Juan",
                        "slug": "Da-Cheng-Juan",
                        "structuredName": {
                            "firstName": "Da-Cheng",
                            "lastName": "Juan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Da-Cheng Juan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1943594"
                        ],
                        "name": "Jia-Yu Pan",
                        "slug": "Jia-Yu-Pan",
                        "structuredName": {
                            "firstName": "Jia-Yu",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia-Yu Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125026801"
                        ],
                        "name": "Yutian Chen",
                        "slug": "Yutian-Chen",
                        "structuredName": {
                            "firstName": "Yutian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yutian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149192010"
                        ],
                        "name": "Wei Wei",
                        "slug": "Wei-Wei",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48435516"
                        ],
                        "name": "Shih-Chieh Chang",
                        "slug": "Shih-Chieh-Chang",
                        "structuredName": {
                            "firstName": "Shih-Chieh",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chieh Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 44
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 45
                            }
                        ],
                        "text": "Therefore, it is a multi-objective NAS task (Hsu et al., 2018; Dong et al., 2018; Elsken et al., 2018a; He et al., 2018; Tan et al., 2018), where one of the objectives is non-differentiable (i.e. latency)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49487031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91bfffb4d07c9ebfe371fbc1539fb8d8a55f2e89",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent studies on neural architecture search have shown that automatically designed neural networks perform as good as expert-crafted architectures. While most existing works aim at finding architectures that optimize the prediction accuracy, these architectures may have complexity and is therefore not suitable being deployed on certain computing environment (e.g., with limited power budgets). We propose MONAS, a framework for Multi-Objective Neural Architectural Search that employs reward functions considering both prediction accuracy and other important objectives (e.g., power consumption) when searching for neural network architectures. Experimental results showed that, compared to the state-ofthe-arts, models found by MONAS achieve comparable or better classification accuracy on computer vision applications, while satisfying the additional objectives such as peak power."
            },
            "slug": "MONAS:-Multi-Objective-Neural-Architecture-Search-Hsu-Chang",
            "title": {
                "fragments": [],
                "text": "MONAS: Multi-Objective Neural Architecture Search using Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results showed that, compared to the state-ofthe-arts, models found by MONAS achieve comparable or better classification accuracy on computer vision applications, while satisfying the additional objectives such as peak power."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 23,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/ProxylessNAS:-Direct-Neural-Architecture-Search-on-Cai-Zhu/dc8b789446416383bfafe9b1c504c4a2b17e68d1?sort=total-citations"
}