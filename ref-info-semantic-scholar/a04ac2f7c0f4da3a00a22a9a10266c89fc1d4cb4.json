{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067445"
                        ],
                        "name": "Yaman Umuroglu",
                        "slug": "Yaman-Umuroglu",
                        "structuredName": {
                            "firstName": "Yaman",
                            "lastName": "Umuroglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaman Umuroglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054413"
                        ],
                        "name": "Magnus Jahre",
                        "slug": "Magnus-Jahre",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Jahre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Jahre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "In parallel with our work, we note that [14] pursued a similar line of work."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 26223295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a42b9a97d0458dda4bbc0863eca0143d7505c3c",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Running Deep Neural Network (DNN) models on devices with limited computational capability is a challenge due to large compute and memory requirements. Quantized Neural Networks (QNNs) have emerged as a potential solution to this problem, promising to offer most of the DNN accuracy benefits with much lower computational cost. However, harvesting these benefits on existing mobile CPUs is a challenge since operations on highly quantized datatypes are not natively supported in most instruction set architectures (ISAs). In this work, we first describe a streamlining flow to convert all QNN inference operations to integer ones. Afterwards, we provide techniques based on processing one bit position at a time (bit-serial) to show how QNNs can be efficiently deployed using common bitwise operations. We demonstrate the potential of QNNs on mobile CPUs with microbenchmarks and on a quantized AlexNet, which is 3.5x faster than an optimized 8-bit baseline."
            },
            "slug": "Streamlined-Deployment-for-Quantized-Neural-Umuroglu-Jahre",
            "title": {
                "fragments": [],
                "text": "Streamlined Deployment for Quantized Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work describes a streamlining flow to convert all QNN inference operations to integer ones and provides techniques based on processing one bit position at a time (bit-serial) to show how QNNs can be efficiently deployed using common bitwise operations."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287035"
                        ],
                        "name": "Mengxiao Lin",
                        "slug": "Mengxiao-Lin",
                        "structuredName": {
                            "firstName": "Mengxiao",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengxiao Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24982157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da734397acd7ff7c557960c62fb1b400b27bd89",
            "isKey": false,
            "numCitedBy": 3251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13\u00c3\u2014 actual speedup over AlexNet while maintaining comparable accuracy."
            },
            "slug": "ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An extremely computation-efficient CNN architecture named ShuffleNet is introduced, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs), to greatly reduce computation cost while maintaining accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115354049"
                        ],
                        "name": "Jeff Johnson",
                        "slug": "Jeff-Johnson",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143949035"
                        ],
                        "name": "Micha\u00ebl Mathieu",
                        "slug": "Micha\u00ebl-Mathieu",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Mathieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Micha\u00ebl Mathieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058304"
                        ],
                        "name": "Serkan Piantino",
                        "slug": "Serkan-Piantino",
                        "structuredName": {
                            "firstName": "Serkan",
                            "lastName": "Piantino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serkan Piantino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15193948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "326d65827307862ddc3d39b84ebc662e83ff95b3",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units. We introduce two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFT (over 1.5x) for whole CNNs. Both of these convolution implementations are available in open source, and are faster than NVIDIA's cuDNN implementation for many common convolutional layers (up to 23.5x for some synthetic kernel configurations). We discuss different performance regimes of convolutions, comparing areas where straightforward time domain convolutions outperform Fourier frequency domain convolutions. Details on algorithmic applications of NVIDIA GPU hardware specifics in the implementation of fbfft are also provided."
            },
            "slug": "Fast-Convolutional-Nets-With-fbfft:-A-GPU-Vasilache-Johnson",
            "title": {
                "fragments": [],
                "text": "Fast Convolutional Nets With fbfft: A GPU Performance Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work examines the performance profile of Convolutional Neural Network training on the current generation of NVIDIA Graphics Processing Units, and introduces two new Fast Fourier Transform convolution implementations: one based on NVIDIA's cuFFT library, and another based on a Facebook authored FFT implementation, fbfft, that provides significant speedups over cuFFt."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688587"
                        ],
                        "name": "Haojin Yang",
                        "slug": "Haojin-Yang",
                        "structuredName": {
                            "firstName": "Haojin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haojin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065661000"
                        ],
                        "name": "Martin Fritzsche",
                        "slug": "Martin-Fritzsche",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fritzsche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Fritzsche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28918194"
                        ],
                        "name": "Christian Bartz",
                        "slug": "Christian-Bartz",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Bartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708312"
                        ],
                        "name": "C. Meinel",
                        "slug": "C.-Meinel",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Meinel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Meinel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7323727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15bf028d4f4f73c87d8240d6616340bbcea28208",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Binary Neural Networks (BNNs) can drastically reduce memory size and accesses by applying bit-wise operations instead of standard arithmetic operations. Therefore it could significantly improve the efficiency and lower the energy consumption at runtime, which enables the application of state-of-the-art deep learning models on low power devices. BMXNet is an open-source BNN library based on MXNet, which supports both XNOR-Networks and Quantized Neural Networks. The developed BNN layers can be seamlessly applied with other standard library components and work in both GPU and CPU mode. BMXNet is maintained and developed by the multimedia research group at Hasso Plattner Institute and released under Apache license. Extensive experiments validate the efficiency and effectiveness of our implementation. The BMXNet library, several sample projects, and a collection of pre-trained binary deep models are available for download at https://github.com/hpi-xnor."
            },
            "slug": "BMXNet:-An-Open-Source-Binary-Neural-Network-Based-Yang-Fritzsche",
            "title": {
                "fragments": [],
                "text": "BMXNet: An Open-Source Binary Neural Network Implementation Based on MXNet"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "BMXNet is an open-source BNN library based on MXNet, which supports both XNOR-Networks and Quantized Neural Networks and can be seamlessly applied with other standard library components and work in both GPU and CPU mode."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10324,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73175007"
                        ],
                        "name": "Andrew Lavin",
                        "slug": "Andrew-Lavin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lavin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lavin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145565184"
                        ],
                        "name": "Scott Gray",
                        "slug": "Scott-Gray",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Gray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Our 3\u00d73 convolution implementation is a variant of the F (6\u00d76, 3\u00d73) Winograd transform approach [10], with a few modifications \u2014 we cache the transformed filter weights, (which avoids repeated computation at inference time, in exchange for increased memory footprint), and we optionally store intermediate transformed data in float16 (which trades off a reduction precision by reducing the memory bandwidth)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 962822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5eadd6f059d742d76441fd0a635a21694dd7392",
            "isKey": false,
            "numCitedBy": 617,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks take GPU-days of computation to train on large data sets. Pedestrian detection for self driving cars requires very low latency. Image recognition for mobile phones is constrained by limited processing resources. The success of convolutional neural networks in these situations is limited by how fast we can compute them. Conventional FFT based convolution is fast for large filters, but state of the art convolutional neural networks use small, 3 3 filters. We introduce a new class of fast algorithms for convolutional neural networks using Winograd's minimal filtering algorithms. The algorithms compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes. We benchmark a GPU implementation of our algorithm with the VGG network and show state of the art throughput at batch sizes from 1 to 64."
            },
            "slug": "Fast-Algorithms-for-Convolutional-Neural-Networks-Lavin-Gray",
            "title": {
                "fragments": [],
                "text": "Fast Algorithms for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new class of fast algorithms for convolutional neural networks is introduced using Winograd's minimal filtering algorithms, which compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132667"
                        ],
                        "name": "Shuchang Zhou",
                        "slug": "Shuchang-Zhou",
                        "structuredName": {
                            "firstName": "Shuchang",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuchang Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39191613"
                        ],
                        "name": "Zekun Ni",
                        "slug": "Zekun-Ni",
                        "structuredName": {
                            "firstName": "Zekun",
                            "lastName": "Ni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zekun Ni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075348632"
                        ],
                        "name": "He Wen",
                        "slug": "He-Wen",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98264506"
                        ],
                        "name": "Yuxin Wu",
                        "slug": "Yuxin-Wu",
                        "structuredName": {
                            "firstName": "Yuxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3423010"
                        ],
                        "name": "Yuheng Zou",
                        "slug": "Yuheng-Zou",
                        "structuredName": {
                            "firstName": "Yuheng",
                            "lastName": "Zou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuheng Zou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Some examples of this work include XNOR-Net [1], QNNs [2], DoReFa-Net [3], HWGQ-Net [4], and several others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 134
                            }
                        ],
                        "text": "One area of particular interest is the case where both activations and weights are both uniformly quantized \u2014 as in XNOR-Net, HWGQ-Net, DoReFa-Net, and others."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14395129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b053389eb8c18c61b84d7e59a95cb7e13f205b7",
            "isKey": false,
            "numCitedBy": 1360,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose DoReFa-Net, a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients. In particular, during backward pass, parameter gradients are stochastically quantized to low bitwidth numbers before being propagated to convolutional layers. As convolutions during forward/backward passes can now operate on low bitwidth weights and activations/gradients respectively, DoReFa-Net can use bit convolution kernels to accelerate both training and inference. Moreover, as bit convolutions can be efficiently implemented on CPU, FPGA, ASIC and GPU, DoReFa-Net opens the way to accelerate training of low bitwidth neural network on these hardware. Our experiments on SVHN and ImageNet datasets prove that DoReFa-Net can achieve comparable prediction accuracy as 32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has 1-bit weights, 2-bit activations, can be trained from scratch using 6-bit gradients to get 46.1\\% top-1 accuracy on ImageNet validation set. The DoReFa-Net AlexNet model is released publicly."
            },
            "slug": "DoReFa-Net:-Training-Low-Bitwidth-Convolutional-Low-Zhou-Ni",
            "title": {
                "fragments": [],
                "text": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "DoReFa-Net, a method to train convolutional neural networks that have low bitwidth weights and activations using low bit width parameter gradients, is proposed and can achieve comparable prediction accuracy as 32-bit counterparts."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075348632"
                        ],
                        "name": "He Wen",
                        "slug": "He-Wen",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132667"
                        ],
                        "name": "Shuchang Zhou",
                        "slug": "Shuchang-Zhou",
                        "structuredName": {
                            "firstName": "Shuchang",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuchang Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113515664"
                        ],
                        "name": "Zhe Liang",
                        "slug": "Zhe-Liang",
                        "structuredName": {
                            "firstName": "Zhe",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108078811"
                        ],
                        "name": "Yuxiang Zhang",
                        "slug": "Yuxiang-Zhang",
                        "structuredName": {
                            "firstName": "Yuxiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuxiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7841666"
                        ],
                        "name": "Dieqiao Feng",
                        "slug": "Dieqiao-Feng",
                        "structuredName": {
                            "firstName": "Dieqiao",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dieqiao Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146721"
                        ],
                        "name": "C. Yao",
                        "slug": "C.-Yao",
                        "structuredName": {
                            "firstName": "Cong",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The bit-decay method [7] is another simple, intuitive trick, which we found to work well across a range of models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "In particular, we wish to highlight two techniques which we successfully used for a number of our models \u2014 the HWGQ quantizer [4], and the bit-decay method for retraining [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14333937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c98c27f4be40a7675ba9c85179ce72d12593a7a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Fully convolutional neural networks give accurate, per-pixel prediction for input images and have applications like semantic segmentation. However, a typical FCN usually requires lots of floating point computation and large run-time memory, which effectively limits its usability. We propose a method to train Bit Fully Convolution Network (BFCN), a fully convolutional neural network that has low bit-width weights and activations. Because most of its computation-intensive convolutions are accomplished between low bit-width numbers, a BFCN can be accelerated by an efficient bit-convolution implementation. On CPU, the dot product operation between two bit vectors can be reduced to bitwise operations and popcounts, which can offer much higher throughput than 32-bit multiplications and additions. \nTo validate the effectiveness of BFCN, we conduct experiments on the PASCAL VOC 2012 semantic segmentation task and Cityscapes. Our BFCN with 1-bit weights and 2-bit activations, which runs 7.8x faster on CPU or requires less than 1\\% resources on FPGA, can achieve comparable performance as the 32-bit counterpart."
            },
            "slug": "Training-Bit-Fully-Convolutional-Network-for-Fast-Wen-Zhou",
            "title": {
                "fragments": [],
                "text": "Training Bit Fully Convolutional Network for Fast Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a method to train Bit Fully Convolution Network (BFCN), a fully convolutional neural network that has low bit-width weights and activations that can achieve comparable performance as the 32-bit counterpart."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387872181"
                        ],
                        "name": "Ran El-Yaniv",
                        "slug": "Ran-El-Yaniv",
                        "structuredName": {
                            "firstName": "Ran",
                            "lastName": "El-Yaniv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ran El-Yaniv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Some examples of this work include XNOR-Net [1], QNNs [2], DoReFa-Net [3], HWGQ-Net [4], and several others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15817277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2e4147eecae6f914e9e1e9aece8fdd2eaed809f",
            "isKey": false,
            "numCitedBy": 1279,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to train Quantized Neural Networks (QNNs) -- neural networks with extremely low precision (e.g., 1-bit) weights and activations, at run-time. At traintime the quantized weights and activations are used for computing the parameter gradients. During the forward pass, QNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations. As a result, power consumption is expected to be drastically reduced. We trained QNNs over the MNIST, CIFAR-10, SVHN and ImageNet datasets. The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts. For example, our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51% top-1 accuracy. Moreover, we quantize the parameter gradients to 6-bits as well which enables gradients computation using only bit-wise operation. Quantized recurrent neural networks were tested over the Penn Treebank dataset, and achieved comparable accuracy as their 32-bit counterparts using only 4-bits. Last but not least, we programmed a binary matrix multiplication GPU kernel with which it is possible to run our MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The QNN code is available online."
            },
            "slug": "Quantized-Neural-Networks:-Training-Neural-Networks-Hubara-Courbariaux",
            "title": {
                "fragments": [],
                "text": "Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A binary matrix multiplication GPU kernel is programmed with which it is possible to run the MNIST QNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773408"
                        ],
                        "name": "Zhaowei Cai",
                        "slug": "Zhaowei-Cai",
                        "structuredName": {
                            "firstName": "Zhaowei",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaowei Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722627"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 43
                            }
                        ],
                        "text": "With recently developed techniques such as HWGQ-Net (2 bit activations, 1 bit weights) and retraining with bit-decay (2 bit activations, 2 bit weights), these aggressively quantized models are becoming more and more achievable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "In particular, we wish to highlight two techniques which we successfully used for a number of our models \u2014 the HWGQ quantizer [4], and the bit-decay method for retraining [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "Some examples of this work include XNOR-Net [1], QNNs [2], DoReFa-Net [3], HWGQ-Net [4], and several others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 124
                            }
                        ],
                        "text": "One area of particular interest is the case where both activations and weights are both uniformly quantized \u2014 as in XNOR-Net, HWGQ-Net, DoReFa-Net, and others."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1875476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28b79a6a752433958fa4d7ac82ac304b7087400a",
            "isKey": true,
            "numCitedBy": 353,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of quantizing the activations of a deep neural network is considered. An examination of the popular binary quantization approach shows that this consists of approximating a classical non-linearity, the hyperbolic tangent, by two functions: a piecewise constant sign function, which is used in feedforward network computations, and a piecewise linear hard tanh function, used in the backpropagation step during network learning. The problem of approximating the widely used ReLU non-linearity is then considered. An half-wave Gaussian quantizer (HWGQ) is proposed for forward approximation and shown to have efficient implementation, by exploiting the statistics of of network activations and batch normalization operations. To overcome the problem of gradient mismatch, due to the use of different forward and backward approximations, several piece-wise backward approximators are then investigated. The implementation of the resulting quantized network, denoted as HWGQ-Net, is shown to achieve much closer performance to full precision networks, such as AlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision networks, with 1-bit binary weights and 2-bit quantized activations."
            },
            "slug": "Deep-Learning-with-Low-Precision-by-Half-Wave-Cai-He",
            "title": {
                "fragments": [],
                "text": "Deep Learning with Low Precision by Half-Wave Gaussian Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An half-wave Gaussian quantizer (HWGQ) is proposed for forward approximation and shown to have efficient implementation, by exploiting the statistics of of network activations and batch normalization operations, and to achieve much closer performance to full precision networks than previously available low-precision networks."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917613"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc V.",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12227989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0611891b9e8a7c5731146097b6f201578f47b2f",
            "isKey": false,
            "numCitedBy": 3538,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset."
            },
            "slug": "Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan",
            "title": {
                "fragments": [],
                "text": "Learning Transferable Architectures for Scalable Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to search for an architectural building block on a small dataset and then transfer the block to a larger dataset and introduces a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1894799"
                        ],
                        "name": "F. V. Zee",
                        "slug": "F.-V.-Zee",
                        "structuredName": {
                            "firstName": "Field",
                            "lastName": "Zee",
                            "middleNames": [
                                "G.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Zee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9151878"
                        ],
                        "name": "R. V. D. Geijn",
                        "slug": "R.-V.-D.-Geijn",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Geijn",
                            "middleNames": [
                                "A.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. D. Geijn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1242360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355e35184d084abc712c5bfcceafc0fdfe78ceef",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "The BLAS-like Library Instantiation Software (BLIS) framework is a new infrastructure for rapidly instantiating Basic Linear Algebra Subprograms (BLAS) functionality. Its fundamental innovation is that virtually all computation within level-2 (matrix-vector) and level-3 (matrix-matrix) BLAS operations can be expressed and optimized in terms of very simple kernels. While others have had similar insights, BLIS reduces the necessary kernels to what we believe is the simplest set that still supports the high performance that the computational science community demands. Higher-level framework code is generalized and implemented in ISO C99 so that it can be reused and/or reparameterized for different operations (and different architectures) with little to no modification. Inserting high-performance kernels into the framework facilitates the immediate optimization of any BLAS-like operations which are cast in terms of these kernels, and thus the framework acts as a productivity multiplier. Users of BLAS-dependent applications are given a choice of using the traditional Fortran-77 BLAS interface, a generalized C interface, or any other higher level interface that builds upon this latter API. Preliminary performance of level-2 and level-3 operations is observed to be competitive with two mature open source libraries (OpenBLAS and ATLAS) as well as an established commercial product (Intel MKL)."
            },
            "slug": "BLIS:-A-Framework-for-Rapidly-Instantiating-BLAS-Zee-Geijn",
            "title": {
                "fragments": [],
                "text": "BLIS: A Framework for Rapidly Instantiating BLAS Functionality"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Preliminary performance of level-2 and level-3 operations is observed to be competitive with two mature open source libraries (OpenBLAS and ATLAS) as well as an established commercial product (Intel MKL)."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Math. Softw."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361737"
                        ],
                        "name": "I. Carron",
                        "slug": "I.-Carron",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Carron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Carron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Some examples of this work include XNOR-Net [1], QNNs [2], DoReFa-Net [3], HWGQ-Net [4], and several others."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 114
                            }
                        ],
                        "text": "One area of particular interest is the case where both activations and weights are both uniformly quantized \u2014 as in XNOR-Net, HWGQ-Net, DoReFa-Net, and others."
                    },
                    "intents": []
                }
            ],
            "corpusId": 56603066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db55998b130cc5020e3f83e45192bfdfbe92d6e3",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "XNOR-Net:-ImageNet-Classification-Using-Binary-Carron",
            "title": {
                "fragments": [],
                "text": "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/High-performance-ultra-low-precision-convolutions-Tulloch-Jia/a04ac2f7c0f4da3a00a22a9a10266c89fc1d4cb4?sort=total-citations"
}